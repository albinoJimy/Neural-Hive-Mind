{
  "permissions": {
    "allow": [
      "Bash(do echo '--- specialist-$specialist ---' grep -A2 mongodb: /jimy/Neural-Hive-Mind/helm-charts/specialist-$specialist/values-local.yaml)",
      "Bash(kubectl label:*)",
      "Bash(# Configure Grafana to use Loki as datasource\ncat <<'EOF'\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-loki-datasource\n  namespace: observability\n  labels:\n    grafana_datasource: \"1\"\ndata:\n  loki-datasource.yaml: |\n    apiVersion: 1\n    datasources:\n    - name: Loki\n      type: loki\n      access: proxy\n      url: http://loki:3100\n      isDefault: false\n      jsonData:\n        maxLines: 1000\nEOF | kubectl apply -f -)",
      "Bash(__NEW_LINE__ helm install longhorn longhorn/longhorn )",
      "Bash(# Create professional RBAC roles\ncat <<'EOF'\n---\n# Developer Role - Read-only + limited exec\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: developer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\", \"services\", \"endpoints\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\", \"pods/portforward\"]\n  verbs: [\"create\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\", \"statefulsets\", \"daemonsets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"batch\"]\n  resources: [\"jobs\", \"cronjobs\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"networking.k8s.io\"]\n  resources: [\"ingresses\", \"networkpolicies\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\n# DevOps Role - Full namespace control\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: devops\nrules:\n- apiGroups: [\"\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"apps\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"batch\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"networking.k8s.io\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"autoscaling\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"policy\"]\n  resources: [\"poddisruptionbudgets\"]\n  verbs: [\"*\"]\n---\n# SRE Role - Full access + cluster resources\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: sre\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n---\n# Monitoring Role - Read metrics and logs\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: monitoring\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\", \"nodes\", \"services\", \"endpoints\", \"events\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\", \"statefulsets\", \"daemonsets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"metrics.k8s.io\"]\n  resources: [\"*\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"monitoring.coreos.com\"]\n  resources: [\"*\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\n# CI/CD Role - Deploy applications\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cicd-deployer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\", \"secrets\", \"serviceaccounts\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\", \"statefulsets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"batch\"]\n  resources: [\"jobs\", \"cronjobs\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"networking.k8s.io\"]\n  resources: [\"ingresses\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"autoscaling\"]\n  resources: [\"horizontalpodautoscalers\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\nEOF | kubectl apply -f -)",
      "Bash(# Create ServiceAccounts for common use cases\ncat <<'EOF'\n---\n# CI/CD ServiceAccount in neural-hive namespace\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: cicd-deployer\n  namespace: neural-hive\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: cicd-deployer-binding\n  namespace: neural-hive\nsubjects:\n- kind: ServiceAccount\n  name: cicd-deployer\n  namespace: neural-hive\nroleRef:\n  kind: ClusterRole\n  name: cicd-deployer\n  apiGroup: rbac.authorization.k8s.io\n---\n# Monitoring ServiceAccount\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: monitoring-reader\n  namespace: observability\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: monitoring-reader-binding\nsubjects:\n- kind: ServiceAccount\n  name: monitoring-reader\n  namespace: observability\nroleRef:\n  kind: ClusterRole\n  name: monitoring\n  apiGroup: rbac.authorization.k8s.io\n---\n# Developer ServiceAccount for neural-hive\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: developer\n  namespace: neural-hive\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: developer-binding\n  namespace: neural-hive\nsubjects:\n- kind: ServiceAccount\n  name: developer\n  namespace: neural-hive\nroleRef:\n  kind: ClusterRole\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\nEOF | kubectl apply -f -)",
      "Bash(# Create production-grade Prometheus alerting rules\ncat <<'EOF'\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: production-alerts\n  namespace: observability\n  labels:\n    prometheus: neural-hive\n    role: alert-rules\nspec:\n  groups:\n  - name: kubernetes-system\n    rules:\n    - alert: KubernetesNodeNotReady\n      expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"} == 0\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Node {{ $labels.node }} is not ready\"\n        description: \"Node has been unready for more than 5 minutes\"\n    \n    - alert: KubernetesNodeMemoryPressure\n      expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"} == 1\n      for: 2m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Node {{ $labels.node }} has memory pressure\"\n        description: \"Node is running low on memory\"\n    \n    - alert: KubernetesNodeDiskPressure\n      expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"} == 1\n      for: 2m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Node {{ $labels.node }} has disk pressure\"\n        description: \"Node is running low on disk space\"\n\n  - name: kubernetes-pods\n    rules:\n    - alert: KubernetesPodCrashLooping\n      expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 0\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping\"\n        description: \"Pod has been restarting\"\n    \n    - alert: KubernetesPodNotReady\n      expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~\"Pending|Unknown\"}) > 0\n      for: 15m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready\"\n        description: \"Pod has been in non-ready state for more than 15 minutes\"\n    \n    - alert: KubernetesContainerOOMKilled\n      expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"}[10m]) == 1\n      for: 0m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} was OOMKilled\"\n\n  - name: kubernetes-resources\n    rules:\n    - alert: KubernetesCPUOvercommit\n      expr: sum(kube_pod_container_resource_requests{resource=\"cpu\"}) / sum(kube_node_status_allocatable{resource=\"cpu\"}) > 0.9\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Cluster CPU overcommit\"\n        description: \"Cluster CPU requests are over 90% of allocatable\"\n    \n    - alert: KubernetesMemoryOvercommit\n      expr: sum(kube_pod_container_resource_requests{resource=\"memory\"}) / sum(kube_node_status_allocatable{resource=\"memory\"}) > 0.9\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Cluster memory overcommit\"\n        description: \"Cluster memory requests are over 90% of allocatable\"\n    \n    - alert: KubernetesPVCPending\n      expr: kube_persistentvolumeclaim_status_phase{phase=\"Pending\"} == 1\n      for: 15m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"PVC {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\"\n\n  - name: neural-hive-application\n    rules:\n    - alert: NeuralHiveServiceDown\n      expr: up{namespace=\"neural-hive\"} == 0\n      for: 2m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Service {{ $labels.job }} in neural-hive is down\"\n        description: \"Service has been down for more than 2 minutes\"\n    \n    - alert: NeuralHiveHighLatency\n      expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{namespace=\"neural-hive\"}[5m])) by (le, service)) > 2\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High latency in {{ $labels.service }}\"\n        description: \"P99 latency is above 2 seconds\"\n    \n    - alert: NeuralHiveHighErrorRate\n      expr: sum(rate(http_requests_total{namespace=\"neural-hive\",status=~\"5..\"}[5m])) by (service) / sum(rate(http_requests_total{namespace=\"neural-hive\"}[5m])) by (service) > 0.05\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High error rate in {{ $labels.service }}\"\n        description: \"Error rate is above 5%\"\n\n  - name: kafka-alerts\n    rules:\n    - alert: KafkaConsumerLag\n      expr: kafka_consumergroup_lag > 1000\n      for: 10m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Kafka consumer lag is high for {{ $labels.consumergroup }}\"\n        description: \"Consumer group {{ $labels.consumergroup }} has lag > 1000\"\n    \n    - alert: KafkaBrokerDown\n      expr: kafka_brokers < 3\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Kafka broker is down\"\n        description: \"Number of Kafka brokers is below expected\"\n\n  - name: mongodb-alerts\n    rules:\n    - alert: MongoDBDown\n      expr: mongodb_up == 0\n      for: 2m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"MongoDB is down\"\n        description: \"MongoDB instance is not responding\"\n    \n    - alert: MongoDBHighConnections\n      expr: mongodb_connections{state=\"current\"} > 500\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"MongoDB high connections\"\n        description: \"MongoDB has more than 500 active connections\"\nEOF | kubectl apply -f -)",
      "Bash(# Create HorizontalPodAutoscalers for neural-hive services\ncat <<'EOF'\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: gateway-intencoes-hpa\n  namespace: neural-hive\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: gateway-intencoes\n  minReplicas: 1\n  maxReplicas: 5\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 30\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: consensus-engine-hpa\n  namespace: neural-hive\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: consensus-engine\n  minReplicas: 1\n  maxReplicas: 3\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: semantic-translation-engine-hpa\n  namespace: neural-hive\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: semantic-translation-engine\n  minReplicas: 1\n  maxReplicas: 5\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\nEOF | kubectl apply -f -)",
      "Bash(# Create sample Ingress with TLS for neural-hive gateway\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: neural-hive-gateway\n  namespace: neural-hive\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"50m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\n    nginx.ingress.kubernetes.io/rate-limit-window: \"1m\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.neural-hive.local\n    secretName: neural-hive-gateway-tls\n  rules:\n  - host: api.neural-hive.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: gateway-intencoes\n            port:\n              number: 8000\n---\n# Ingress for Grafana\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.neural-hive.local\n    secretName: grafana-tls\n  rules:\n  - host: grafana.neural-hive.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-grafana\n            port:\n              number: 80\n---\n# Ingress for Longhorn UI\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: longhorn-ingress\n  namespace: longhorn-system\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: longhorn-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: longhorn.neural-hive.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: longhorn-frontend\n            port:\n              number: 80\nEOF | kubectl apply -f -)",
      "Bash(# Create basic auth secret for Longhorn using heredoc\ncat <<'EOF'\napiVersion: v1\nkind: Secret\nmetadata:\n  name: longhorn-basic-auth\n  namespace: longhorn-system\ntype: Opaque\nstringData:\n  auth: \"admin:$apr1$7qJN3pYX$OZsVqCzHCRu/qJxcBLhWp0\"\nEOF | kubectl apply -f -)",
      "Bash(kubectl get:*)",
      "Bash(helm repo add:*)",
      "Bash(helm repo update:*)",
      "Bash(helm install:*)",
      "Bash(kubectl describe:*)",
      "Bash(helm uninstall:*)",
      "Bash(kubectl logs:*)",
      "Bash(# Update ingresses with external-dns target annotation\ncat <<'EOF'\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: neural-hive-gateway\n  namespace: neural-hive\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"50m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    external-dns.alpha.kubernetes.io/hostname: api.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.elysiumii.com\n    secretName: neural-hive-gateway-tls\n  rules:\n  - host: api.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: gateway-intencoes\n            port:\n              number: 8000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    external-dns.alpha.kubernetes.io/hostname: grafana.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.elysiumii.com\n    secretName: grafana-tls\n  rules:\n  - host: grafana.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-grafana\n            port:\n              number: 80\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: longhorn-ingress\n  namespace: longhorn-system\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: longhorn-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    external-dns.alpha.kubernetes.io/hostname: longhorn.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - longhorn.elysiumii.com\n    secretName: longhorn-tls\n  rules:\n  - host: longhorn.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: longhorn-frontend\n            port:\n              number: 80\nEOF | kubectl apply -f -)",
      "Bash(# Create new ClusterIssuer with DNS-01 solver\ncat <<'EOF'\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod-dns\nspec:\n  acme:\n    email: admin@elysiumii.com\n    server: https://acme-v02.api.letsencrypt.org/directory\n    privateKeySecretRef:\n      name: letsencrypt-prod-dns-account-key\n    solvers:\n    - dns01:\n        cloudflare:\n          apiTokenSecretRef:\n            name: cloudflare-api-token\n            key: api-token\n      selector:\n        dnsZones:\n        - \"elysiumii.com\"\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging-dns\nspec:\n  acme:\n    email: admin@elysiumii.com\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    privateKeySecretRef:\n      name: letsencrypt-staging-dns-account-key\n    solvers:\n    - dns01:\n        cloudflare:\n          apiTokenSecretRef:\n            name: cloudflare-api-token\n            key: api-token\n      selector:\n        dnsZones:\n        - \"elysiumii.com\"\nEOF | kubectl apply -f -)",
      "Bash(# Update Ingresses to use DNS-01 issuer\ncat <<'EOF'\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: neural-hive-gateway\n  namespace: neural-hive\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod-dns\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"50m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    external-dns.alpha.kubernetes.io/hostname: api.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.elysiumii.com\n    secretName: neural-hive-gateway-tls\n  rules:\n  - host: api.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: gateway-intencoes\n            port:\n              number: 8000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod-dns\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    external-dns.alpha.kubernetes.io/hostname: grafana.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.elysiumii.com\n    secretName: grafana-tls\n  rules:\n  - host: grafana.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-grafana\n            port:\n              number: 80\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: longhorn-ingress\n  namespace: longhorn-system\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod-dns\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: longhorn-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\n    external-dns.alpha.kubernetes.io/hostname: longhorn.elysiumii.com\n    external-dns.alpha.kubernetes.io/ttl: \"120\"\n    external-dns.alpha.kubernetes.io/target: \"37.60.241.150\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - longhorn.elysiumii.com\n    secretName: longhorn-tls\n  rules:\n  - host: longhorn.elysiumii.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: longhorn-frontend\n            port:\n              number: 80\nEOF | kubectl apply -f -)",
      "Bash(dig:*)",
      "Bash(whois:*)",
      "Bash(echo:*)",
      "Bash(# Create new Ingresses with HTTP-01 (not DNS-01) for elysiumii.site\ncat <<'EOF'\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: neural-hive-gateway\n  namespace: neural-hive\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"50m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.elysiumii.site\n    secretName: neural-hive-gateway-tls\n  rules:\n  - host: api.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: gateway-intencoes\n            port:\n              number: 8000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.elysiumii.site\n    secretName: grafana-tls\n  rules:\n  - host: grafana.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-grafana\n            port:\n              number: 80\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: longhorn-ingress\n  namespace: longhorn-system\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: longhorn-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - longhorn.elysiumii.site\n    secretName: longhorn-tls\n  rules:\n  - host: longhorn.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: longhorn-frontend\n            port:\n              number: 80\nEOF | kubectl apply -f -)",
      "Bash(curl:*)",
      "Bash(ss:*)",
      "Bash(docker ps:*)",
      "Bash(docker stop:*)",
      "Bash(docker rm:*)",
      "Bash(__NEW_LINE__ helm upgrade ingress-nginx ingress-nginx/ingress-nginx )",
      "Bash(jq -r \".[] | \"\"\\(.name): \\(.value // .valueFrom.secretKeyRef.name)\"\"\")",
      "Bash(kubectl exec:*)",
      "Bash(xargs:*)",
      "Bash(kubectl rollout:*)",
      "Bash(pkill:*)",
      "Bash(for specialist in business technical behavior evolution architecture)",
      "Bash(do echo '--- specialist-$specialist ---')",
      "Bash(jq:*)",
      "Bash(done)",
      "Bash(do echo)",
      "Bash(cat:*)",
      "Bash(docker build:*)",
      "Bash(.)",
      "Bash(./scripts/build-base-images.sh:*)",
      "Bash(docker run:*)",
      "Bash(./scripts/build-and-push-to-registry.sh:*)",
      "Bash(openssl s_client:*)",
      "Bash(openssl x509:*)",
      "Bash(for specialist in specialist-business specialist-technical specialist-behavior specialist-evolution specialist-architecture)",
      "Bash(do)",
      "Bash(kubectl run curl-test --rm -it --restart=Never --image=curlimages/curl:latest -n neural-hive -- curl -s http://gateway-intencoes/health)",
      "Bash(kubectl delete:*)",
      "Bash(# Create NGINX Ingress Dashboard\ncat <<'EOF'\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-dashboard-nginx-ingress\n  namespace: observability\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  nginx-ingress.json: |\n    {\n      \"annotations\": {\n        \"list\": []\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": null,\n      \"links\": [],\n      \"liveNow\": false,\n      \"panels\": [\n        {\n          \"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"},\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\"mode\": \"palette-classic\"},\n              \"mappings\": [],\n              \"thresholds\": {\"mode\": \"absolute\", \"steps\": [{\"color\": \"green\", \"value\": null}]},\n              \"unit\": \"reqps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0},\n          \"id\": 1,\n          \"options\": {\"colorMode\": \"value\", \"graphMode\": \"area\", \"justifyMode\": \"auto\", \"orientation\": \"auto\", \"reduceOptions\": {\"calcs\": [\"lastNotNull\"], \"fields\": \"\", \"values\": false}, \"textMode\": \"auto\"},\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [{\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"sum(rate(nginx_ingress_controller_requests[5m]))\", \"refId\": \"A\"}],\n          \"title\": \"Total Requests/sec\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"},\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\"mode\": \"palette-classic\"},\n              \"mappings\": [],\n              \"thresholds\": {\"mode\": \"absolute\", \"steps\": [{\"color\": \"green\", \"value\": null}, {\"color\": \"yellow\", \"value\": 0.01}, {\"color\": \"red\", \"value\": 0.05}]},\n              \"unit\": \"percentunit\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0},\n          \"id\": 2,\n          \"options\": {\"colorMode\": \"value\", \"graphMode\": \"area\", \"justifyMode\": \"auto\", \"orientation\": \"auto\", \"reduceOptions\": {\"calcs\": [\"lastNotNull\"], \"fields\": \"\", \"values\": false}, \"textMode\": \"auto\"},\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [{\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"sum(rate(nginx_ingress_controller_requests{status=~\\\"5..\\\"}[5m])) / sum(rate(nginx_ingress_controller_requests[5m]))\", \"refId\": \"A\"}],\n          \"title\": \"Error Rate (5xx)\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"},\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\"mode\": \"palette-classic\"},\n              \"custom\": {\"axisCenteredZero\": false, \"axisColorMode\": \"text\", \"axisLabel\": \"\", \"axisPlacement\": \"auto\", \"barAlignment\": 0, \"drawStyle\": \"line\", \"fillOpacity\": 10, \"gradientMode\": \"none\", \"hideFrom\": {\"legend\": false, \"tooltip\": false, \"viz\": false}, \"lineInterpolation\": \"linear\", \"lineWidth\": 1, \"pointSize\": 5, \"scaleDistribution\": {\"type\": \"linear\"}, \"showPoints\": \"never\", \"spanNulls\": false, \"stacking\": {\"group\": \"A\", \"mode\": \"none\"}, \"thresholdsStyle\": {\"mode\": \"off\"}},\n              \"mappings\": [],\n              \"thresholds\": {\"mode\": \"absolute\", \"steps\": [{\"color\": \"green\", \"value\": null}]},\n              \"unit\": \"reqps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 8},\n          \"id\": 3,\n          \"options\": {\"legend\": {\"calcs\": [], \"displayMode\": \"list\", \"placement\": \"bottom\", \"showLegend\": true}, \"tooltip\": {\"mode\": \"multi\", \"sort\": \"none\"}},\n          \"targets\": [{\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"sum by (ingress) (rate(nginx_ingress_controller_requests[5m]))\", \"legendFormat\": \"{{ingress}}\", \"refId\": \"A\"}],\n          \"title\": \"Requests by Ingress\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"},\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\"mode\": \"palette-classic\"},\n              \"custom\": {\"axisCenteredZero\": false, \"axisColorMode\": \"text\", \"axisLabel\": \"\", \"axisPlacement\": \"auto\", \"barAlignment\": 0, \"drawStyle\": \"line\", \"fillOpacity\": 10, \"gradientMode\": \"none\", \"hideFrom\": {\"legend\": false, \"tooltip\": false, \"viz\": false}, \"lineInterpolation\": \"linear\", \"lineWidth\": 1, \"pointSize\": 5, \"scaleDistribution\": {\"type\": \"linear\"}, \"showPoints\": \"never\", \"spanNulls\": false, \"stacking\": {\"group\": \"A\", \"mode\": \"none\"}, \"thresholdsStyle\": {\"mode\": \"off\"}},\n              \"mappings\": [],\n              \"thresholds\": {\"mode\": \"absolute\", \"steps\": [{\"color\": \"green\", \"value\": null}]},\n              \"unit\": \"s\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 16},\n          \"id\": 4,\n          \"options\": {\"legend\": {\"calcs\": [], \"displayMode\": \"list\", \"placement\": \"bottom\", \"showLegend\": true}, \"tooltip\": {\"mode\": \"multi\", \"sort\": \"none\"}},\n          \"targets\": [{\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"histogram_quantile(0.50, sum(rate(nginx_ingress_controller_request_duration_seconds_bucket[5m])) by (le, ingress))\", \"legendFormat\": \"p50 {{ingress}}\", \"refId\": \"A\"}, {\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"histogram_quantile(0.95, sum(rate(nginx_ingress_controller_request_duration_seconds_bucket[5m])) by (le, ingress))\", \"legendFormat\": \"p95 {{ingress}}\", \"refId\": \"B\"}, {\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"histogram_quantile(0.99, sum(rate(nginx_ingress_controller_request_duration_seconds_bucket[5m])) by (le, ingress))\", \"legendFormat\": \"p99 {{ingress}}\", \"refId\": \"C\"}],\n          \"title\": \"Request Latency by Ingress\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"},\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\"mode\": \"palette-classic\"},\n              \"custom\": {\"axisCenteredZero\": false, \"axisColorMode\": \"text\", \"axisLabel\": \"\", \"axisPlacement\": \"auto\", \"barAlignment\": 0, \"drawStyle\": \"line\", \"fillOpacity\": 10, \"gradientMode\": \"none\", \"hideFrom\": {\"legend\": false, \"tooltip\": false, \"viz\": false}, \"lineInterpolation\": \"linear\", \"lineWidth\": 1, \"pointSize\": 5, \"scaleDistribution\": {\"type\": \"linear\"}, \"showPoints\": \"never\", \"spanNulls\": false, \"stacking\": {\"group\": \"A\", \"mode\": \"normal\"}, \"thresholdsStyle\": {\"mode\": \"off\"}},\n              \"mappings\": [],\n              \"thresholds\": {\"mode\": \"absolute\", \"steps\": [{\"color\": \"green\", \"value\": null}]},\n              \"unit\": \"reqps\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\"h\": 8, \"w\": 24, \"x\": 0, \"y\": 24},\n          \"id\": 5,\n          \"options\": {\"legend\": {\"calcs\": [], \"displayMode\": \"list\", \"placement\": \"bottom\", \"showLegend\": true}, \"tooltip\": {\"mode\": \"multi\", \"sort\": \"none\"}},\n          \"targets\": [{\"datasource\": {\"type\": \"prometheus\", \"uid\": \"prometheus\"}, \"expr\": \"sum by (status) (rate(nginx_ingress_controller_requests[5m]))\", \"legendFormat\": \"{{status}}\", \"refId\": \"A\"}],\n          \"title\": \"Requests by Status Code\",\n          \"type\": \"timeseries\"\n        }\n      ],\n      \"refresh\": \"30s\",\n      \"schemaVersion\": 38,\n      \"style\": \"dark\",\n      \"tags\": [\"nginx\", \"ingress\"],\n      \"templating\": {\"list\": []},\n      \"time\": {\"from\": \"now-1h\", \"to\": \"now\"},\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"NGINX Ingress Controller\",\n      \"uid\": \"nginx-ingress\",\n      \"version\": 1,\n      \"weekStart\": \"\"\n    }\nEOF | kubectl apply -f -)",
      "Bash(for spec in specialist-business specialist-technical specialist-behavior specialist-evolution specialist-architecture)",
      "Bash(do echo '--- $spec ---' kubectl logs -n neural-hive deploy/$spec --tail=500)",
      "Bash(find:*)",
      "Bash(source .env.training)",
      "Bash(export LLM_PROVIDER LLM_MODEL LLM_API_KEY MLFLOW_TRACKING_URI MONGODB_URI)",
      "Bash(./train_all_specialists.sh:*)",
      "Bash(export MLFLOW_TRACKING_URI=http://localhost:5000:*)",
      "Bash(export LLM_PROVIDER LLM_MODEL LLM_API_KEY)",
      "Bash(export ALLOW_SYNTHETIC_FALLBACK=true)",
      "Bash(export DATASET_DIR=/jimy/Neural-Hive-Mind/ml_pipelines/training/data:*)",
      "Bash(python3:*)",
      "Bash(pip install:*)",
      "Bash(pip3 install:*)",
      "Bash(pip3 show:*)",
      "Bash(/usr/bin/python3:*)",
      "Bash(export OUTPUT_DIR=/jimy/Neural-Hive-Mind/ml_pipelines/training/data:*)",
      "Bash(export NUM_SAMPLES=100)",
      "Bash(./generate_all_datasets.sh:*)",
      "Bash(pip3 --version:*)",
      "Bash(/usr/local/bin/python3.11:*)",
      "Bash(for specialist in business behavior evolution architecture)",
      "Bash(for specialist in technical business behavior evolution architecture)",
      "Bash(kubectl set env:*)",
      "Bash(apt-get install:*)",
      "Bash(kubectl run:*)",
      "Bash(do echo \"=== specialist-$specialist ===\" kubectl logs -n neural-hive deploy/specialist-$specialist --since=2m)",
      "Bash(source:*)",
      "Bash(export MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI:-http://localhost:5000)",
      "Bash(export TRAINING_DATASET_PATH=$TRAINING_DATASET_PATH:-/jimy/Neural-Hive-Mind/ml_pipelines/training/data/specialist_{specialist_type_training.parquet})",
      "Bash(export TRAINING_DATASET_PATH=\"/jimy/Neural-Hive-Mind/ml_pipelines/training/data/specialist_{specialist_type}_training.parquet\")",
      "Bash(netstat:*)",
      "Bash(do echo echo '--- specialist-$specialist ---' kubectl logs -n neural-hive deploy/specialist-$specialist --tail=20)",
      "Bash(cp:*)",
      "Bash(do echo \"Atualizando specialist-$specialist...\")",
      "Bash(kubectl set image deployment/specialist-$specialist -n neural-hive specialist=37.60.241.150:30500/specialist-$specialist:latest done)",
      "Bash(kubectl set image:*)",
      "Bash(kubectl patch:*)",
      "Bash(grep:*)",
      "Bash(kubectl create configmap:*)",
      "Bash(kubectl apply:*)",
      "Bash(helm get values:*)",
      "Bash(helm upgrade:*)",
      "Bash(for img in specialist-business specialist-technical specialist-behavior specialist-evolution specialist-architecture)",
      "Bash(do echo -n '$img: ' curl -s http://37.60.241.150:30500/v2/$img/tags/list)",
      "Bash(docker images:*)",
      "Bash(sort:*)",
      "Bash(for svc in specialist-business specialist-technical specialist-behavior specialist-evolution)",
      "Bash(do echo '=== $svc ===' kubectl exec -n neural-hive deploy/$svc -- curl -s http://localhost:8000/status)",
      "Bash(do echo -n \"specialist-$spec: \" kubectl exec -n neural-hive deploy/specialist-$spec -- curl -s http://localhost:8000/health)",
      "Bash(docker push:*)",
      "Bash(docker tag:*)",
      "Bash(for spec in business technical behavior evolution architecture)",
      "Bash(do echo -n 'specialist-$spec: ' kubectl exec -n neural-hive deploy/specialist-$spec -- curl -s http://localhost:8000/status)",
      "Bash(for spec in technical behavior evolution architecture)",
      "Bash(do echo '=== SPECIALIST-$spec ===' kubectl logs -n neural-hive deploy/specialist-$spec --since=5m)",
      "Bash(for spec in technical business behavior evolution architecture)",
      "Bash(do echo '=== specialist-$spec ===' kubectl exec -n neural-hive deploy/specialist-$spec -- curl -s http://localhost:8000/status)",
      "Bash(export PYTHONPATH=\"/jimy/Neural-Hive-Mind/libraries/python:/jimy/Neural-Hive-Mind/ml_pipelines:$PYTHONPATH\")",
      "Bash(export LLM_PROVIDER=groq)",
      "Bash(export LLM_MODEL=llama-3.1-70b-versatile)",
      "Bash(export LLM_API_KEY=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)",
      "Bash(export LLM_MODEL=llama-3.3-70b-versatile)",
      "Bash(ls:*)",
      "Bash(for f in /jimy/Neural-Hive-Mind/ml_pipelines/training/data/specialist_*_base.parquet)",
      "Bash(do echo \"=== $f ===\")",
      "Bash(export LLM_PROVIDER=deepseek)",
      "Bash(export LLM_MODEL=deepseek-chat)",
      "Bash(export LLM_API_KEY=sk-6cd0e5de616c4d5bb7232fe87f8c9bfd)",
      "Bash(for f in data/specialist_*_base.parquet)",
      "Bash(export NUM_SAMPLES=30)",
      "Bash(export MIN_QUALITY_SCORE=0.5)",
      "Bash(chmod:*)",
      "Bash(bash -n:*)",
      "Bash(DOCKER_BUILDKIT=1 docker build:*)",
      "Bash(for service in analyst-agents code-forge execution-ticket-service guard-agents mcp-tool-catalog optimizer-agents orchestrator-dynamic queen-agent scout-agents self-healing-engine service-registry sla-management-system worker-agents)",
      "Bash(mv:*)",
      "Bash(# Aplicar MCP Tool Catalog alerts com namespace correto (observability)\ncat <<'EOF'\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: mcp-tool-catalog-alerts\n  namespace: observability\n  labels:\n    app.kubernetes.io/name: mcp-tool-catalog\n    app.kubernetes.io/component: alerting\n    prometheus: neural-hive\nspec:\n  groups:\n  - name: mcp-tool-catalog\n    interval: 30s\n    rules:\n    - alert: MCPToolCatalogDown\n      expr: up{job=\"mcp-tool-catalog\"} == 0\n      for: 1m\n      labels:\n        severity: critical\n        component: mcp-tool-catalog\n      annotations:\n        summary: \"MCP Tool Catalog Service is down\"\n        description: \"MCP Tool Catalog has been down for more than 1 minute.\"\n    - alert: MCPHighSelectionLatency\n      expr: histogram_quantile(0.95, rate(mcp_tool_selection_duration_seconds_bucket[5m])) > 5\n      for: 5m\n      labels:\n        severity: warning\n        component: mcp-tool-catalog\n      annotations:\n        summary: \"High tool selection latency (p95 > 5s)\"\n        description: \"95th percentile of tool selection duration is {{ $value }}s.\"\n    - alert: MCPPodCrashLooping\n      expr: rate(kube_pod_container_status_restarts_total{pod=~\"mcp-tool-catalog.*\"}[15m]) > 0\n      for: 5m\n      labels:\n        severity: critical\n        component: mcp-tool-catalog\n      annotations:\n        summary: \"Pod is crash looping\"\n        description: \"Pod {{ $labels.pod }} has restarted {{ $value }} times in the last 15 minutes.\"\nEOF | kubectl apply -f -)",
      "Bash(# Aplicar circuit-breaker-alerts com header correto\ncat <<'EOF'\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: circuit-breaker-alerts\n  namespace: observability\n  labels:\n    prometheus: neural-hive\nspec:\n  groups:\n  - name: circuit_breakers\n    interval: 30s\n    rules:\n    - alert: CircuitBreakerOpen\n      expr: circuit_breaker_state == 1\n      for: 2m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Circuit breaker {{ $labels.circuit }} is open in {{ $labels.service }}\"\n    - alert: CircuitBreakerHighFailureRate\n      expr: rate(circuit_breaker_failures_total[5m]) > 0.1\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"High failure rate in circuit {{ $labels.circuit }} ({{ $labels.service }})\"\nEOF | kubectl apply -f -)",
      "Bash(# Aplicar model-performance-alerts com header correto\ncat <<'EOF'\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: model-performance-alerts\n  namespace: observability\n  labels:\n    prometheus: neural-hive\nspec:\n  groups:\n  - name: model_performance_alerts\n    interval: 30s\n    rules:\n    - alert: ModelPerformanceDegraded\n      expr: neural_hive_model_performance_score < 0.6\n      for: 1h\n      labels:\n        severity: warning\n        component: ml-monitoring\n      annotations:\n        summary: \"Performance do modelo {{ $labels.specialist_type }} degradada\"\n        description: \"Performance do modelo está abaixo de 60%\"\n    - alert: ModelPrecisionBelowThreshold\n      expr: neural_hive_mlflow_model_precision < 0.75\n      for: 30m\n      labels:\n        severity: warning\n        component: ml-monitoring\n      annotations:\n        summary: \"Precision do modelo {{ $labels.specialist_type }} abaixo do threshold\"\n    - alert: AutoRetrainFailed\n      expr: increase(neural_hive_auto_retrain_triggered_total{status=\"failed\"}[15m]) > 0\n      for: 5m\n      labels:\n        severity: critical\n        component: ml-monitoring\n      annotations:\n        summary: \"Auto-retrain falhou para {{ $labels.specialist_type }}\"\n    - alert: ModelNotLoaded\n      expr: neural_hive_specialist_model_loaded == 0\n      for: 2m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Modelo {{ $labels.specialist_type }} não carregado\"\n        description: \"Specialist está usando heurísticas ao invés de modelo ML\"\n  - name: model_degradation\n    interval: 30s\n    rules:\n    - alert: FeatureExtractionLatencyHigh\n      expr: histogram_quantile(0.95, sum(rate(neural_hive_specialist_feature_extraction_duration_seconds_bucket[5m])) by (le, specialist_type)) > 30\n      for: 10m\n      labels:\n        severity: critical\n        component: ml-monitoring\n      annotations:\n        summary: \"Feature extraction muito lenta para {{ $labels.specialist_type }}\"\n    - alert: ModelConfidenceCritical\n      expr: neural_hive_specialist_confidence_score < 0.1\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Modelo {{ $labels.specialist_type }} com confiança crítica\"\nEOF | kubectl apply -f -)",
      "Bash(# Criar Ingress para Prometheus\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: prometheus-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required - Prometheus\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - prometheus.elysiumii.site\n    secretName: prometheus-tls\n  rules:\n  - host: prometheus.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-kub-prometheus\n            port:\n              number: 9090\nEOF | kubectl apply -f -)",
      "Bash(# Criar Ingress para Alertmanager\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: alertmanager-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: alertmanager-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required - Alertmanager\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - alertmanager.elysiumii.site\n    secretName: alertmanager-tls\n  rules:\n  - host: alertmanager.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-kub-alertmanager\n            port:\n              number: 9093\nEOF | kubectl apply -f -)",
      "Bash(# Criar Ingress para Jaeger UI\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: jaeger-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: jaeger-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required - Jaeger\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - jaeger.elysiumii.site\n    secretName: jaeger-tls\n  rules:\n  - host: jaeger.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-jaeger-query\n            port:\n              number: 16686\nEOF | kubectl apply -f -)",
      "Bash(# Criar Ingress para Loki (opcional, para queries via API)\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: loki-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: loki-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required - Loki\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - loki.elysiumii.site\n    secretName: loki-tls\n  rules:\n  - host: loki.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: loki\n            port:\n              number: 3100\nEOF | kubectl apply -f -)",
      "Bash(# Gerar senha segura e criar secrets de autenticação básica\n# Usando htpasswd format: admin:$apr1$...\n\n# Criar secret para Prometheus (admin/NeuralHive2024!)\ncat <<'EOF'\napiVersion: v1\nkind: Secret\nmetadata:\n  name: prometheus-basic-auth\n  namespace: observability\ntype: Opaque\nstringData:\n  auth: \"admin:$apr1$Xz7qK2pL$8vR4Y1mN5wQ3zE6tU9jH0.\"\nEOF | kubectl apply -f -)",
      "Bash(# Criar secret para Alertmanager\ncat <<'EOF'\napiVersion: v1\nkind: Secret\nmetadata:\n  name: alertmanager-basic-auth\n  namespace: observability\ntype: Opaque\nstringData:\n  auth: \"admin:$apr1$Xz7qK2pL$8vR4Y1mN5wQ3zE6tU9jH0.\"\nEOF | kubectl apply -f -)",
      "Bash(# Criar secret para Jaeger\ncat <<'EOF'\napiVersion: v1\nkind: Secret\nmetadata:\n  name: jaeger-basic-auth\n  namespace: observability\ntype: Opaque\nstringData:\n  auth: \"admin:$apr1$Xz7qK2pL$8vR4Y1mN5wQ3zE6tU9jH0.\"\nEOF | kubectl apply -f -)",
      "Bash(# Criar secret para Loki\ncat <<'EOF'\napiVersion: v1\nkind: Secret\nmetadata:\n  name: loki-basic-auth\n  namespace: observability\ntype: Opaque\nstringData:\n  auth: \"admin:$apr1$Xz7qK2pL$8vR4Y1mN5wQ3zE6tU9jH0.\"\nEOF | kubectl apply -f -)",
      "Bash(# Atualizar Ingress do Jaeger para usar o serviço correto (all-in-one)\ncat <<'EOF'\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: jaeger-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: jaeger-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required - Jaeger\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - jaeger.elysiumii.site\n    secretName: jaeger-tls\n  rules:\n  - host: jaeger.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-jaeger-allinone\n            port:\n              number: 16686\nEOF | kubectl apply -f -)",
      "Bash(# Deletar e recriar os ingresses\nkubectl delete ingress prometheus-ingress alertmanager-ingress jaeger-ingress loki-ingress -n observability 2>/dev/null\n\nsleep 3\n\n# Recriar todos\ncat <<'EOF'\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: prometheus-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - prometheus.elysiumii.site\n    secretName: prometheus-tls\n  rules:\n  - host: prometheus.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-kub-prometheus\n            port:\n              number: 9090\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: alertmanager-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: alertmanager-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - alertmanager.elysiumii.site\n    secretName: alertmanager-tls\n  rules:\n  - host: alertmanager.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-prometheus-kub-alertmanager\n            port:\n              number: 9093\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: jaeger-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: jaeger-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - jaeger.elysiumii.site\n    secretName: jaeger-tls\n  rules:\n  - host: jaeger.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: neural-hive-jaeger-allinone\n            port:\n              number: 16686\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: loki-ingress\n  namespace: observability\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: loki-basic-auth\n    nginx.ingress.kubernetes.io/auth-realm: \"Authentication Required\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - loki.elysiumii.site\n    secretName: loki-tls\n  rules:\n  - host: loki.elysiumii.site\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: loki\n            port:\n              number: 3100\nEOF | kubectl apply -f -\n\necho \"\"Ingresses recriados\"\")",
      "Bash(/usr/bin/docker build:*)",
      "Bash(docker:*)",
      "Bash(timedatectl status:*)",
      "Bash(ssh:*)",
      "Bash(python -c:*)",
      "Bash(./generate_all_specialists.sh:*)",
      "Bash(pip3 uninstall:*)",
      "Bash(mkdir:*)",
      "Bash(# Verificar se já existe port-forward para MLflow pgrep -f \"\"port-forward.*mlflow.*5000\"\" && echo \"\"Port-forward já existe\"\" || { echo \"\"Iniciando port-forward para MLflow...\"\" kubectl port-forward -n mlflow svc/mlflow 5000:5000 & sleep 3 echo \"\"Port-forward iniciado\"\" } # Testar conexão curl -s http://localhost:5000/health || curl -s http://localhost:5000/api/2.0/mlflow/experiments/list)",
      "Bash(# Matar port-forward antigo e criar novo pkill -f \"\"port-forward.*mlflow.*5001\"\" || true sleep 1 # Criar novo port-forward em background nohup kubectl port-forward -n mlflow svc/mlflow 5001:5000 2>&1 & sleep 3 # Testar conexão curl -s http://localhost:5001/health && echo \"\"MLflow health OK\"\" || \\ curl -s http://localhost:5001/)",
      "Bash(# Usar kubectl exec para acessar MLflow de dentro do cluster kubectl exec -n mlflow deployment/mlflow -- curl -s http://localhost:5000/api/2.0/mlflow/experiments/list)",
      "Bash(# Verificar se curl está disponível no pod MLflow kubectl exec -n mlflow deployment/mlflow -- which curl || echo \"\"curl não disponível\"\" # Tentar com wget kubectl exec -n mlflow deployment/mlflow -- wget -qO- http://localhost:5000/api/2.0/mlflow/experiments/list 2>&1)",
      "Bash(# Copiar arquivos parquet para o pod MLflow kubectl cp /jimy/Neural-Hive-Mind/ml_pipelines/training/data/ mlflow/mlflow-6f55659b89-pdbm9:/tmp/training-data/ echo \"\"Arquivos copiados\"\" kubectl exec -n mlflow deployment/mlflow -- ls -la /tmp/training-data/)",
      "Bash(# Verificar status atual dos specialists kubectl get pods -n neural-hive -l app.kubernetes.io/component=specialist || \\ kubectl get pods -n neural-hive)",
      "Bash(git fetch:*)",
      "Bash(git remote set-url:*)",
      "Bash(ssh-add:*)",
      "Bash(git add:*)"
    ],
    "deny": [],
    "ask": []
  }
}
