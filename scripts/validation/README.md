# Scripts de ValidaÃ§Ã£o - Neural Hive-Mind

Este diretÃ³rio contÃ©m scripts para validaÃ§Ã£o completa do sistema Neural Hive-Mind, incluindo validaÃ§Ãµes de especialistas, modelos ML, infraestrutura e fluxos end-to-end.

## VisÃ£o Geral

### Arquitetura de ValidaÃ§Ã£o

A suite de validaÃ§Ã£o cobre mÃºltiplas camadas do sistema:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Master Orchestrator: validate-all-specialists.sh            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Fase 1: Modelos ML         (validate_models_loaded.sh)     â”‚
â”‚  Fase 2: SaÃºde Specialists  (validate-specialist-health.sh)  â”‚
â”‚  Fase 3: InferÃªncia Modelos (test-specialist-inference.py)   â”‚
â”‚  Fase 4: E2E Consensus      (test-consensus-engine-e2e.py)   â”‚
â”‚  Fase 5: MÃ©tricas           (validate-prometheus-metrics.sh) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo E2E Completo

```
Gateway â†’ Semantic Translation â†’ Consensus Engine â†’ Specialists (5) â†’ MongoDB â†’ Memory Layer API
                                       â†“
                                   Pheromone Trails (Redis)
                                       â†“
                                   Prometheus Metrics
```

---

## ğŸ†• Scripts de ValidaÃ§Ã£o de Especialistas

### validate-all-specialists.sh (Master Orchestrator)

**PropÃ³sito**: Orquestrador mestre que executa toda a suite de validaÃ§Ã£o de especialistas em sequÃªncia

**Uso**:
```bash
# Executar validaÃ§Ã£o completa
./scripts/validation/validate-all-specialists.sh

# Modo rÃ¡pido (pula testes de inferÃªncia e E2E)
./scripts/validation/validate-all-specialists.sh --quick

# Validar apenas um especialista
./scripts/validation/validate-all-specialists.sh --specialist technical

# Modo CI/CD (output JSON)
./scripts/validation/validate-all-specialists.sh --ci-mode --output-dir ./reports
```

**Fases de ValidaÃ§Ã£o**:
1. **PrÃ©-requisitos**: Valida kubectl, jq, curl, python3, acesso ao cluster
2. **Modelos ML**: Verifica modelos no MLflow e carregamento nos specialists
3. **SaÃºde dos Specialists**: Pods, containers, endpoints, dependÃªncias
4. **InferÃªncia de Modelos**: Testa inferÃªncia real via gRPC com planos cognitivos
5. **MÃ©tricas Prometheus**: Valida coleta de mÃ©tricas e dashboards Grafana

**Exit Codes**:
- `0`: Sucesso (taxa â‰¥ 80%)
- `1`: Falha (taxa < 50%)
- `2`: Avisos (taxa entre 50-79%)

**Output**:
- `validation-reports/validation-run-YYYYMMDD_HHMMSS.log`
- `validation-reports/ci-report-YYYYMMDD_HHMMSS.json` (se --ci-mode)

---

### validate_models_loaded.sh

**PropÃ³sito**: Valida que os modelos ML foram carregados com sucesso em todos os especialistas

**LocalizaÃ§Ã£o**: `ml_pipelines/training/validate_models_loaded.sh`

**Uso**:
```bash
# Validar modelos em namespace padrÃ£o
NAMESPACE=semantic-translation ./ml_pipelines/training/validate_models_loaded.sh

# Especificar MLflow URI customizado
MLFLOW_URI=http://mlflow:5000 ./ml_pipelines/training/validate_models_loaded.sh
```

**O que valida**:
1. Modelos registrados no MLflow (5 modelos: technical, business, behavior, evolution, architecture)
2. VersÃ£o Production de cada modelo
3. Status dos pods dos especialistas
4. Endpoint `/status` de cada pod (campos: `model_loaded`, `mlflow_connected`, `ledger_connected`)
5. Estado SERVING do especialista

**DiagnÃ³stico**:
- Se `model_loaded = False`: Modelo nÃ£o existe no MLflow ou nÃ£o estÃ¡ em Production
- Se `mlflow_connected = False`: MLflow nÃ£o estÃ¡ acessÃ­vel
- Se `status != SERVING`: Especialista nÃ£o estÃ¡ pronto para receber requisiÃ§Ãµes

**Exit Code**: `0` se 5/5 especialistas carregaram modelos, `1` caso contrÃ¡rio

---

### validate-specialist-health.sh

**PropÃ³sito**: ValidaÃ§Ã£o abrangente de saÃºde dos especialistas (9 categorias)

**Uso**:
```bash
# ValidaÃ§Ã£o completa
./scripts/validation/validate-specialist-health.sh --namespace semantic-translation

# Pular testes de integraÃ§Ã£o
./scripts/validation/validate-specialist-health.sh --skip-integration

# Modo verbose (inclui testes de inferÃªncia)
./scripts/validation/validate-specialist-health.sh --verbose
```

**Categorias de ValidaÃ§Ã£o**:
1. **Pod Status**: Deployment, replicas, pod phase, readiness
2. **Container Health**: Restart count, estado dos containers
3. **Logs Validation**: Erros crÃ­ticos, conexÃµes com MongoDB
4. **Endpoint Validation**: `/health`, `/ready`, `/metrics` (Prometheus), gRPC (50051)
5. **Dependency Connectivity**: MongoDB, Redis, Neo4j
6. **Resource Usage**: CPU, memÃ³ria
7. **Configuration Validation**: Imagens, variÃ¡veis de ambiente
8. **Integration Testing**: (Opcional, customizÃ¡vel)
9. **ğŸ†• Model & ML Pipeline Health**:
   - Model loaded status
   - MLflow connectivity
   - Serving status (SERVING/NOT_SERVING)
   - Degraded mode detection
   - Inference test (se --verbose)

**Output**:
- `logs/validation-YYYYMMDD-HHMMSS/VALIDATION_REPORT.md`
- Logs individuais por especialista
- SumÃ¡rio com contadores (Passed, Failed, Warnings)

---

### test-specialist-inference.py

**PropÃ³sito**: Testa inferÃªncia real dos modelos via gRPC com planos cognitivos variados

**Uso**:
```bash
# Testar todos os especialistas
./scripts/validation/test-specialist-inference.py

# Testar apenas um especialista
./scripts/validation/test-specialist-inference.py --specialist technical

# CenÃ¡rios especÃ­ficos
./scripts/validation/test-specialist-inference.py --scenarios simple high_risk complex

# Verbose + JSON output
./scripts/validation/test-specialist-inference.py --verbose --output-json inference-report.json

# Namespace customizado
./scripts/validation/test-specialist-inference.py --namespace specialist-ns
```

**CenÃ¡rios de Teste**:
1. **Simple**: Plano de baixo risco, aprovaÃ§Ã£o esperada
2. **High Risk**: Plano de alto risco, rejeiÃ§Ã£o/review esperado
3. **Complex**: Plano com mÃºltiplas tarefas e dependÃªncias
4. **Malformed**: (Futuro) Plano malformado para teste de error handling

**ValidaÃ§Ã£o da Resposta**:
- âœ… `opinion_id` presente e nÃ£o vazio
- âœ… `specialist_type` correto
- âœ… `confidence_score` no range [0.0-1.0]
- âœ… `risk_score` no range [0.0-1.0]
- âœ… `recommendation` em ['approve', 'reject', 'review_required', 'conditional']
- âœ… `reasoning_summary` nÃ£o vazio
- âœ… `evaluated_at` timestamp vÃ¡lido
- âœ… `processing_time_ms` > 0

**Output JSON** (se `--output-json`):
```json
{
  "test_run_id": "uuid",
  "timestamp": "ISO-8601",
  "namespace": "semantic-translation",
  "results": [
    {
      "specialist_type": "technical",
      "scenarios": [
        {
          "scenario": "simple",
          "status": "passed",
          "response_time_ms": 245.67,
          "opinion": {
            "confidence_score": 0.87,
            "risk_score": 0.12,
            "recommendation": "approve"
          }
        }
      ],
      "summary": {"total": 3, "passed": 3, "failed": 0}
    }
  ],
  "overall_summary": {
    "total_tests": 15,
    "passed": 14,
    "failed": 1,
    "success_rate": 93.33
  }
}
```

---

### test-consensus-engine-e2e.py

**PropÃ³sito**: Teste end-to-end do Consensus Engine (Kafka â†’ Especialistas â†’ MongoDB â†’ Redis)

**Status**: âš ï¸ Parcialmente implementado (estrutura pronta, integraÃ§Ã£o Kafka/MongoDB pendente)

**Uso**:
```bash
# Teste E2E com cenÃ¡rios padrÃ£o
./scripts/validation/test-consensus-engine-e2e.py

# CenÃ¡rios customizados
./scripts/validation/test-consensus-engine-e2e.py --scenarios simple,high_risk

# Kafka/MongoDB customizados
./scripts/validation/test-consensus-engine-e2e.py \
  --kafka-bootstrap kafka:9092 \
  --mongodb-uri mongodb://mongo:27017 \
  --timeout 15
```

**Fluxo de Teste**:
1. Publica plano cognitivo no tÃ³pico `cognitive-plans` (Kafka)
2. Monitora tÃ³pico `consensus-decisions` para decisÃ£o
3. Valida que 5/5 especialistas foram invocados
4. Verifica decisÃ£o de consenso no MongoDB
5. Valida pheromone trails atualizados no Redis
6. Mede tempo de processamento fim-a-fim

**Exit Codes**:
- `0`: Todos os testes passaram
- `1`: Falhas detectadas
- `2`: ImplementaÃ§Ã£o pendente

---

### validate-prometheus-metrics.sh

**PropÃ³sito**: Valida coleta de mÃ©tricas Prometheus e dashboards Grafana

**Uso**:
```bash
# ValidaÃ§Ã£o completa
./scripts/validation/validate-prometheus-metrics.sh

# URLs customizadas
./scripts/validation/validate-prometheus-metrics.sh \
  --prometheus-url http://prometheus:9090 \
  --grafana-url http://grafana:3000

# Namespace especÃ­fico
./scripts/validation/validate-prometheus-metrics.sh --namespace specialist-ns
```

**MÃ©tricas Validadas**:
- `specialist_evaluations_total` (counter)
- `specialist_evaluation_duration_seconds` (histogram)
- `specialist_model_inference_duration_seconds` (histogram)
- `specialist_cache_hits_total` / `specialist_cache_misses_total`
- `specialist_errors_total` (por error_type)

**ValidaÃ§Ãµes**:
1. âœ… Prometheus estÃ¡ acessÃ­vel (`/-/healthy`)
2. âœ… MÃ©tricas existem para todos os 5 especialistas
3. âœ… Freshness das mÃ©tricas (Ãºltima coleta < 2 minutos)
4. âœ… Grafana estÃ¡ acessÃ­vel (`/api/health`)
5. âœ… Alerting rules configurados (specialist_down, model_not_loaded)

---

## Quick Start - ValidaÃ§Ã£o Completa

### OpÃ§Ã£o 1: ValidaÃ§Ã£o RÃ¡pida (5 minutos)

```bash
cd /jimy/Neural-Hive-Mind/scripts/validation

# Executar validaÃ§Ã£o completa em modo quick (pula inferÃªncia E2E)
./validate-all-specialists.sh --quick
```

### OpÃ§Ã£o 2: ValidaÃ§Ã£o Completa (15 minutos)

```bash
cd /jimy/Neural-Hive-Mind/scripts/validation

# Executar todas as fases incluindo testes de inferÃªncia
./validate-all-specialists.sh --output-dir ./reports
```

### OpÃ§Ã£o 3: ValidaÃ§Ã£o Individual

```bash
# 1. Validar apenas modelos ML
NAMESPACE=semantic-translation ../../ml_pipelines/training/validate_models_loaded.sh

# 2. Validar apenas saÃºde dos specialists
./validate-specialist-health.sh --namespace semantic-translation --verbose

# 3. Testar apenas inferÃªncia
./test-specialist-inference.py --specialist technical --verbose

# 4. Validar apenas mÃ©tricas
./validate-prometheus-metrics.sh
```

---

## Troubleshooting - ValidaÃ§Ã£o de Especialistas

### Problema: "Model not loaded" (model_loaded = False)

**DiagnÃ³stico**:
```bash
# 1. Verificar se modelo existe no MLflow
curl -s http://mlflow:5000/api/2.0/mlflow/registered-models/get?name=technical-evaluator | jq

# 2. Verificar se estÃ¡ em Production
curl -s http://mlflow:5000/api/2.0/mlflow/registered-models/get?name=technical-evaluator \
  | jq '.registered_model.latest_versions[] | select(.current_stage == "Production")'

# 3. Verificar logs do specialist
kubectl logs -n semantic-translation -l app=specialist-technical --tail=50 | grep -i "model\|mlflow"
```

**SoluÃ§Ã£o**:
- Se modelo nÃ£o existe: Executar treinamento (`ml_pipelines/training/train_specialist_model.py`)
- Se nÃ£o estÃ¡ em Production: Promover modelo no MLflow UI
- Se erro ao carregar: Verificar compatibilidade de versÃ£o (protobuf, mlflow, pandas)

---

### Problema: "Specialist timeout" durante inferÃªncia

**DiagnÃ³stico**:
```bash
# 1. Verificar se pod estÃ¡ Ready
kubectl get pods -n semantic-translation -l app=specialist-technical

# 2. Testar endpoint gRPC manualmente
kubectl port-forward -n semantic-translation svc/specialist-technical 50051:50051 &
grpcurl -plaintext localhost:50051 neural_hive.specialist.SpecialistService/HealthCheck

# 3. Verificar logs de erro
kubectl logs -n semantic-translation -l app=specialist-technical --tail=100 | grep -i "error\|timeout\|exception"
```

**SoluÃ§Ã£o**:
- Aumentar timeout no teste (`--timeout` parameter)
- Verificar recursos do pod (CPU/memÃ³ria)
- Verificar circuit breakers abertos (`/status` endpoint)

---

### Problema: "Prometheus metrics not found"

**DiagnÃ³stico**:
```bash
# 1. Verificar ServiceMonitor configurado
kubectl get servicemonitor -n semantic-translation

# 2. Verificar target no Prometheus
# Acessar Prometheus UI â†’ Status â†’ Targets â†’ Buscar "specialist"

# 3. Testar endpoint /metrics diretamente
kubectl port-forward -n semantic-translation svc/specialist-technical 8000:8000 &
curl -s localhost:8000/metrics | grep specialist_
```

**SoluÃ§Ã£o**:
- Criar ServiceMonitor se nÃ£o existe
- Verificar labels do Service match com ServiceMonitor selector
- Aguardar intervalo de scrape (default: 30s)

---

## Scripts E2E Legados

Os scripts abaixo focam na validaÃ§Ã£o do fluxo Gateway â†’ Consensus â†’ Memory Layer:

## Scripts DisponÃ­veis

### 1. execute-e2e-validation-v1.0.9.sh

**PropÃ³sito**: Executar validaÃ§Ã£o automatizada completa do pipeline

**Uso**:
```bash
./scripts/validation/execute-e2e-validation-v1.0.9.sh
```

**O que faz**:
1. Valida prÃ©-requisitos (kubectl, jq, curl)
2. Executa 7 passos de validaÃ§Ã£o:
   - Gateway health check
   - Envio de intent de teste
   - VerificaÃ§Ã£o de logs do gateway
   - VerificaÃ§Ã£o do Semantic Translation Engine
   - VerificaÃ§Ã£o do Consensus Engine
   - VerificaÃ§Ã£o dos 5 Specialists
   - VerificaÃ§Ã£o de persistÃªncia MongoDB
   - VerificaÃ§Ã£o da Memory Layer API
3. Coleta logs e mÃ©tricas de todos os componentes
4. Gera artefatos em `logs/validation-e2e-v1.0.9-<timestamp>/`
5. Exibe resumo no terminal

**Output**:
- DiretÃ³rio: `logs/validation-e2e-v1.0.9-<timestamp>/`
- Arquivos:
  - `validation.log` - Log consolidado
  - `correlation-ids.txt` - IDs para correlaÃ§Ã£o
  - `01-gateway-health.json` - Health check
  - `02-gateway-response.json` - Response do intent
  - `03-gateway-logs.txt` - Logs do gateway
  - `04-semantic-logs.txt` - Logs do semantic translation
  - `05-consensus-logs.txt` - Logs do consensus engine
  - `06-specialist-*.txt` - Logs de cada specialist
  - `06.5-mongodb-persistence.txt` - Logs de persistÃªncia
  - `07-memory-*.json` - Responses da Memory Layer API
  - `SUMMARY.txt` - Resumo executivo

**Exit Codes**:
- `0` - Todos os passos passaram
- `1` - Algum passo falhou

---

### 2. generate-e2e-report-v1.0.9.sh

**PropÃ³sito**: Gerar relatÃ³rio markdown estruturado a partir dos artefatos coletados

**Uso**:
```bash
./scripts/validation/generate-e2e-report-v1.0.9.sh <output_dir>
```

**Exemplo**:
```bash
./scripts/validation/generate-e2e-report-v1.0.9.sh logs/validation-e2e-v1.0.9-20251110-153000
```

**O que faz**:
1. Processa artefatos do diretÃ³rio de input
2. Extrai mÃ©tricas e evidÃªncias
3. Gera anÃ¡lise comparativa com v1.0.7
4. Cria relatÃ³rio estruturado em markdown
5. Salva em `RELATORIO_VALIDACAO_E2E_POS_CORRECAO.md`

**Output**:
- Arquivo: `RELATORIO_VALIDACAO_E2E_POS_CORRECAO.md`
- Formato: Markdown estruturado com:
  - SumÃ¡rio executivo
  - AnÃ¡lise passo a passo
  - MÃ©tricas comparativas
  - EvidÃªncias de logs
  - ConclusÃ£o e recomendaÃ§Ãµes

---

## Fluxo de Trabalho Completo

### Passo 1: Preparar Ambiente

```bash
# Verificar conectividade com cluster
kubectl cluster-info

# Verificar pods estÃ£o rodando
kubectl get pods -A | grep -E "gateway|semantic|consensus|specialist|memory"

# Verificar versÃµes das imagens (deve ser 1.0.9)
kubectl get pods -n default -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\n' | grep -E 'consensus-engine|specialist'
```

### Passo 2: Executar ValidaÃ§Ã£o

```bash
cd /jimy/Neural-Hive-Mind
./scripts/validation/execute-e2e-validation-v1.0.9.sh
```

**Tempo estimado**: 2-3 minutos

### Passo 3: Gerar RelatÃ³rio

```bash
# Usar o diretÃ³rio de output exibido no passo anterior
OUTPUT_DIR="logs/validation-e2e-v1.0.9-<timestamp>"
./scripts/validation/generate-e2e-report-v1.0.9.sh $OUTPUT_DIR
```

**Tempo estimado**: 30 segundos

### Passo 4: Revisar Resultados

```bash
# Ver resumo
cat $OUTPUT_DIR/SUMMARY.txt

# Ver relatÃ³rio completo
cat RELATORIO_VALIDACAO_E2E_POS_CORRECAO.md

# Ou abrir em editor markdown
code RELATORIO_VALIDACAO_E2E_POS_CORRECAO.md
```

---

## CritÃ©rios de Sucesso

### ValidaÃ§Ã£o v1.0.9 - Objetivos

1. âœ… **0 TypeErrors de timestamp**
   - ValidaÃ§Ãµes defensivas em `specialists_grpc_client.py` devem prevenir erros
   - Buscar nos logs: "TypeError", "AttributeError", "evaluated_at"
   - Esperado: 0 ocorrÃªncias

2. âœ… **5/5 specialists respondendo**
   - Todos os 5 specialists devem responder sem timeout
   - Buscar nos logs: "EvaluatePlan completed successfully"
   - Esperado: 5 ocorrÃªncias

3. âœ… **MongoDB persistence funcionando**
   - DecisÃ£o de consenso deve ser salva no ledger
   - Buscar nos logs: "DecisÃ£o salva no ledger" ou "save_consensus_decision"
   - Esperado: 1 ocorrÃªncia

4. âœ… **Memory Layer API operacional**
   - Dados devem ser recuperÃ¡veis via query
   - Verificar: HTTP 200 + dados completos no response
   - Esperado: Query bem-sucedida

5. âœ… **Pipeline E2E completo**
   - Todos os 7 passos devem passar
   - Taxa de sucesso: 100%
   - Esperado: 7/7 passos PASS

---

## Troubleshooting

### Problema: Script nÃ£o encontra pods

**Sintoma**: "Nenhum pod encontrado para gateway-intencoes"

**SoluÃ§Ã£o**:
```bash
# Verificar namespaces corretos
kubectl get pods -A | grep gateway

# Ajustar variÃ¡vel NAMESPACE no script se necessÃ¡rio
```

### Problema: Timeout ao enviar intent

**Sintoma**: "Timeout ao conectar ao gateway"

**SoluÃ§Ã£o**:
```bash
# Verificar se gateway estÃ¡ rodando
kubectl get pods -n gateway-intencoes

# Verificar logs do gateway
kubectl logs -n gateway-intencoes -l app=gateway-intencoes --tail=50

# Tentar port-forward
kubectl port-forward -n gateway-intencoes svc/gateway-intencoes 8000:8000
```

### Problema: Specialists nÃ£o respondem

**Sintoma**: "Pareceres insuficientes: 2/5"

**SoluÃ§Ã£o**:
```bash
# Verificar se specialists estÃ£o rodando
kubectl get pods -A | grep specialist

# Verificar logs de um specialist
kubectl logs -n specialist-business -l app=specialist-business --tail=100

# Verificar conectividade gRPC
kubectl exec -n default consensus-engine-XXX -- nc -zv specialist-business.specialist-business.svc.cluster.local 50051
```

### Problema: Memory Layer API nÃ£o retorna dados

**Sintoma**: "HTTP 404 - Intent not found"

**SoluÃ§Ã£o**:
```bash
# Verificar se Memory Layer estÃ¡ rodando
kubectl get pods -n memory-layer-api

# Verificar readiness
kubectl exec -n memory-layer-api memory-layer-api-XXX -- curl -s http://localhost:8000/ready

# Verificar MongoDB estÃ¡ conectado
kubectl logs -n memory-layer-api -l app=memory-layer-api --tail=50 | grep -i mongodb

# Aguardar mais tempo (dados podem levar 30-60s para serem indexados)
sleep 60
```

---

## ComparaÃ§Ã£o com ValidaÃ§Ã£o Anterior

### v1.0.7 (Baseline)

- **Taxa de Sucesso**: 62.5% (5/8 passos)
- **Bloqueio**: Timeout em 3/5 specialists
- **Specialists Response Rate**: 40% (2/5)
- **MongoDB**: â¸ï¸ NÃ£o testado
- **Memory Layer**: â¸ï¸ NÃ£o testado
- **TypeErrors**: N/A (problema nÃ£o identificado ainda)

### v1.0.9 (Atual)

- **Taxa de Sucesso**: [A ser determinado]
- **Bloqueio**: [A ser determinado]
- **Specialists Response Rate**: [A ser determinado]
- **MongoDB**: [A ser testado]
- **Memory Layer**: [A ser testado]
- **TypeErrors**: 0 (esperado - validaÃ§Ãµes defensivas implementadas)

**Objetivo**: AlcanÃ§ar 100% de sucesso com 0 erros de timestamp

---

## ReferÃªncias

- **Guia de ValidaÃ§Ã£o Manual**: `../../VALIDACAO_E2E_MANUAL.md`
- **RelatÃ³rio Anterior**: `../../RELATORIO_VALIDACAO_E2E.md`
- **AnÃ¡lise de Debug**: `../../ANALISE_DEBUG_GRPC_TYPEERROR.md`
- **CorreÃ§Ãµes v1.0.9**: `../../RELATORIO_SESSAO_CORRECAO_V1.0.9.md`
- **CÃ³digo Relevante**:
  - `../../services/consensus-engine/src/clients/specialists_grpc_client.py`
  - `../../libraries/python/neural_hive_specialists/grpc_server.py`
  - `../../services/consensus-engine/src/consumers/plan_consumer.py`

---

**Ãšltima AtualizaÃ§Ã£o**: 2025-11-10
**VersÃ£o**: 1.0.0
**Autor**: Neural Hive-Mind Team
