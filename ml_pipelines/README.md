# ML Pipeline - Neural Hive Mind Specialist Models

## 1. Vis√£o Geral

O Neural Hive Mind utiliza um pipeline de Machine Learning para treinar e gerenciar modelos de avalia√ß√£o para 5 especialistas distintos:

- **Technical Specialist**: Avalia viabilidade t√©cnica e complexidade de implementa√ß√£o
- **Business Specialist**: Analisa valor de neg√≥cio, ROI e alinhamento estrat√©gico
- **Behavior Specialist**: Avalia UX, comportamento do usu√°rio e usabilidade
- **Evolution Specialist**: Analisa escalabilidade, manutenibilidade e d√©bito t√©cnico
- **Architecture Specialist**: Avalia design de arquitetura, padr√µes e integra√ß√£o

### Arquitetura de Treinamento/Infer√™ncia

Cada especialista utiliza modelos de Machine Learning (Random Forest, Gradient Boosting ou Neural Networks) para avaliar planos cognitivos e emitir opini√µes estruturadas. Os modelos s√£o:

- **Treinados** com datasets sint√©ticos gerados por LLMs (GPT-4, Claude, Ollama)
- **Versionados** e **rastreados** no MLflow Model Registry
- **Promovidos** automaticamente quando atingem thresholds de qualidade
- **Carregados** em runtime pelos pods de especialistas via `mlflow_client.py`
- **Validados** continuamente com feedback humano (continuous learning)

## 2. Quick Start

### CLI Unificado (Recomendado)

O CLI `ml.sh` consolida todas as operacoes ML em um unico ponto de entrada:

```bash
# Gerar datasets
./ml.sh generate-dataset --all

# Treinar todos os modelos
./ml.sh train --all

# Validar modelos
./ml.sh validate --all

# Verificar status
./ml.sh status --all --verbose

# Promover modelo
./ml.sh promote --model technical-evaluator --version 3

# Re-treinar com feedback
./ml.sh retrain --specialist business --hyperparameter-tuning

# Rollback
./ml.sh rollback --specialist evolution --reason "Alta latencia"
```

### Scripts Individuais (Legado)

> **AVISO**: Os scripts individuais estao sendo descontinuados. Use `ml.sh` acima.

```bash
# Gerar Datasets com IA
cd ml_pipelines/training
./generate_all_datasets.sh

# Treinar Todos os Modelos
./train_all_specialists.sh

# Validar Modelos Carregados
./validate_models_loaded.sh

# Verificar Status dos Modelos
cd ml_pipelines/scripts
./check_model_status.sh --all
```

### Mapeamento de Scripts Antigos para CLI

| Script Antigo | Comando Novo |
|---------------|--------------|
| `train_all_specialists.sh` | `ml.sh train --all` |
| `train_specialist_model.py --specialist-type TYPE` | `ml.sh train --specialist TYPE` |
| `retrain_specialist.sh --specialist TYPE` | `ml.sh retrain --specialist TYPE` |
| `check_model_status.sh --all` | `ml.sh status --all` |
| `rollback_model.sh --specialist TYPE` | `ml.sh rollback --specialist TYPE` |
| `generate_all_datasets.sh` | `ml.sh generate-dataset --all` |
| `validate_models_loaded.sh` | `ml.sh validate --all` |

## 3. Gera√ß√£o de Datasets com IA

Os datasets de treinamento s√£o gerados **sinteticamente** usando LLMs (Large Language Models) para criar exemplos realistas de planos cognitivos e suas avalia√ß√µes esperadas.

### Providers Suportados

- **OpenAI** (GPT-4, GPT-3.5-turbo): Melhor qualidade, requer API key
- **Anthropic** (Claude): Alta qualidade, alternativa ao OpenAI
- **Ollama** (Llama 3, Mistral, etc.): Gratuito, execu√ß√£o local

### Estrutura de Features

Cada exemplo gerado cont√©m **26+ dimens√µes** de features estruturadas:

**Technical Features** (9):
- `complexity_score`, `technical_debt`, `code_quality`, `test_coverage`
- `performance_impact`, `security_risk`, `integration_complexity`
- `technical_feasibility`, `tech_stack_alignment`

**Business Features** (8):
- `business_value`, `roi_score`, `strategic_alignment`, `market_demand`
- `competitive_advantage`, `revenue_impact`, `cost_efficiency`, `customer_satisfaction`

**Behavioral Features** (5):
- `user_experience`, `accessibility`, `usability_score`, `user_engagement`
- `adoption_rate`

**Evolution Features** (4):
- `scalability`, `maintainability`, `extensibility`, `future_proof`

Veja [training/README_DATASET_GENERATION.md](training/README_DATASET_GENERATION.md) para detalhes completos sobre prompts, schemas e distribui√ß√£o de labels.

### Labels e Distribui√ß√£o Recomendada

Cada exemplo √© rotulado com uma das 4 recomenda√ß√µes:

- **approve** (40%): Plano de alta qualidade, pronto para execu√ß√£o
- **approve_with_conditions** (30%): Bom, mas requer ajustes menores
- **review_required** (20%): Necessita revis√£o mais profunda
- **reject** (10%): N√£o vi√°vel ou de baixa qualidade

### Comandos B√°sicos

```bash
# Gerar dataset para um especialista espec√≠fico
cd ml_pipelines/training
python3 generate_training_datasets.py \
  --specialist-type technical \
  --provider openai \
  --num-examples 1000

# Gerar todos os datasets de uma vez
./generate_all_datasets.sh
```

**Refer√™ncia completa**: [training/README_DATASET_GENERATION.md](training/README_DATASET_GENERATION.md)

## 4. Treinamento de Modelos

### Conven√ß√£o de Nomes

- **Modelos**: `{specialist_type}-evaluator` (ex: `technical-evaluator`)
- **Experimentos MLflow**: `{specialist_type}-specialist` (ex: `technical-specialist`)

### Thresholds de Promo√ß√£o

Para um modelo ser promovido automaticamente para **Production**, ele deve atingir:

| M√©trica | Threshold |
|---------|-----------|
| **Precision** | ‚â• 0.75 |
| **Recall** | ‚â• 0.70 |
| **F1 Score** | ‚â• 0.72 |
| **Improvement** | ‚â• 5% vs baseline |

Se j√° existe um modelo em Production, o novo modelo deve ser **pelo menos 5% melhor** em F1 score.

### Tipos de Modelos Suportados

- **random_forest** (default): Robusto, r√°pido, bom para features categ√≥ricas
- **gradient_boosting**: Melhor accuracy, mais lento
- **neural_network**: Para datasets grandes (>10k exemplos)

### Scripts Dispon√≠veis

#### Treinar Modelo Individual
```bash
cd ml_pipelines/training
python3 train_specialist_model.py \
  --specialist-type technical \
  --model-type random_forest \
  --hyperparameter-tuning
```

#### Treinar Todos os Especialistas
```bash
cd ml_pipelines/training
./train_all_specialists.sh
```

#### Re-treinar com Op√ß√µes Customizadas
```bash
cd ml_pipelines/scripts
./retrain_specialist.sh \
  --specialist technical \
  --model-type gradient_boosting \
  --hyperparameter-tuning
```

### Integra√ß√£o com MLflow

Durante o treinamento:

1. **Tracking**: M√©tricas, par√¢metros e artefatos s√£o logados no MLflow
2. **Model Registry**: Modelo √© registrado como `{specialist}-evaluator`
3. **Auto-promotion**: Se thresholds forem atingidos, modelo vai para **Production**
4. **Baseline Comparison**: Compara com vers√£o atual em Production (se existir)

Localiza√ß√£o: `http://mlflow.mlflow:5000`

## 5. Registro e Promo√ß√£o no MLflow

### Fluxo de Registro de Modelos

```mermaid
graph LR
    A[Train Model] --> B[Log to MLflow]
    B --> C[Register Model]
    C --> D{Meets Thresholds?}
    D -->|Yes| E[Promote to Production]
    D -->|No| F[Keep in Staging]
    E --> G[Archive Old Production]
```

### Stages do MLflow

- **Production**: Modelo ativo, carregado pelos especialistas em runtime
- **Staging**: Modelo candidato, aguardando promo√ß√£o
- **Archived**: Vers√µes antigas, preservadas para hist√≥rico/rollback

### Crit√©rios de Promo√ß√£o Autom√°tica

Um modelo √© promovido automaticamente se:

1. **Thresholds absolutos** s√£o atingidos (precision ‚â• 0.75, recall ‚â• 0.70, f1 ‚â• 0.72)
2. **Melhoria relativa** ‚â• 5% vs baseline (se j√° existe modelo em Production)
3. **Sem degrada√ß√£o** em nenhuma m√©trica cr√≠tica

### Promo√ß√£o Manual via MLflow UI

Se um modelo em Staging for promissor mas n√£o atingiu auto-promo√ß√£o:

```bash
# Port-forward para acessar MLflow UI
kubectl port-forward -n mlflow svc/mlflow 5000:5000

# Acesse http://localhost:5000
# Navegue at√© Models > {specialist}-evaluator > Version X
# Clique em "Transition to" > "Production"
```

### Localiza√ß√£o do MLflow

- **Namespace Kubernetes**: `mlflow`
- **Service**: `mlflow.mlflow:5000`
- **UI**: `http://mlflow.mlflow:5000` (dentro do cluster)
- **Port-forward**: `kubectl port-forward -n mlflow svc/mlflow 5000:5000`

## 6. Scripts de Manuten√ß√£o

Utilit√°rios bash em `ml_pipelines/scripts/` para opera√ß√µes comuns:

### check_model_status.sh

Verifica status de modelos no MLflow (vers√µes, stages, m√©tricas).

```bash
# Verificar todos os especialistas
./check_model_status.sh --all

# Verificar especialista espec√≠fico com detalhes
./check_model_status.sh --specialist technical --verbose

# Output JSON para parsing
./check_model_status.sh --all --format json
```

**Funcionalidades**:
- Lista vers√µes em Production, Staging, Archived
- Mostra m√©tricas (precision, recall, f1, accuracy)
- Compara vers√µes e recomenda promo√ß√£o
- Health check integrado (MLflow + pods K8s)

### retrain_specialist.sh

Re-treina especialista espec√≠fico com op√ß√µes customizadas.

```bash
# Re-treinar technical com defaults
./retrain_specialist.sh --specialist technical

# Re-treinar com hyperparameter tuning
./retrain_specialist.sh --specialist business \
  --hyperparameter-tuning \
  --model-type gradient_boosting

# For√ßar re-treino sem promo√ß√£o autom√°tica
./retrain_specialist.sh --specialist behavior \
  --force-retrain \
  --promote-if-better false
```

**Funcionalidades**:
- Pre-flight checks (MLflow, MongoDB, datasets)
- An√°lise de necessidade de re-treino
- Compara√ß√£o p√≥s-treinamento com baseline
- Logging e auditoria
- Sugest√£o de restart de pods

### rollback_model.sh

Faz rollback de modelo em Production para vers√£o anterior.

```bash
# Rollback para vers√£o anterior
./rollback_model.sh --specialist technical \
  --reason "High latency in production"

# Rollback para vers√£o espec√≠fica
./rollback_model.sh --specialist business \
  --to-version 3 \
  --reason "Regression in accuracy"

# Rollback de todos os especialistas (emerg√™ncia)
./rollback_model.sh --all \
  --reason "Emergency rollback after deployment"
```

**Funcionalidades**:
- Valida√ß√µes pr√©-rollback (vers√£o existe, m√©tricas)
- An√°lise de impacto (compara√ß√£o de m√©tricas)
- Confirma√ß√£o interativa (desabilit√°vel com `--force`)
- Auditoria completa (logs + tags no MLflow)
- Sugest√£o de restart de pods

## 7. Valida√ß√£o e Troubleshooting

### Validar Modelos Carregados

```bash
cd ml_pipelines/training
./validate_models_loaded.sh
```

Verifica se:
- Pods de especialistas est√£o rodando (1/1 Ready)
- Endpoint `/status` retorna `model_loaded: true`
- Vers√£o do modelo em mem√≥ria corresponde √† vers√£o em Production no MLflow

### Problemas Comuns e Solu√ß√µes

#### üî¥ MLflow N√£o Conectado

**Sintoma**: Logs mostram `Failed to connect to MLflow` ou timeout

**Diagn√≥stico**:
```bash
# Verificar se MLflow est√° rodando
kubectl get pods -n mlflow

# Testar conectividade
curl -f http://mlflow.mlflow:5000/health
```

**Solu√ß√£o**:
```bash
# Reiniciar MLflow
kubectl rollout restart deployment/mlflow -n mlflow

# Verificar logs
kubectl logs -n mlflow deployment/mlflow --tail=50
```

#### üî¥ Modelo N√£o Carregado pelo Especialista

**Sintoma**: `/status` retorna `model_loaded: false`

**Diagn√≥stico**:
```bash
# Verificar logs do especialista
kubectl logs -n semantic-translation deployment/specialist-technical --tail=100 | grep -i "model"

# Verificar se modelo existe no MLflow
ml_pipelines/scripts/check_model_status.sh --specialist technical
```

**Solu√ß√£o**:
```bash
# Reiniciar pod para for√ßar reload
kubectl rollout restart deployment/specialist-technical -n semantic-translation

# Verificar carregamento ap√≥s restart
ml_pipelines/training/validate_models_loaded.sh
```

#### üî¥ Specialist Technical 0/1 NOT READY

**Sintoma**: Pod nunca fica Ready, restart loops

**Diagn√≥stico**: Veja an√°lise completa em `/tmp/ANALISE_SPECIALIST_TECHNICAL.md`

**Causas Comuns**:
- Liveness probe falhando (MongoDB n√£o acess√≠vel)
- Model loading timeout
- Depend√™ncias faltando (protobuf, grpcio)

**Solu√ß√£o R√°pida**:
```bash
# Verificar eventos do pod
kubectl describe pod -n semantic-translation -l app=specialist-technical

# Verificar logs de startup
kubectl logs -n semantic-translation -l app=specialist-technical --tail=200

# Ajustar probes se necess√°rio (values.yaml)
```

#### üî¥ Datasets Ausentes

**Sintoma**: `train_specialist_model.py` falha com `FileNotFoundError`

**Solu√ß√£o**:
```bash
# Gerar datasets
cd ml_pipelines/training
./generate_all_datasets.sh

# Verificar arquivos gerados
ls -lh /data/training/specialist_*.parquet
```

### Comandos de Diagn√≥stico

```bash
# Status geral do cluster
kubectl get pods -A | grep -E "(mlflow|specialist|semantic)"

# Health checks de especialistas
for specialist in technical business behavior evolution architecture; do
  kubectl exec -n semantic-translation deployment/specialist-$specialist -- \
    curl -s http://localhost:8080/status | jq .
done

# Queries MLflow API
curl -s http://mlflow.mlflow:5000/api/2.0/mlflow/registered-models/list | jq .

# Logs de treinamento
tail -f ml_pipelines/scripts/logs/retrain_*.log
```

### Refer√™ncias de Troubleshooting

- [/tmp/ANALISE_SPECIALIST_TECHNICAL.md](../../tmp/ANALISE_SPECIALIST_TECHNICAL.md): An√°lise profunda do Specialist Technical NOT READY
- [OPERATIONAL_GUIDE.md](../OPERATIONAL_GUIDE.md): Guia operacional completo
- [docs/RESOURCE_TUNING_GUIDE.md](../docs/RESOURCE_TUNING_GUIDE.md): Tuning de recursos

## 8. An√°lise de Modelos

### Jupyter Notebook

An√°lise explorat√≥ria interativa dispon√≠vel em:

```
ml_pipelines/notebooks/model_analysis.ipynb
```

**Funcionalidades**:

- **Status Atual**: Tabela com vers√µes, stages e m√©tricas de todos os especialistas
- **Compara√ß√£o de Vers√µes**: Production vs Staging com c√°lculo de deltas
- **Evolu√ß√£o Temporal**: Line plots mostrando evolu√ß√£o de m√©tricas ao longo das vers√µes
- **Feature Importance**: Top 15 features mais importantes (para modelos tree-based)
- **Confusion Matrix**: Heatmap de confusion matrix por especialista
- **Distribui√ß√£o de Predi√ß√µes**: Histogramas de confidence e risk scores
- **Compara√ß√£o Cross-Specialist**: Boxplots e correla√ß√µes entre especialistas
- **Feedback Humano**: Agreement rate (human vs model) ao longo do tempo
- **Recomenda√ß√µes Automatizadas**: Lista priorizada de a√ß√µes (retrain, promote, rollback)
- **Export de Relat√≥rio**: Gera HTML com todos os plots e tabelas

### Executar Notebook

```bash
# Instalar Jupyter (se n√£o instalado)
pip install jupyter pandas matplotlib seaborn mlflow scikit-learn

# Iniciar Jupyter
cd ml_pipelines/notebooks
jupyter notebook model_analysis.ipynb

# Port-forward MLflow (se necess√°rio)
kubectl port-forward -n mlflow svc/mlflow 5000:5000
```

### Relat√≥rios Gerados

Relat√≥rios HTML s√£o salvos em:

```
ml_pipelines/notebooks/reports/model_analysis_{timestamp}.html
```

Incluem:
- Timestamp de gera√ß√£o
- Vers√µes analisadas
- Plots interativos
- Tabelas de m√©tricas
- Recomenda√ß√µes priorizadas

## 9. Integra√ß√£o com Kubernetes

### Como Modelos S√£o Carregados

Os pods de especialistas carregam modelos em runtime via `mlflow_client.py`:

```python
from neural_hive_specialists.mlflow_client import MLflowClient

client = MLflowClient(
    tracking_uri="http://mlflow.mlflow:5000",
    model_name="technical-evaluator"
)

# Carrega modelo em Production
model = client.load_production_model()
```

**Fluxo**:
1. Pod inicia, `mlflow_client.py` √© inicializado
2. Query MLflow API para buscar vers√£o em Production
3. Download do modelo (pickle) para `/tmp/mlflow_cache/`
4. Carregamento em mem√≥ria com circuit breaker
5. Cache v√°lido por 1h (configur√°vel)
6. Fallback para cache expirado se MLflow n√£o acess√≠vel

### Health Checks

Especialistas exp√µem endpoints para valida√ß√£o:

#### /status
```bash
curl http://specialist-technical.semantic-translation:8080/status
```

Retorna:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_version": "5",
  "model_name": "technical-evaluator",
  "last_model_update": "2025-01-15T10:30:00Z",
  "cache_valid": true
}
```

#### /ready
```bash
curl http://specialist-technical.semantic-translation:8080/ready
```

Usado por Kubernetes readiness probe. Retorna 200 se modelo carregado.

### Reiniciar Pods para For√ßar Reload

Ap√≥s promo√ß√£o de um novo modelo ou rollback:

```bash
# Reiniciar especialista espec√≠fico
kubectl rollout restart deployment/specialist-technical -n semantic-translation

# Reiniciar todos os especialistas
for specialist in technical business behavior evolution architecture; do
  kubectl rollout restart deployment/specialist-$specialist -n semantic-translation
done

# Verificar reload
ml_pipelines/training/validate_models_loaded.sh
```

### Namespace

Todos os especialistas rodam no namespace:

```
semantic-translation
```

**Deployments**:
- `specialist-technical`
- `specialist-business`
- `specialist-behavior`
- `specialist-evolution`
- `specialist-architecture`

## 10. Arquitetura e Fluxo

### Fluxo de Gera√ß√£o de Datasets

```mermaid
graph LR
    A[LLM Provider] -->|Prompt| B[generate_training_datasets.py]
    B -->|JSON Response| C[Feature Extraction]
    C -->|26+ dimensions| D[Parquet File]
    D --> E[/data/training/specialist_*.parquet]
```

**Providers**: OpenAI GPT-4, Anthropic Claude, Ollama Llama 3

### Fluxo de Treinamento

```mermaid
graph LR
    A[Dataset Parquet] --> B[train_specialist_model.py]
    B --> C[Train Model]
    C --> D[Evaluate Metrics]
    D --> E{Meets Thresholds?}
    E -->|Yes| F[Register in MLflow]
    F --> G[Promote to Production]
    E -->|No| H[Keep in Staging]
    G --> I[Archive Old Version]
```

**Models**: Random Forest, Gradient Boosting, Neural Network

### Fluxo de Infer√™ncia

```mermaid
graph LR
    A[Cognitive Plan] --> B[Specialist Pod]
    B --> C[mlflow_client.py]
    C --> D{Model in Cache?}
    D -->|Yes| E[Load from Cache]
    D -->|No| F[Query MLflow API]
    F --> G[Download Model]
    G --> H[Cache Model]
    H --> E
    E --> I[Predict]
    I --> J[Specialist Opinion]
```

**Circuit Breaker**: Fallback para cache expirado se MLflow n√£o acess√≠vel

### Pipeline Completo (End-to-End)

```mermaid
graph TB
    subgraph "Data Generation"
        A[LLM Provider] --> B[Synthetic Dataset]
    end

    subgraph "Training"
        B --> C[Train Model]
        C --> D[Evaluate]
        D --> E[MLflow Registry]
    end

    subgraph "Deployment"
        E --> F[Production Stage]
        F --> G[Specialist Pods]
    end

    subgraph "Inference"
        H[Cognitive Plan] --> G
        G --> I[Model Prediction]
        I --> J[Specialist Opinion]
    end

    subgraph "Continuous Learning"
        J --> K[Human Feedback]
        K --> L[MongoDB Feedback Collection]
        L --> M[Retrain with Feedback]
        M --> C
    end
```

## 11. Monitoramento de Performance & Auto-Retrain

Sistema automatizado de monitoramento de performance de modelos e retreinamento baseado em degrada√ß√£o detectada.

### Componentes

- **ModelPerformanceMonitor**: Consulta m√©tricas MLflow e feedback MongoDB
- **AutoRetrainOrchestrator**: Trigger dataset generation e retreinamento autom√°tico
- **K8s CronJob**: Execu√ß√£o automatizada a cada 6 horas

### Quick Start

```bash
# Verificar performance de um specialist
python ml_pipelines/monitoring/model_performance_monitor.py --specialist-type technical

# Trigger auto-retrain (se necess√°rio)
python ml_pipelines/monitoring/auto_retrain.py --specialist-type technical

# Deploy CronJob automatizado
kubectl apply -f ml_pipelines/k8s/model-monitor-cronjob.yaml
```

### Thresholds

- **Precision**: ‚â• 0.75
- **Recall**: ‚â• 0.70
- **F1 Score**: ‚â• 0.72
- **Feedback Avg**: ‚â• 0.6

### Monitoramento

- **Dashboard**: Grafana ‚Üí "Continuous Learning - Feedback & Retraining"
- **Alertas**: Prometheus ‚Üí `model-performance-alerts.yaml`
- **Logs**: `kubectl logs -n ml-pipelines -l app=model-performance-monitor`

### Documenta√ß√£o

Consulte [monitoring/README.md](monitoring/README.md) para documenta√ß√£o completa sobre:
- Como funciona o monitoring flow e auto-retrain flow
- Configura√ß√£o de LLM providers (Ollama/OpenAI/Anthropic)
- Notifica√ß√µes Slack/Email
- Troubleshooting e problemas comuns
- Integra√ß√£o com sistemas existentes

---

## 12. Refer√™ncias

### Documenta√ß√£o Interna

- **[training/README_DATASET_GENERATION.md](training/README_DATASET_GENERATION.md)**: Documenta√ß√£o completa sobre gera√ß√£o de datasets com LLMs
- **[train_specialist_model.py](training/train_specialist_model.py)**: Script principal de treinamento (linhas 1-700+)
- **[libraries/python/neural_hive_specialists/mlflow_client.py](../libraries/python/neural_hive_specialists/mlflow_client.py)**: Cliente MLflow com circuit breaker e cache
- **[OPERATIONAL_GUIDE.md](../OPERATIONAL_GUIDE.md)**: Guia operacional completo do Neural Hive Mind
- **[CONTINUOUS_LEARNING_GUIDE.md](../CONTINUOUS_LEARNING_GUIDE.md)**: Continuous learning com feedback humano
- **[docs/ml/PREDICTIVE_MODELS_GUIDE.md](../docs/ml/PREDICTIVE_MODELS_GUIDE.md)**: Guia de modelos preditivos

### Schemas Avro

- **[schemas/avro/cognitive-plan.avsc](../schemas/avro/cognitive-plan.avsc)**: Schema de plano cognitivo (input para especialistas)
- **[schemas/avro/specialist-opinion.avsc](../schemas/avro/specialist-opinion.avsc)**: Schema de opini√£o de especialista (output dos modelos)

### Documenta√ß√£o Externa

- **[MLflow Documentation](https://mlflow.org/docs/latest/index.html)**: Documenta√ß√£o oficial do MLflow
- **[MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)**: Gerenciamento de modelos
- **[MLflow Tracking API](https://mlflow.org/docs/latest/tracking.html)**: API de tracking
- **[Scikit-learn Documentation](https://scikit-learn.org/stable/)**: Documenta√ß√£o do scikit-learn

### Scripts e Ferramentas

- **[scripts/check_model_status.sh](scripts/check_model_status.sh)**: Verificar status de modelos
- **[scripts/retrain_specialist.sh](scripts/retrain_specialist.sh)**: Re-treinar especialista
- **[scripts/rollback_model.sh](scripts/rollback_model.sh)**: Fazer rollback de modelo
- **[notebooks/model_analysis.ipynb](notebooks/model_analysis.ipynb)**: An√°lise explorat√≥ria de modelos
- **[training/validate_models_loaded.sh](training/validate_models_loaded.sh)**: Validar modelos carregados

---

**√öltima atualiza√ß√£o**: 2025-01-22
**Vers√£o**: 1.0.0
**Mantenedores**: Neural Hive Mind Team
