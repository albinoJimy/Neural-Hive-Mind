{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise de Modelos ML - Neural Hive Mind\n",
    "\n",
    "Notebook para an√°lise explorat√≥ria de modelos de especialistas treinados com MLflow.\n",
    "\n",
    "**Funcionalidades:**\n",
    "- Status atual de todos os especialistas\n",
    "- Compara√ß√£o de vers√µes (Production vs Staging)\n",
    "- Evolu√ß√£o temporal de m√©tricas\n",
    "- Feature importance\n",
    "- Confusion matrix\n",
    "- Recomenda√ß√µes automatizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de estilo\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Constantes\n",
    "MLFLOW_URI = 'http://mlflow.mlflow:5000'\n",
    "SPECIALISTS = ['technical', 'business', 'behavior', 'evolution', 'architecture']\n",
    "THRESHOLDS = {\n",
    "    'precision': 0.75,\n",
    "    'recall': 0.70,\n",
    "    'f1': 0.72,\n",
    "    'improvement': 0.05\n",
    "}\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "\n",
    "print(f\"MLflow Tracking URI: {MLFLOW_URI}\")\n",
    "print(f\"Specialists: {', '.join(SPECIALISTS)}\")\n",
    "print(f\"Thresholds: {THRESHOLDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_versions(specialist_type):\n",
    "    \"\"\"Buscar todas as vers√µes de um modelo no MLflow.\"\"\"\n",
    "    model_name = f\"{specialist_type}-evaluator\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    try:\n",
    "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        return versions\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar vers√µes de {model_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_model_metrics(run_id):\n",
    "    \"\"\"Extrair m√©tricas de um run espec√≠fico.\"\"\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    try:\n",
    "        run = client.get_run(run_id)\n",
    "        metrics = run.data.metrics\n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar m√©tricas do run {run_id}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def load_model_from_mlflow(model_name, version):\n",
    "    \"\"\"Carregar modelo espec√≠fico do MLflow.\"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}/{version}\"\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar modelo {model_name} v{version}: {e}\")\n",
    "        return None\n",
    "\n",
    "def compare_models(specialist_type, version1, version2):\n",
    "    \"\"\"Comparar m√©tricas entre duas vers√µes.\"\"\"\n",
    "    versions = get_model_versions(specialist_type)\n",
    "    \n",
    "    v1_metrics = None\n",
    "    v2_metrics = None\n",
    "    \n",
    "    for v in versions:\n",
    "        if v.version == str(version1):\n",
    "            v1_metrics = get_model_metrics(v.run_id)\n",
    "        if v.version == str(version2):\n",
    "            v2_metrics = get_model_metrics(v.run_id)\n",
    "    \n",
    "    return v1_metrics, v2_metrics\n",
    "\n",
    "def get_all_specialists_status():\n",
    "    \"\"\"Obter status de todos os especialistas.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for specialist in SPECIALISTS:\n",
    "        versions = get_model_versions(specialist)\n",
    "        \n",
    "        prod_version = None\n",
    "        staging_version = None\n",
    "        prod_metrics = {}\n",
    "        last_updated = None\n",
    "        \n",
    "        for v in versions:\n",
    "            if v.current_stage == 'Production':\n",
    "                prod_version = v.version\n",
    "                prod_metrics = get_model_metrics(v.run_id)\n",
    "                last_updated = datetime.fromtimestamp(v.last_updated_timestamp / 1000)\n",
    "            elif v.current_stage == 'Staging':\n",
    "                staging_version = v.version\n",
    "        \n",
    "        data.append({\n",
    "            'Specialist': specialist,\n",
    "            'Production Version': prod_version or 'N/A',\n",
    "            'Staging Version': staging_version or 'N/A',\n",
    "            'Precision': prod_metrics.get('precision', 0),\n",
    "            'Recall': prod_metrics.get('recall', 0),\n",
    "            'F1': prod_metrics.get('f1', 0),\n",
    "            'Accuracy': prod_metrics.get('accuracy', 0),\n",
    "            'Last Updated': last_updated or 'N/A'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"Fun√ß√µes auxiliares carregadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lise de Status Atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter status de todos os especialistas\n",
    "status_df = get_all_specialists_status()\n",
    "\n",
    "# Aplicar formata√ß√£o de cores baseado em thresholds\n",
    "def highlight_metrics(row):\n",
    "    colors = []\n",
    "    for col in row.index:\n",
    "        if col == 'Precision':\n",
    "            colors.append('background-color: lightgreen' if row[col] >= THRESHOLDS['precision'] else 'background-color: lightyellow')\n",
    "        elif col == 'Recall':\n",
    "            colors.append('background-color: lightgreen' if row[col] >= THRESHOLDS['recall'] else 'background-color: lightyellow')\n",
    "        elif col == 'F1':\n",
    "            colors.append('background-color: lightgreen' if row[col] >= THRESHOLDS['f1'] else 'background-color: lightyellow')\n",
    "        else:\n",
    "            colors.append('')\n",
    "    return colors\n",
    "\n",
    "display(status_df.style.apply(highlight_metrics, axis=1))\n",
    "\n",
    "# Identificar especialistas com modelos desatualizados\n",
    "print(\"\\n=== Modelos Desatualizados (> 30 dias) ===\")\n",
    "for idx, row in status_df.iterrows():\n",
    "    if row['Last Updated'] != 'N/A':\n",
    "        days_old = (datetime.now() - row['Last Updated']).days\n",
    "        if days_old > 30:\n",
    "            print(f\"‚ö†Ô∏è  {row['Specialist']}: {days_old} dias desde √∫ltima atualiza√ß√£o\")\n",
    "\n",
    "# Identificar especialistas abaixo dos thresholds\n",
    "print(\"\\n=== Modelos Abaixo dos Thresholds ===\")\n",
    "for idx, row in status_df.iterrows():\n",
    "    issues = []\n",
    "    if row['Precision'] < THRESHOLDS['precision']:\n",
    "        issues.append(f\"Precision ({row['Precision']:.3f} < {THRESHOLDS['precision']})\")\n",
    "    if row['Recall'] < THRESHOLDS['recall']:\n",
    "        issues.append(f\"Recall ({row['Recall']:.3f} < {THRESHOLDS['recall']})\")\n",
    "    if row['F1'] < THRESHOLDS['f1']:\n",
    "        issues.append(f\"F1 ({row['F1']:.3f} < {THRESHOLDS['f1']})\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"‚ö†Ô∏è  {row['Specialist']}: {', '.join(issues)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compara√ß√£o de Vers√µes (Production vs Staging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar Production vs Staging para cada especialista\n",
    "for specialist in SPECIALISTS:\n",
    "    versions = get_model_versions(specialist)\n",
    "    \n",
    "    prod_version = None\n",
    "    staging_version = None\n",
    "    prod_metrics = None\n",
    "    staging_metrics = None\n",
    "    \n",
    "    for v in versions:\n",
    "        if v.current_stage == 'Production':\n",
    "            prod_version = v.version\n",
    "            prod_metrics = get_model_metrics(v.run_id)\n",
    "        elif v.current_stage == 'Staging':\n",
    "            staging_version = v.version\n",
    "            staging_metrics = get_model_metrics(v.run_id)\n",
    "    \n",
    "    if prod_metrics and staging_metrics:\n",
    "        print(f\"\\n=== {specialist.upper()} - Production v{prod_version} vs Staging v{staging_version} ===\")\n",
    "        \n",
    "        # Criar dataframe de compara√ß√£o\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Production': [prod_metrics.get(m, 0) for m in ['precision', 'recall', 'f1', 'accuracy']],\n",
    "            'Staging': [staging_metrics.get(m, 0) for m in ['precision', 'recall', 'f1', 'accuracy']]\n",
    "        }, index=['Precision', 'Recall', 'F1', 'Accuracy'])\n",
    "        \n",
    "        # Calcular deltas\n",
    "        comparison_df['Delta'] = comparison_df['Staging'] - comparison_df['Production']\n",
    "        comparison_df['Delta %'] = (comparison_df['Delta'] / comparison_df['Production'] * 100).round(2)\n",
    "        \n",
    "        display(comparison_df)\n",
    "        \n",
    "        # Gr√°fico de barras\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        comparison_df[['Production', 'Staging']].plot(kind='bar', ax=ax)\n",
    "        ax.set_title(f'{specialist.capitalize()} - Production vs Staging')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Recomenda√ß√£o\n",
    "        f1_improvement = comparison_df.loc['F1', 'Delta %']\n",
    "        if f1_improvement > 5:\n",
    "            print(f\"‚úÖ RECOMENDA√á√ÉO: Promover Staging para Production (+{f1_improvement:.1f}% F1)\")\n",
    "        elif f1_improvement < -5:\n",
    "            print(f\"‚ö†Ô∏è  ATEN√á√ÉO: Staging √© PIOR que Production ({f1_improvement:.1f}% F1)\")\n",
    "    elif prod_metrics and not staging_metrics:\n",
    "        print(f\"\\n=== {specialist.upper()} - Apenas Production dispon√≠vel ===\")\n",
    "    elif not prod_metrics:\n",
    "        print(f\"\\n=== {specialist.upper()} - Nenhum modelo em Production ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evolu√ß√£o Temporal de M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada especialista, plotar evolu√ß√£o de m√©tricas\n",
    "for specialist in SPECIALISTS:\n",
    "    versions = get_model_versions(specialist)\n",
    "    \n",
    "    if not versions:\n",
    "        print(f\"Nenhuma vers√£o encontrada para {specialist}\")\n",
    "        continue\n",
    "    \n",
    "    # Ordenar por vers√£o\n",
    "    versions_sorted = sorted(versions, key=lambda x: int(x.version))\n",
    "    \n",
    "    # Coletar m√©tricas\n",
    "    data = []\n",
    "    for v in versions_sorted:\n",
    "        metrics = get_model_metrics(v.run_id)\n",
    "        data.append({\n",
    "            'Version': int(v.version),\n",
    "            'Precision': metrics.get('precision', 0),\n",
    "            'Recall': metrics.get('recall', 0),\n",
    "            'F1': metrics.get('f1', 0),\n",
    "            'Accuracy': metrics.get('accuracy', 0),\n",
    "            'Stage': v.current_stage\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    ax.plot(df['Version'], df['Precision'], marker='o', label='Precision', linewidth=2)\n",
    "    ax.plot(df['Version'], df['Recall'], marker='s', label='Recall', linewidth=2)\n",
    "    ax.plot(df['Version'], df['F1'], marker='^', label='F1', linewidth=2)\n",
    "    ax.plot(df['Version'], df['Accuracy'], marker='d', label='Accuracy', linewidth=2)\n",
    "    \n",
    "    # Marcar vers√µes em Production\n",
    "    prod_versions = df[df['Stage'] == 'Production']\n",
    "    for idx, row in prod_versions.iterrows():\n",
    "        ax.axvline(x=row['Version'], color='green', linestyle='--', alpha=0.3)\n",
    "        ax.text(row['Version'], 0.95, f\"v{row['Version']}\\n(Prod)\", \n",
    "                ha='center', va='top', fontsize=8, color='green')\n",
    "    \n",
    "    # Thresholds\n",
    "    ax.axhline(y=THRESHOLDS['precision'], color='red', linestyle=':', alpha=0.5, label='Precision Threshold')\n",
    "    ax.axhline(y=THRESHOLDS['recall'], color='orange', linestyle=':', alpha=0.5, label='Recall Threshold')\n",
    "    ax.axhline(y=THRESHOLDS['f1'], color='purple', linestyle=':', alpha=0.5, label='F1 Threshold')\n",
    "    \n",
    "    ax.set_xlabel('Version')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(f'{specialist.capitalize()} - Evolu√ß√£o de M√©tricas')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # An√°lise de tend√™ncia\n",
    "    if len(df) >= 3:\n",
    "        recent_f1 = df.tail(3)['F1'].mean()\n",
    "        older_f1 = df.head(3)['F1'].mean()\n",
    "        trend = (recent_f1 - older_f1) / older_f1 * 100 if older_f1 > 0 else 0\n",
    "        \n",
    "        if trend > 5:\n",
    "            print(f\"üìà {specialist}: Tend√™ncia de MELHORIA (+{trend:.1f}% F1)\")\n",
    "        elif trend < -5:\n",
    "            print(f\"üìâ {specialist}: Tend√™ncia de DEGRADA√á√ÉO ({trend:.1f}% F1)\")\n",
    "        else:\n",
    "            print(f\"‚û°Ô∏è  {specialist}: Tend√™ncia EST√ÅVEL\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lise de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelos em Production e extrair feature importance\n",
    "for specialist in SPECIALISTS:\n",
    "    model_name = f\"{specialist}-evaluator\"\n",
    "    \n",
    "    # Buscar vers√£o em Production\n",
    "    versions = get_model_versions(specialist)\n",
    "    prod_version = None\n",
    "    \n",
    "    for v in versions:\n",
    "        if v.current_stage == 'Production':\n",
    "            prod_version = v.version\n",
    "            break\n",
    "    \n",
    "    if not prod_version:\n",
    "        print(f\"Nenhum modelo em Production para {specialist}\")\n",
    "        continue\n",
    "    \n",
    "    # Carregar modelo\n",
    "    model = load_model_from_mlflow(model_name, prod_version)\n",
    "    \n",
    "    if model is None:\n",
    "        print(f\"Falha ao carregar modelo {model_name} v{prod_version}\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar se modelo tem feature_importances_\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Feature names (assumindo 26 features padr√£o)\n",
    "        feature_names = [\n",
    "            'complexity_score', 'technical_debt', 'code_quality', 'test_coverage',\n",
    "            'performance_impact', 'security_risk', 'integration_complexity',\n",
    "            'technical_feasibility', 'tech_stack_alignment',\n",
    "            'business_value', 'roi_score', 'strategic_alignment', 'market_demand',\n",
    "            'competitive_advantage', 'revenue_impact', 'cost_efficiency', 'customer_satisfaction',\n",
    "            'user_experience', 'accessibility', 'usability_score', 'user_engagement', 'adoption_rate',\n",
    "            'scalability', 'maintainability', 'extensibility', 'future_proof'\n",
    "        ]\n",
    "        \n",
    "        # Limitar ao n√∫mero de features do modelo\n",
    "        feature_names = feature_names[:len(importances)]\n",
    "        \n",
    "        # Criar dataframe\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Top 15\n",
    "        top_15 = importance_df.head(15)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.barh(top_15['Feature'], top_15['Importance'], color='steelblue')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title(f'{specialist.capitalize()} - Top 15 Features')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nTop 5 features para {specialist}:\")\n",
    "        for idx, row in top_15.head(5).iterrows():\n",
    "            print(f\"  {row['Feature']}: {row['Importance']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Modelo {specialist} n√£o suporta feature_importances_ (pode ser neural network)\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Recomenda√ß√µes Automatizadas"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations():\n",
    "    \"\"\"Gerar lista de recomenda√ß√µes automatizadas.\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    for specialist in SPECIALISTS:\n",
    "        versions = get_model_versions(specialist)\n",
    "        \n",
    "        prod_version = None\n",
    "        staging_version = None\n",
    "        prod_metrics = None\n",
    "        staging_metrics = None\n",
    "        prod_timestamp = None\n",
    "        \n",
    "        for v in versions:\n",
    "            if v.current_stage == 'Production':\n",
    "                prod_version = v.version\n",
    "                prod_metrics = get_model_metrics(v.run_id)\n",
    "                prod_timestamp = datetime.fromtimestamp(v.last_updated_timestamp / 1000)\n",
    "            elif v.current_stage == 'Staging':\n",
    "                staging_version = v.version\n",
    "                staging_metrics = get_model_metrics(v.run_id)\n",
    "        \n",
    "        # Verificar se modelo existe em Production\n",
    "        if not prod_metrics:\n",
    "            recommendations.append({\n",
    "                'severity': 'critical',\n",
    "                'specialist': specialist,\n",
    "                'message': f\"CRITICAL: Nenhum modelo em Production para {specialist}\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Verificar thresholds\n",
    "        precision = prod_metrics.get('precision', 0)\n",
    "        recall = prod_metrics.get('recall', 0)\n",
    "        f1 = prod_metrics.get('f1', 0)\n",
    "        \n",
    "        if precision < THRESHOLDS['precision']:\n",
    "            recommendations.append({\n",
    "                'severity': 'high',\n",
    "                'specialist': specialist,\n",
    "                'message': f\"Retrain {specialist}: precision abaixo do threshold ({precision:.3f} < {THRESHOLDS['precision']})\"\n",
    "            })\n",
    "        \n",
    "        if recall < THRESHOLDS['recall']:\n",
    "            recommendations.append({\n",
    "                'severity': 'high',\n",
    "                'specialist': specialist,\n",
    "                'message': f\"Retrain {specialist}: recall abaixo do threshold ({recall:.3f} < {THRESHOLDS['recall']})\"\n",
    "            })\n",
    "        \n",
    "        if f1 < THRESHOLDS['f1']:\n",
    "            recommendations.append({\n",
    "                'severity': 'high',\n",
    "                'specialist': specialist,\n",
    "                'message': f\"Retrain {specialist}: F1 abaixo do threshold ({f1:.3f} < {THRESHOLDS['f1']})\"\n",
    "            })\n",
    "        \n",
    "        # Verificar se modelo est√° desatualizado\n",
    "        if prod_timestamp:\n",
    "            days_old = (datetime.now() - prod_timestamp).days\n",
    "            if days_old > 45:\n",
    "                recommendations.append({\n",
    "                    'severity': 'medium',\n",
    "                    'specialist': specialist,\n",
    "                    'message': f\"Update {specialist}: modelo desatualizado ({days_old} dias desde √∫ltima atualiza√ß√£o)\"\n",
    "                })\n",
    "        \n",
    "        # Comparar com Staging\n",
    "        if staging_metrics and prod_metrics:\n",
    "            staging_f1 = staging_metrics.get('f1', 0)\n",
    "            prod_f1 = prod_metrics.get('f1', 0)\n",
    "            \n",
    "            if prod_f1 > 0:\n",
    "                improvement = (staging_f1 - prod_f1) / prod_f1 * 100\n",
    "                \n",
    "                if improvement > 8:\n",
    "                    recommendations.append({\n",
    "                        'severity': 'high',\n",
    "                        'specialist': specialist,\n",
    "                        'message': f\"Promote {specialist} Staging to Production: +{improvement:.1f}% improvement in F1\"\n",
    "                    })\n",
    "                elif improvement < -5:\n",
    "                    recommendations.append({\n",
    "                        'severity': 'medium',\n",
    "                        'specialist': specialist,\n",
    "                        'message': f\"Rollback {specialist}: Staging √© PIOR que Production ({improvement:.1f}% F1)\"\n",
    "                    })\n",
    "    \n",
    "    # Ordenar por severidade\n",
    "    severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}\n",
    "    recommendations.sort(key=lambda x: severity_order[x['severity']])\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Gerar e exibir recomenda√ß√µes\n",
    "recommendations = generate_recommendations()\n",
    "\n",
    "print(\"\\n=== RECOMENDA√á√ïES AUTOMATIZADAS ===\")\n",
    "print(f\"Total: {len(recommendations)} recomenda√ß√µes\\n\")\n",
    "\n",
    "for rec in recommendations:\n",
    "    severity_emoji = {\n",
    "        'critical': 'üî¥',\n",
    "        'high': 'üü†',\n",
    "        'medium': 'üü°',\n",
    "        'low': 'üîµ'\n",
    "    }\n",
    "    \n",
    "    print(f\"{severity_emoji[rec['severity']]} [{rec['severity'].upper()}] {rec['message']}\")\n",
    "\n",
    "if not recommendations:\n",
    "    print(\"‚úÖ Nenhuma recomenda√ß√£o - todos os modelos est√£o OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "## 12. Export de Relat√≥rio HTML",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. An√°lise de Feedback Humano (se dispon√≠vel)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Agregar m√©tricas de todos os especialistas e fazer an√°lise comparativa\nmetrics_data = []\n\nfor specialist in SPECIALISTS:\n    versions = get_model_versions(specialist)\n    \n    prod_version = None\n    prod_metrics = {}\n    \n    for v in versions:\n        if v.current_stage == 'Production':\n            prod_version = v.version\n            prod_metrics = get_model_metrics(v.run_id)\n            break\n    \n    if prod_metrics:\n        metrics_data.append({\n            'Specialist': specialist,\n            'Precision': prod_metrics.get('precision', 0),\n            'Recall': prod_metrics.get('recall', 0),\n            'F1': prod_metrics.get('f1', 0),\n            'Accuracy': prod_metrics.get('accuracy', 0)\n        })\n\n# Criar DataFrame agregado\ncross_df = pd.DataFrame(metrics_data)\n\nif not cross_df.empty:\n    print(\"=== M√©tricas Agregadas de Todos os Especialistas ===\")\n    display(cross_df)\n    \n    # Boxplot de m√©tricas\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    metrics_to_plot = ['Precision', 'Recall', 'F1', 'Accuracy']\n    colors = ['steelblue', 'coral', 'lightgreen', 'gold']\n    \n    for idx, metric in enumerate(metrics_to_plot):\n        ax = axes[idx // 2, idx % 2]\n        \n        # Boxplot\n        bp = ax.boxplot([cross_df[metric]], labels=[metric], patch_artist=True)\n        bp['boxes'][0].set_facecolor(colors[idx])\n        \n        # Scatter dos pontos individuais\n        y_values = cross_df[metric].values\n        x_values = np.ones(len(y_values))\n        ax.scatter(x_values, y_values, color='darkblue', s=100, zorder=3, alpha=0.6)\n        \n        # Adicionar labels dos especialistas\n        for i, specialist in enumerate(cross_df['Specialist']):\n            ax.text(1.05, y_values[i], specialist, fontsize=9, va='center')\n        \n        # Linha de threshold\n        threshold_map = {\n            'Precision': 0.75,\n            'Recall': 0.70,\n            'F1': 0.72,\n            'Accuracy': 0.70\n        }\n        if metric in threshold_map:\n            ax.axhline(y=threshold_map[metric], color='red', linestyle='--', \n                       linewidth=2, label=f'Threshold ({threshold_map[metric]})')\n            ax.legend()\n        \n        ax.set_ylabel('Score')\n        ax.set_title(f'Distribui√ß√£o de {metric} entre Especialistas')\n        ax.set_ylim([0, 1])\n        ax.grid(axis='y', alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Heatmap de correla√ß√£o entre especialistas\n    # Criar matriz onde cada linha √© um especialista e colunas s√£o m√©tricas\n    corr_matrix = cross_df[['Precision', 'Recall', 'F1', 'Accuracy']].T.corr()\n    \n    fig, ax = plt.subplots(figsize=(8, 6))\n    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n                xticklabels=cross_df['Specialist'], \n                yticklabels=cross_df['Specialist'],\n                vmin=-1, vmax=1, center=0, ax=ax)\n    ax.set_title('Correla√ß√£o de M√©tricas entre Especialistas')\n    plt.tight_layout()\n    plt.show()\n    \n    # Estat√≠sticas descritivas\n    print(\"\\n=== Estat√≠sticas Descritivas ===\")\n    print(cross_df[['Precision', 'Recall', 'F1', 'Accuracy']].describe())\n    \n    # Identificar melhor e pior especialista\n    print(\"\\n=== Ranking por F1 Score ===\")\n    ranked = cross_df.sort_values('F1', ascending=False)\n    for idx, row in ranked.iterrows():\n        print(f\"{row['Specialist']}: F1={row['F1']:.3f}\")\n    \n    best_specialist = ranked.iloc[0]['Specialist']\n    worst_specialist = ranked.iloc[-1]['Specialist']\n    print(f\"\\nMelhor: {best_specialist} (F1={ranked.iloc[0]['F1']:.3f})\")\n    print(f\"Pior: {worst_specialist} (F1={ranked.iloc[-1]['F1']:.3f})\")\n    \nelse:\n    print(\"Nenhuma m√©trica dispon√≠vel para an√°lise cross-specialist\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. An√°lise Cross-Specialist",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Analisar distribui√ß√£o de confidence scores e risk scores\nfor specialist in SPECIALISTS:\n    model_name = f\"{specialist}-evaluator\"\n    \n    # Buscar vers√£o em Production\n    versions = get_model_versions(specialist)\n    prod_version = None\n    \n    for v in versions:\n        if v.current_stage == 'Production':\n            prod_version = v.version\n            break\n    \n    if not prod_version:\n        continue\n    \n    # Carregar modelo\n    model = load_model_from_mlflow(model_name, prod_version)\n    if model is None:\n        continue\n    \n    # Tentar carregar dataset\n    dataset_path = f\"/data/training/specialist_{specialist}_base.parquet\"\n    try:\n        import os\n        if not os.path.exists(dataset_path):\n            continue\n        \n        df = pd.read_parquet(dataset_path)\n        \n        if 'recommendation' not in df.columns:\n            continue\n        \n        # Separar features\n        label_col = 'recommendation'\n        feature_cols = [col for col in df.columns if col != label_col]\n        X = df[feature_cols]\n        \n        # Obter probabilidades (se modelo suportar)\n        if hasattr(model, 'predict_proba'):\n            probas = model.predict_proba(X)\n            \n            # Confidence score = max probability\n            confidence_scores = np.max(probas, axis=1)\n            \n            # Risk score = 1 - confidence (inversamente proporcional)\n            risk_scores = 1 - confidence_scores\n            \n            # Criar subplots\n            fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n            \n            # Histograma de confidence\n            axes[0, 0].hist(confidence_scores, bins=50, color='steelblue', edgecolor='black')\n            axes[0, 0].set_xlabel('Confidence Score')\n            axes[0, 0].set_ylabel('Frequ√™ncia')\n            axes[0, 0].set_title(f'{specialist.capitalize()} - Distribui√ß√£o de Confidence')\n            axes[0, 0].axvline(confidence_scores.mean(), color='red', linestyle='--', \n                               label=f'M√©dia: {confidence_scores.mean():.3f}')\n            axes[0, 0].legend()\n            \n            # Histograma de risk\n            axes[0, 1].hist(risk_scores, bins=50, color='coral', edgecolor='black')\n            axes[0, 1].set_xlabel('Risk Score')\n            axes[0, 1].set_ylabel('Frequ√™ncia')\n            axes[0, 1].set_title(f'{specialist.capitalize()} - Distribui√ß√£o de Risk')\n            axes[0, 1].axvline(risk_scores.mean(), color='red', linestyle='--',\n                               label=f'M√©dia: {risk_scores.mean():.3f}')\n            axes[0, 1].legend()\n            \n            # Scatter: confidence vs risk\n            axes[1, 0].scatter(confidence_scores, risk_scores, alpha=0.5, s=10)\n            axes[1, 0].set_xlabel('Confidence Score')\n            axes[1, 0].set_ylabel('Risk Score')\n            axes[1, 0].set_title(f'{specialist.capitalize()} - Confidence vs Risk')\n            axes[1, 0].plot([0, 1], [1, 0], 'r--', label='Te√≥rico (Risk = 1 - Confidence)')\n            axes[1, 0].legend()\n            \n            # Boxplot de confidence por classe predita\n            predictions = model.predict(X)\n            df_plot = pd.DataFrame({\n                'prediction': predictions,\n                'confidence': confidence_scores\n            })\n            \n            # Ordenar por ordem de severidade\n            class_order = ['approve', 'approve_with_conditions', 'review_required', 'reject']\n            df_plot['prediction'] = pd.Categorical(df_plot['prediction'], categories=class_order, ordered=True)\n            \n            df_plot.boxplot(column='confidence', by='prediction', ax=axes[1, 1])\n            axes[1, 1].set_xlabel('Predi√ß√£o')\n            axes[1, 1].set_ylabel('Confidence Score')\n            axes[1, 1].set_title(f'{specialist.capitalize()} - Confidence por Classe')\n            plt.sca(axes[1, 1])\n            plt.xticks(rotation=15, ha='right')\n            \n            plt.suptitle('')  # Remover t√≠tulo autom√°tico do boxplot\n            plt.tight_layout()\n            plt.show()\n            \n            # Estat√≠sticas\n            print(f\"\\n=== {specialist.upper()} - Estat√≠sticas de Scores ===\")\n            print(f\"Confidence - M√©dia: {confidence_scores.mean():.3f}, Std: {confidence_scores.std():.3f}\")\n            print(f\"Confidence - Min: {confidence_scores.min():.3f}, Max: {confidence_scores.max():.3f}\")\n            print(f\"Risk - M√©dia: {risk_scores.mean():.3f}, Std: {risk_scores.std():.3f}\")\n            \n            # Contar predi√ß√µes de alta incerteza (low confidence)\n            low_confidence_count = (confidence_scores < 0.6).sum()\n            print(f\"Predi√ß√µes com baixa confidence (<0.6): {low_confidence_count} ({low_confidence_count/len(confidence_scores)*100:.1f}%)\")\n            \n        else:\n            print(f\"{specialist}: Modelo n√£o suporta predict_proba, pulando distribui√ß√£o de scores\")\n    \n    except Exception as e:\n        print(f\"Erro ao processar {specialist}: {e}\")\n        continue\n    \n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Distribui√ß√£o de Scores de Predi√ß√£o",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Importar confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Carregar datasets de valida√ß√£o e calcular confusion matrix para cada especialista\nfor specialist in SPECIALISTS:\n    model_name = f\"{specialist}-evaluator\"\n    \n    # Buscar vers√£o em Production\n    versions = get_model_versions(specialist)\n    prod_version = None\n    \n    for v in versions:\n        if v.current_stage == 'Production':\n            prod_version = v.version\n            break\n    \n    if not prod_version:\n        print(f\"Nenhum modelo em Production para {specialist}\")\n        continue\n    \n    # Carregar modelo\n    model = load_model_from_mlflow(model_name, prod_version)\n    \n    if model is None:\n        print(f\"Falha ao carregar modelo {model_name} v{prod_version}\")\n        continue\n    \n    # Tentar carregar dataset de valida√ß√£o\n    dataset_path = f\"/data/training/specialist_{specialist}_base.parquet\"\n    try:\n        import os\n        if not os.path.exists(dataset_path):\n            print(f\"Dataset n√£o encontrado: {dataset_path}\")\n            print(f\"Pulando confusion matrix para {specialist}\")\n            continue\n        \n        df = pd.read_parquet(dataset_path)\n        \n        # Assumir que dataset tem coluna 'recommendation' com labels\n        if 'recommendation' not in df.columns:\n            print(f\"Coluna 'recommendation' n√£o encontrada em dataset de {specialist}\")\n            continue\n        \n        # Separar features e labels\n        label_col = 'recommendation'\n        feature_cols = [col for col in df.columns if col != label_col]\n        \n        X = df[feature_cols]\n        y_true = df[label_col]\n        \n        # Fazer predi√ß√µes\n        y_pred = model.predict(X)\n        \n        # Calcular confusion matrix\n        labels = ['approve', 'approve_with_conditions', 'review_required', 'reject']\n        cm = confusion_matrix(y_true, y_pred, labels=labels)\n        \n        # Plot confusion matrix\n        fig, ax = plt.subplots(figsize=(10, 8))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                    xticklabels=labels, yticklabels=labels, ax=ax)\n        ax.set_xlabel('Predi√ß√£o')\n        ax.set_ylabel('Real')\n        ax.set_title(f'{specialist.capitalize()} - Confusion Matrix (v{prod_version})')\n        plt.tight_layout()\n        plt.show()\n        \n        # Calcular accuracy por classe\n        print(f\"\\nAccuracy por classe para {specialist}:\")\n        for i, label in enumerate(labels):\n            class_accuracy = cm[i, i] / cm[i, :].sum() if cm[i, :].sum() > 0 else 0\n            print(f\"  {label}: {class_accuracy:.2%}\")\n        \n    except Exception as e:\n        print(f\"Erro ao processar {specialist}: {e}\")\n        continue\n    \n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Confusion Matrix por Especialista",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export de Relat√≥rio HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Criar diret√≥rio de reports se n√£o existir\n",
    "reports_dir = os.path.join(os.path.dirname(os.path.abspath('__file__')), 'reports')\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Gerar timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "report_file = os.path.join(reports_dir, f'model_analysis_{timestamp}.html')\n",
    "\n",
    "# Criar HTML\n",
    "html_content = f\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>Model Analysis Report - {timestamp}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "        h1 {{ color: #2c3e50; }}\n",
    "        h2 {{ color: #34495e; margin-top: 30px; }}\n",
    "        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "        th {{ background-color: #3498db; color: white; }}\n",
    "        .critical {{ color: #e74c3c; font-weight: bold; }}\n",
    "        .high {{ color: #e67e22; font-weight: bold; }}\n",
    "        .medium {{ color: #f39c12; }}\n",
    "        .low {{ color: #3498db; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Neural Hive Mind - Model Analysis Report</h1>\n",
    "    <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    <p><strong>MLflow URI:</strong> {MLFLOW_URI}</p>\n",
    "    \n",
    "    <h2>Status Summary</h2>\n",
    "    {status_df.to_html(index=False)}\n",
    "    \n",
    "    <h2>Recommendations</h2>\n",
    "    <ul>\n",
    "\"\"\"\n",
    "\n",
    "for rec in recommendations:\n",
    "    html_content += f'<li class=\"{rec[\"severity\"]}\">[{rec[\"severity\"].upper()}] {rec[\"message\"]}</li>\\n'\n",
    "\n",
    "html_content += \"\"\"\n",
    "    </ul>\n",
    "    \n",
    "    <h2>Thresholds</h2>\n",
    "    <ul>\n",
    "        <li>Precision: >= 0.75</li>\n",
    "        <li>Recall: >= 0.70</li>\n",
    "        <li>F1 Score: >= 0.72</li>\n",
    "        <li>Improvement: >= 5%</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Salvar relat√≥rio\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"\\n‚úÖ Relat√≥rio HTML salvo em: {report_file}\")\n",
    "print(f\"Para visualizar: open {report_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}