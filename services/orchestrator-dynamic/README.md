# Orchestrator Dynamic - Orquestrador DinÃ¢mico

**VersÃ£o**: 1.0.0
**Fase**: 2.1 - FundaÃ§Ã£o do Orquestrador
**Status**: ImplementaÃ§Ã£o Base Completa (85%)

## VisÃ£o Geral

O **Orchestrator Dynamic** Ã© o componente central da Fase 2 do Neural Hive-Mind, responsÃ¡vel por implementar o **Fluxo C - OrquestraÃ§Ã£o de ExecuÃ§Ã£o Adaptativa** conforme descrito no `documento-06-fluxos-processos-neural-hive-mind.md`.

Este serviÃ§o consome **Consolidated Decisions** do Consensus Engine, converte **Cognitive Plans** em **Execution Tickets**, e orquestra a execuÃ§Ã£o distribuÃ­da seguindo polÃ­ticas de SLA, QoS e priorizaÃ§Ã£o baseada em risk bands.

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Orchestrator Dynamic                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ FastAPI      â”‚    â”‚ Temporal Worker                  â”‚  â”‚
â”‚  â”‚              â”‚    â”‚                                  â”‚  â”‚
â”‚  â”‚ /health      â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚ /ready       â”‚    â”‚  â”‚ OrchestrationWorkflow      â”‚ â”‚  â”‚
â”‚  â”‚ /metrics     â”‚    â”‚  â”‚  â€¢ C1: Validate Plan       â”‚ â”‚  â”‚
â”‚  â”‚ /api/v1/...  â”‚    â”‚  â”‚  â€¢ C2: Generate Tickets    â”‚ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â€¢ C3: Allocate Resources  â”‚ â”‚  â”‚
â”‚                       â”‚  â”‚  â€¢ C4: Publish Tickets     â”‚ â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚  â€¢ C5: Consolidate Results â”‚ â”‚  â”‚
â”‚  â”‚ Kafka        â”‚    â”‚  â”‚  â€¢ C6: Publish Telemetry   â”‚ â”‚  â”‚
â”‚  â”‚ Consumer     â”‚â”€â”€â”€â†’â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚              â”‚    â”‚                                  â”‚  â”‚
â”‚  â”‚ plans.       â”‚    â”‚  Activities:                     â”‚  â”‚
â”‚  â”‚ consensus    â”‚    â”‚  â€¢ plan_validation               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ ticket_generation             â”‚  â”‚
â”‚                       â”‚  â€¢ result_consolidation          â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  Observability:                                              â”‚
â”‚  â€¢ Prometheus Metrics (20+ mÃ©tricas)                        â”‚
â”‚  â€¢ OpenTelemetry Tracing                                    â”‚
â”‚  â€¢ Structured Logging (structlog)                           â”‚
â”‚  â€¢ PolicyValidator + OPA Enforcement                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                   â”‚
         â†“                        â†“                   â†“
    Kafka Topics            PostgreSQL          MongoDB
    â€¢ execution.tickets     (Temporal State)   (Auditoria)
    â€¢ orchestration.incidents
    â€¢ telemetry.orchestration
```

## Observability & Tracing

O serviÃ§o estÃ¡ instrumentado com OpenTelemetry via `neural_hive_observability`, habilitando tracing para Kafka (consumers/producers), gRPC (clientes) e workflows Temporal. Os spans incluem atributos customizados do Neural Hive para facilitar correlaÃ§Ã£o:
- `neural.hive.intent.id`: ID da intenÃ§Ã£o original
- `neural.hive.plan.id`: ID do plano cognitivo
- `neural.hive.decision.id`: ID da decisÃ£o consolidada
- `neural.hive.workflow.id`: ID do workflow Temporal
- `neural.hive.ticket.id`: ID do execution ticket
- `neural.hive.worker.id`: ID do worker alocado
- `neural.hive.ml.*`: Atributos de operaÃ§Ãµes ML (source, predicted_queue_ms, predicted_load_pct, anomaly_score, optimization_source)
- `messaging.kafka.*`: TÃ³pico/partiÃ§Ã£o/offset Kafka consumido
- `rpc.*`: ServiÃ§o/mÃ©todo gRPC invocado

Consultas Ãºteis no Jaeger:
- Por plano: `neural.hive.plan.id=<plan_id>`
- Por intenÃ§Ã£o: `neural.hive.intent.id=<intent_id>`
- Spans ML: `operation=load.predict_worker_load` ou `operation=scheduling.optimize_allocation`

VisualizaÃ§Ã£o: os traces sÃ£o exportados para o OTLP Collector configurado em `OTEL_EXPORTER_ENDPOINT` e podem ser inspecionados no Jaeger UI do cluster.

## Tecnologias

- **Framework**: FastAPI 0.104+
- **Workflow Engine**: Temporal 1.5+ (Python SDK)
- **Messaging**: Kafka (aiokafka)
- **State Store**: PostgreSQL 15 (Temporal)
- **Auditoria**: MongoDB 6+
- **Cache**: Redis Cluster
- **Observabilidade**: Prometheus + OpenTelemetry + Jaeger
- **Logging**: structlog

## Estrutura do Projeto

```
services/orchestrator-dynamic/
â”œâ”€â”€ Dockerfile                 # Multi-stage Docker build
â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py               # Entry point FastAPI + lifecycle
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py       # Pydantic Settings (Temporal, Kafka, DB)
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â”œâ”€â”€ intelligent_scheduler.py  # Scheduler principal
â”‚   â”‚   â”œâ”€â”€ priority_calculator.py    # CÃ¡lculo de prioridades
â”‚   â”‚   â””â”€â”€ resource_allocator.py     # AlocaÃ§Ã£o de recursos
â”‚   â”œâ”€â”€ sla/
â”‚   â”‚   â”œâ”€â”€ sla_monitor.py           # Monitor proativo de SLA
â”‚   â”‚   â””â”€â”€ alert_manager.py         # Gerenciador de alertas SLA
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â””â”€â”€ orchestration_workflow.py  # Workflow principal Fluxo C
â”‚   â”œâ”€â”€ activities/
â”‚   â”‚   â”œâ”€â”€ plan_validation.py         # C1: ValidaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ ticket_generation.py       # C2: GeraÃ§Ã£o de tickets
â”‚   â”‚   â””â”€â”€ result_consolidation.py    # C5-C6: ConsolidaÃ§Ã£o e telemetria
â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”œâ”€â”€ service_registry_client.py # Cliente gRPC Service Registry
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py          # Cliente Kafka Producer
â”‚   â”‚   â”œâ”€â”€ redis_client.py            # Cliente Redis (singleton)
â”‚   â”‚   â””â”€â”€ mongodb_client.py          # Cliente MongoDB
â”‚   â”œâ”€â”€ consumers/
â”‚   â”‚   â””â”€â”€ decision_consumer.py       # Consumer plans.consensus
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ temporal_worker.py         # Temporal Worker Manager
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ execution_ticket.py        # Pydantic model ExecutionTicket
â”‚   â””â”€â”€ observability/
â”‚       â””â”€â”€ metrics.py                 # MÃ©tricas Prometheus
â””â”€â”€ README.md (este arquivo)
```

## Fluxo de ExecuÃ§Ã£o (Fluxo C)

### Etapa C1: Validar Plano Cognitivo
- Verifica schema Avro do Cognitive Plan
- Valida campos obrigatÃ³rios, versÃ£o, expiraÃ§Ã£o
- Detecta ciclos no DAG de dependÃªncias
- Audita resultado no MongoDB

### Etapa C2: Quebrar Plano em Tickets
- Gera um `ExecutionTicket` para cada task do plano
- Calcula SLA baseado em `risk_band` e `estimated_duration_ms`
- Define QoS (delivery_mode, consistency, durability)
- Mapeia dependencies (task_ids â†’ ticket_ids)
- Ordena tickets topologicamente

### Etapa C3: Alocar Recursos
- Usa `IntelligentScheduler` para alocaÃ§Ã£o otimizada
- Calcula `priority_score` baseado em risk_band, QoS e SLA urgency
- Descobre workers via Service Registry gRPC
- Seleciona melhor worker baseado em score composto
- Fallback para alocaÃ§Ã£o stub se Service Registry indisponÃ­vel
- Tempo de reaÃ§Ã£o <30s conforme SLO

### Etapa C4: Executar Tarefas
- Publica cada ticket no Kafka `execution.tickets`
- Aguarda confirmaÃ§Ã£o de publicaÃ§Ã£o
- Atualiza status do ticket para `RUNNING`
- Persiste ticket no MongoDB para auditoria

### Etapa C5: Consolidar Resultado
- Agrega resultados de todos os tickets
- Calcula mÃ©tricas (duraÃ§Ã£o, sucesso/falha, retries, SLA violations)
- Valida integridade (verifica inconsistÃªncias)
- Aciona autocura (Fluxo E) se necessÃ¡rio

### Etapa C6: Publicar Telemetria
- Cria Telemetry Frame com correlaÃ§Ã£o completa
- Publica no Kafka `telemetry.orchestration`
- Exporta mÃ©tricas para Prometheus
- Cria span OpenTelemetry para o workflow
- Buffer local em caso de falha

## MongoDB Persistence

- ColeÃ§Ãµes: `validation_audit` (auditoria C1), `workflow_results` (resultados C5), `incidents` (autocura Fluxo E), `telemetry_buffer` (retry de telemetria)
- Estruturas: cada coleÃ§Ã£o inclui `workflow_id`; `validation_audit` armazena `validation_result`, `timestamp`, `hash`; `workflow_results` guarda mÃ©tricas/SLA e resumo de tickets; `incidents` registra `type`, `details`, `severity`; `telemetry_buffer` persiste frame com `buffered_at` e `retry_count`
- Ãndices: `validation_audit` em `plan_id`, `workflow_id`, `(plan_id, timestamp)`; `workflow_results` em `workflow_id` (Ãºnico), `status`, `(status, consolidated_at)`; `incidents` em `workflow_id`, `type`, `(severity, timestamp)`; `telemetry_buffer` em `workflow_id`, `buffered_at`, `(retry_count, buffered_at)`
- Uso: auditoria completa de validaÃ§Ãµes, consolidaÃ§Ã£o para analytics/SLA, trilha de incidentes para autocura e buffer resiliente de telemetria
- Diagrama (simplificado): `plan_validation.audit_validation â†’ validation_audit` | `consolidate_results â†’ workflow_results` | `trigger_self_healing â†’ incidents` | `buffer_telemetry â†’ telemetry_buffer`

## Retry e ResiliÃªncia

- Todas as operaÃ§Ãµes de persistÃªncia usam `tenacity` com `stop_after_attempt(config.retry_max_attempts)` e `wait_exponential` (`multiplier=config.retry_backoff_coefficient`, `min=config.retry_initial_interval_ms/1000`, `max=config.retry_max_interval_ms/1000`)
- Fail-open por padrÃ£o: erros de MongoDB sÃ£o logados e nÃ£o bloqueiam workflow (orquestraÃ§Ã£o continua em modo degradado)
- Logs estruturados para sucesso/erro: `validation_audit_saved`, `workflow_result_saved`, `incident_saved`, `telemetry_buffered`
- ConfiguraÃ§Ãµes padrÃ£o em `src/config/settings.py`: tentativas=3, intervalo inicial=1000ms, backoff=2.0, intervalo mÃ¡ximo=60000ms

## ConfiguraÃ§Ã£o MongoDB

- `MONGODB_URI`: string de conexÃ£o (pode vir do Vault)
- `MONGODB_DATABASE`: nome do database (default: `neural_hive_orchestration`)
- `RETRY_MAX_ATTEMPTS`: tentativas de retry (default: 3)
- `RETRY_INITIAL_INTERVAL_MS`: intervalo inicial em ms (default: 1000)
- `RETRY_BACKOFF_COEFFICIENT`: multiplicador do backoff (default: 2.0)
- `RETRY_MAX_INTERVAL_MS`: intervalo mÃ¡ximo em ms (default: 60000)

## Troubleshooting MongoDB

- MongoDB indisponÃ­vel: serviÃ§o segue em modo degradado; logs `mongodb_client_not_initialized` indicam que a activity foi pulada
- Falhas recorrentes de persistÃªncia: revisar logs `*_persist_failed`, ajustar parÃ¢metros de retry ou conexÃ£o
- Ãndices: executar `db.<collection>.getIndexes()` para validar criaÃ§Ã£o; `workflow_results` usa `_id=workflow_id` com Ã­ndice Ãºnico
- Consultas rÃ¡pidas: contar validaÃ§Ãµes por plano (`db.validation_audit.countDocuments({plan_id: "<id>"})`), listar SLA violados (`db.workflow_results.find({"sla_status.violations_count": {$gt: 0}})`), incidentes crÃ­ticos (`db.incidents.find({severity: "CRITICAL"})`)

## Testes de PersistÃªncia

- Rodar unitÃ¡rios: `pytest services/orchestrator-dynamic/tests/test_mongodb_persistence.py`
- Rodar integraÃ§Ã£o das activities: `pytest services/orchestrator-dynamic/tests/test_activities_mongodb_integration.py`
- Tests usam MongoDB mockado e validam retry + fail-open; seguros para execuÃ§Ã£o local sem MongoDB real

## Policy Validation

- IntegraÃ§Ã£o com OPA Policy Engine cobrindo C1 (plano cognitivo), C2 (tickets) e C3 (alocaÃ§Ã£o de recursos).
- C1: `plan_validation.validate_cognitive_plan` valida planos completos com `resource_limits.rego` e `sla_enforcement.rego`.
- C2: `ticket_generation.allocate_resources` valida tickets e aplica `feature_flags.rego` para habilitar Intelligent Scheduler e capacidades relacionadas.
- C3: `ticket_generation.allocate_resources` valida a alocaÃ§Ã£o retornada pelo `IntelligentScheduler.schedule_ticket` via `validate_resource_allocation`.
- MÃ©tricas OPA registradas em todas as etapas (validaÃ§Ãµes, rejeiÃ§Ãµes, warnings e erros).
- Detalhamento completo em `docs/POLICY_VALIDATION_INTEGRATION.md`.

## OPA Policy Enforcement

- Enforcement centralizado com OPA no C1 (plano completo) e C3 (tickets e alocaÃ§Ãµes), usando `PolicyValidator` + `OPAClient`.
- PolÃ­ticas ativas: `resource_limits`, `sla_enforcement`, `feature_flags`, `security_constraints`.
- ConfiguraÃ§Ã£o rÃ¡pida (env):
  - `OPA_ENABLED=true`, `OPA_HOST`, `OPA_PORT`, `OPA_TIMEOUT_SECONDS`, `OPA_FAIL_OPEN`
  - `OPA_POLICY_RESOURCE_LIMITS`, `OPA_POLICY_SLA_ENFORCEMENT`, `OPA_POLICY_FEATURE_FLAGS`, `OPA_POLICY_SECURITY_CONSTRAINTS`
  - `OPA_CIRCUIT_BREAKER_ENABLED=true`, `OPA_CIRCUIT_BREAKER_FAILURE_THRESHOLD=5`, `OPA_CACHE_TTL_SECONDS=30`
- DocumentaÃ§Ã£o: `docs/OPA_INTEGRATION_GUIDE.md` e `docs/FEATURE_FLAGS_GUIDE.md`.
- ValidaÃ§Ã£o rÃ¡pida: `scripts/validate_opa_integration.sh` (faz healthcheck, valida polÃ­ticas e roda testes E2E).
- Observabilidade: mÃ©tricas OPA jÃ¡ expostas em `/metrics` e alertas prÃ©-configurados em `monitoring/prometheus-rules/orchestrator-opa-alerts.yaml`.
- Troubleshooting resumido:
  - OPA indisponÃ­vel â†’ verificar `/health`, mÃ©trica `orchestration_opa_evaluation_errors_total`, circuit breaker (`orchestration_opa_circuit_breaker_state`).
  - RejeiÃ§Ãµes inesperadas â†’ revisar `orchestration_opa_policy_rejections_total{policy_name,rule}` e testar entrada no OPA Playground.
  - Cache/latÃªncia â†’ `orchestration_opa_cache_hits_total` e `orchestration_opa_validation_duration_seconds`.

## Scheduler Inteligente

O Orchestrator Dynamic inclui um scheduler inteligente que otimiza a alocaÃ§Ã£o de recursos para execution tickets baseado em mÃºltiplos fatores:

### Principais Funcionalidades

- **PriorizaÃ§Ã£o Multi-Fator:** Combina risk band (40%), requisitos QoS (30%) e urgÃªncia SLA (30%) para priorizaÃ§Ã£o inteligente
- **IntegraÃ§Ã£o com Service Registry:** Descobre workers disponÃ­veis via gRPC com matching de health e capabilities
- **SeleÃ§Ã£o Inteligente de Workers:** Scoring composto baseado em saÃºde do agente, telemetria (taxa de sucesso, latÃªncia, experiÃªncia)
- **Cache de Performance:** Cache baseado em TTL para descoberta de workers reduz latÃªncia em 70-80%
- **Fallback Gracioso:** Fallback automÃ¡tico para alocaÃ§Ã£o stub quando Service Registry estÃ¡ indisponÃ­vel
- **IntegraÃ§Ã£o ML:** Boost de prioridade baseado em duraÃ§Ã£o de execuÃ§Ã£o prevista por modelos ML
- **Enforcement de PolÃ­tica OPA:** Valida tickets contra polÃ­ticas antes da alocaÃ§Ã£o
- **MÃ©tricas Abrangentes:** 10+ mÃ©tricas Prometheus para monitoramento e alertas

### Arquitetura

```
Ticket â†’ ValidaÃ§Ã£o OPA â†’ PrediÃ§Ãµes ML â†’ CÃ¡lculo de Prioridade â†’ Descoberta de Workers â†’ SeleÃ§Ã£o â†’ AlocaÃ§Ã£o
                                                                           â†“
                                                                    Service Registry
```

### ConfiguraÃ§Ã£o

```yaml
# Habilitar/desabilitar scheduler
ENABLE_INTELLIGENT_SCHEDULER: "true"

# ConexÃ£o Service Registry
SERVICE_REGISTRY_ENDPOINT: "service-registry:50051"
SERVICE_REGISTRY_CACHE_TTL_SECONDS: "60"
SERVICE_REGISTRY_MAX_RESULTS: "10"

# Pesos de prioridade (customizar scoring)
SCHEDULER_PRIORITY_WEIGHTS: '{"risk": 0.4, "qos": 0.3, "sla": 0.3}'
```

### PriorizaÃ§Ã£o

Score composto: `(risk_weight * 0.4) + (qos_weight * 0.3) + (sla_urgency * 0.3)`

**Risk Weights:**
- critical: 1.0
- high: 0.7
- normal: 0.5
- low: 0.3

**QoS Weights:**
- EXACTLY_ONCE + STRONG + PERSISTENT: 1.0
- AT_LEAST_ONCE + STRONG: 0.85
- AT_LEAST_ONCE + EVENTUAL + PERSISTENT: 0.595
- AT_MOST_ONCE: 0.5

**SLA Urgency:**
- 0-50% deadline consumido: 0.3
- 50-80%: 0.7
- 80-100%: 1.0

### Discovery de Workers

- IntegraÃ§Ã£o gRPC com Service Registry
- Matching baseado em capabilities, namespace e security level
- Ranking por health + telemetria (success_rate, latÃªncia, experiÃªncia)
- Cache de descobertas (TTL configurÃ¡vel, padrÃ£o 60s)
- Timeout 5s com fallback gracioso

### SeleÃ§Ã£o de Workers

Score composto do worker: `(agent_score * 0.6) + (priority_score * 0.4)`

**Agent Score** combina:
- Health (50%): status HEALTHY=1.0, DEGRADED=0.6, UNHEALTHY=0.0
- Telemetry (50%): (success_rate Ã— 0.6) + (duration_score Ã— 0.2) + (experience Ã— 0.2)

**Disponibilidade:**
- Status: deve ser HEALTHY ou DEGRADED
- Capacidade: active_tasks < max_concurrent_tasks

### Monitoramento

**Dashboards:**
- MÃ©tricas detalhadas: `monitoring/dashboards/orchestrator-intelligent-scheduler.json`
- VisÃ£o geral: `monitoring/dashboards/fluxo-c-orquestracao.json` (seÃ§Ã£o Scheduler)

**MÃ©tricas Principais:**
- `orchestration_scheduler_allocations_total`: Total de alocaÃ§Ãµes (sucesso/falha)
- `orchestration_scheduler_allocation_duration_seconds`: LatÃªncia de alocaÃ§Ã£o (p50, p95, p99)
- `orchestration_scheduler_priority_score`: DistribuiÃ§Ã£o de scores de prioridade por risk band
- `orchestration_scheduler_workers_discovered`: Workers encontrados por alocaÃ§Ã£o
- `orchestration_scheduler_cache_hits_total`: EficiÃªncia de cache
- `orchestration_scheduler_rejections_total`: RazÃµes de rejeiÃ§Ã£o

**Endpoint Prometheus:** `http://localhost:8000/metrics`

### Performance

- **LatÃªncia:** p95 < 200ms (tÃ­pico: p50 ~50ms, p95 ~150ms)
- **Taxa de Cache Hit:** 70-80% tÃ­pico
- **Taxa de Fallback:** <5% em ambientes saudÃ¡veis
- **Throughput:** AtÃ© 50 alocaÃ§Ãµes concorrentes

### Testes

```bash
# Executar todos os testes do scheduler
./scripts/test_scheduler.sh

# Testes unitÃ¡rios apenas
pytest tests/unit/test_intelligent_scheduler.py -v

# Testes de integraÃ§Ã£o
pytest tests/integration/test_scheduler_integration.py -v
```

**Cobertura de Testes:** 40+ testes cobrindo todos os componentes do scheduler e cenÃ¡rios de integraÃ§Ã£o

## SLA Monitoring

O Orchestrator Dynamic implementa monitoramento proativo de SLA em tempo de execuÃ§Ã£o, integrado com o SLA Management System.

### Componentes

#### SLAMonitor (`src/sla/sla_monitor.py`)

ResponsÃ¡vel por verificar deadlines de tickets e consultar error budgets via API:

- **VerificaÃ§Ã£o de Deadlines**: Calcula tempo restante e percentual consumido para cada ticket
- **AgregaÃ§Ã£o de Workflow**: Identifica tickets crÃ­ticos (>80% deadline consumido)
- **Consulta de Budgets**: IntegraÃ§Ã£o HTTP com SLA Management System API
- **Cache Redis**: Cache de budgets com TTL configurÃ¡vel (default: 10s)
- **Fail-open**: Continua operaÃ§Ã£o mesmo com falhas no sistema de SLA

#### AlertManager (`src/sla/alert_manager.py`)

Gerencia publicaÃ§Ã£o de alertas proativos e violaÃ§Ãµes no Kafka:

- **Alertas Proativos**: Budget crÃ­tico, deadline prÃ³ximo, burn rate alto
- **ViolaÃ§Ãµes SLA**: Eventos de deadline excedido ou timeout
- **DeduplicaÃ§Ã£o**: Cache Redis de alertas enviados (TTL: 5min)
- **Fail-safe**: ValidaÃ§Ã£o de Kafka producer antes de publicaÃ§Ã£o

### TÃ³picos Kafka

- **`sla.alerts`**: Alertas proativos (BUDGET_CRITICAL, DEADLINE_APPROACHING, BURN_RATE_HIGH)
- **`sla.violations`**: ViolaÃ§Ãµes formais de SLA (DEADLINE_EXCEEDED, TIMEOUT)

Cada mensagem inclui campo `event_type` ('ALERT' ou 'VIOLATION') para distinÃ§Ã£o clara.

### IntegraÃ§Ã£o no Fluxo C5

Durante consolidaÃ§Ã£o de resultados (`result_consolidation.py`):

1. **InicializaÃ§Ã£o**: Cria clientes Redis e Kafka compartilhados
2. **VerificaÃ§Ã£o de Deadlines**: Monitora todos os tickets do workflow
3. **Alertas de Deadline**: Envia alertas para tickets crÃ­ticos (>80% consumido)
4. **VerificaÃ§Ã£o de Budget**: Consulta error budget do serviÃ§o
5. **Alertas de Budget**: Envia alertas se budget < 20%
6. **DetecÃ§Ã£o de ViolaÃ§Ãµes**: Calcula duraÃ§Ã£o real vs timeout_ms usando:
   - `actual_duration_ms` (se disponÃ­vel)
   - `completed_at - started_at` (calculado de timestamps)
   - `estimated_duration_ms` (fallback)
7. **PublicaÃ§Ã£o de ViolaÃ§Ãµes**: Publica eventos de violaÃ§Ã£o no Kafka
8. **Cleanup**: Fecha conexÃµes Redis e Kafka

### ConfiguraÃ§Ã£o

VariÃ¡veis de ambiente:

```bash
# SLA Management System Integration
SLA_MANAGEMENT_ENABLED=true
SLA_MANAGEMENT_HOST=sla-management-system.neural-hive-orchestration.svc.cluster.local
SLA_MANAGEMENT_PORT=8000
SLA_MANAGEMENT_TIMEOUT_SECONDS=5
SLA_MANAGEMENT_CACHE_TTL_SECONDS=10

# Thresholds
SLA_BUDGET_CRITICAL_THRESHOLD=0.2        # 20%
SLA_DEADLINE_WARNING_THRESHOLD=0.8       # 80%

# Kafka Topics
SLA_VIOLATIONS_TOPIC=sla.violations
SLA_ALERTS_TOPIC=sla.alerts

# DeduplicaÃ§Ã£o
SLA_ALERT_DEDUPLICATION_TTL_SECONDS=300  # 5 minutos
```

### MÃ©tricas Prometheus

**Budgets**:
- `orchestration_sla_budget_remaining_percent` - Percentual de error budget restante (labels: service_name, slo_id)
- `orchestration_sla_budget_status` - Status do budget: 0=HEALTHY, 1=WARNING, 2=CRITICAL, 3=EXHAUSTED (labels: service_name, slo_id)
- `orchestration_sla_burn_rate` - Taxa de consumo do budget (labels: service_name, window_hours)

**Alertas**:
- `orchestration_sla_alerts_sent_total` - Total de alertas enviados (labels: alert_type, severity)
- `orchestration_sla_alert_deduplication_hits_total` - Alertas bloqueados por deduplicaÃ§Ã£o

**ViolaÃ§Ãµes**:
- `orchestration_sla_violations_published_total` - ViolaÃ§Ãµes publicadas no Kafka (labels: violation_type)

**Performance**:
- `orchestration_sla_check_duration_seconds` - DuraÃ§Ã£o de verificaÃ§Ãµes (labels: check_type) - buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]

**Erros**:
- `orchestration_sla_monitor_errors_total` - Erros no SLA monitoring (labels: error_type: api_error, cache_error, deadline_check, workflow_check, producer_not_initialized, alert_publish, violation_publish)

### Exemplo de Queries PromQL

```promql
# Budget restante por serviÃ§o
orchestration_sla_budget_remaining_percent{service_name="orchestrator-dynamic"}

# Taxa de burn do budget (1h)
orchestration_sla_burn_rate{service_name="orchestrator-dynamic", window_hours="1"}

# Alertas crÃ­ticos enviados
rate(orchestration_sla_alerts_sent_total{severity="CRITICAL"}[5m])

# Taxa de violaÃ§Ãµes por tipo
rate(orchestration_sla_violations_published_total[5m]) by (violation_type)

# LatÃªncia P95 de verificaÃ§Ãµes SLA
histogram_quantile(0.95, rate(orchestration_sla_check_duration_seconds_bucket[5m])) by (check_type)
```

### Alertas Prometheus

Ver regras em `monitoring/alerts/orchestrator-sla-alerts.yaml`:

- **SLABudgetCritical**: Budget < 20%
- **SLABudgetExhausted**: Budget = 0%
- **SLAHighBurnRate**: Taxa de consumo > 10x em 1h
- **SLAViolationRate**: Taxa de violaÃ§Ãµes > threshold

### Troubleshooting

**Erro: "kafka_producer_not_configured"**
- Verificar conectividade Kafka: `kubectl exec -it <pod> -- nc -zv kafka-bootstrap 9092`
- Revisar logs de inicializaÃ§Ã£o do produtor

**Erro: "sla_api_request_error"**
- Verificar SLA Management System: `kubectl get pods -l app=sla-management-system`
- Testar endpoint: `curl http://sla-management-system:8000/api/v1/budgets?service_name=orchestrator-dynamic`

**Alertas nÃ£o sendo enviados**
- Verificar mÃ©trica `orchestration_sla_monitor_errors_total{error_type="producer_not_initialized"}`
- Verificar deduplicaÃ§Ã£o: `orchestration_sla_alert_deduplication_hits_total`

**ViolaÃ§Ãµes nÃ£o detectadas**
- Verificar se tickets possuem `started_at` e `completed_at` preenchidos
- Revisar campo `duration_source` em metadata da violaÃ§Ã£o (persisted/calculated/estimated)

### Monitoramento Proativo (Opcional)

O orchestrator suporta verificaÃ§Ãµes proativas de SLA durante execuÃ§Ã£o do workflow, controlado por feature flag:

```bash
# Habilitar monitoramento proativo
SLA_PROACTIVE_MONITORING_ENABLED=true
```

**Checkpoints:**
- **PÃ³s C2 (geraÃ§Ã£o de tickets)**: Early warning de deadline approaching
- **PÃ³s C4 (publicaÃ§Ã£o)**: VerificaÃ§Ã£o final antes da consolidaÃ§Ã£o

**Trade-offs:**
- **PrÃ³s**: DetecÃ§Ã£o precoce, capacidade de aÃ§Ã£o preventiva
- **Cons**: Adiciona 50-100ms de latÃªncia por check

**Quando usar:**
- Workflows com SLA muito restritivo (<5 minutos)
- Necessidade de early warning para acionar burst capacity
- Workflows complexos com mÃºltiplos estÃ¡gios

### Alertas Slack e PagerDuty

ConfiguraÃ§Ã£o de alertas externos via Alertmanager:

**ConfiguraÃ§Ã£o Slack:**

```yaml
# Ver: monitoring/alertmanager/alertmanager-slack-pagerduty-config.yaml
receivers:
  - name: 'slack-sla-warnings'
    slack_configs:
      - channel: '#sla-alerts'
        api_url: 'https://hooks.slack.com/services/YOUR_WEBHOOK_URL'
```

**ConfiguraÃ§Ã£o PagerDuty:**

```yaml
receivers:
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'YOUR_INTEGRATION_KEY'
        severity: 'critical'
```

**Routing de Alertas:**
- **CrÃ­tico (budget <20%, deadline exceeded)** â†’ PagerDuty
- **Warning (deadline approaching, burn rate alto)** â†’ Slack
- **Info** â†’ Logs apenas

**Templates Customizados:**
- Template Slack com contexto rico: `monitoring/alertmanager/slack-message-template.tmpl`
- Suporte para mÃºltiplos tipos de alerta (budget, deadline, burn rate)
- FormataÃ§Ã£o com emojis e links para dashboards

### Dashboards Grafana

#### Dashboard Principal (`fluxo-c-orquestracao`)

**Row: SLA Compliance & Alerting** (8 painÃ©is):

| Painel | DescriÃ§Ã£o | Threshold |
|--------|-----------|-----------|
| **SLA Remaining Time** | Tempo mÃ­nimo restante de SLA | <60s vermelho, 60-300s amarelo |
| **Error Budget Status** | Percentual de budget restante | <20% vermelho, 20-50% amarelo |
| **SLA Violations (Last Hour)** | Total de violaÃ§Ãµes | >0 vermelho |
| **Deadline Approaching** | Workflows crÃ­ticos (Ãºltimos 15min) | >10 vermelho |
| **SLA Alerts Sent** | Taxa de alertas por tipo | - |
| **Budget Burn Rate** | Taxa de consumo (1h window) | >6 warning, >10 critical |
| **SLA Check Performance** | P95 latÃªncia de verificaÃ§Ãµes | >5s alerta |
| **Alert Deduplication Rate** | % de alertas bloqueados | Monitor tendÃªncia |

**Acesso:** http://grafana/d/fluxo-c-orchestration

### Guia Completo

DocumentaÃ§Ã£o detalhada disponÃ­vel em:

**ğŸ“– [SLA Monitoring Guide](docs/SLA_MONITORING_GUIDE.md)**

Inclui:
- Arquitetura detalhada com diagramas
- ConfiguraÃ§Ã£o completa (SLA Management System, Redis, Kafka)
- Runbooks para alertas crÃ­ticos
- Troubleshooting avanÃ§ado
- Melhores prÃ¡ticas de SLA e capacity planning
- Exemplos de queries PromQL
- Testes de integraÃ§Ã£o real

### Testes de IntegraÃ§Ã£o Real

Testes com serviÃ§os reais (SLA Management System, Redis, Kafka):

```bash
# Executar testes reais (requer serviÃ§os rodando)
SLA_MANAGEMENT_HOST=localhost \
REDIS_HOST=localhost:6379 \
KAFKA_BOOTSTRAP_SERVERS=localhost:9092 \
pytest -m real_integration tests/integration/test_sla_real_integration.py -v

# Pular testes reais (padrÃ£o)
pytest -m "not real_integration"
```

**CenÃ¡rios testados:**
- Fetch de budget do SLA Management System
- VerificaÃ§Ã£o de threshold
- DetecÃ§Ã£o de deadline approaching
- PublicaÃ§Ã£o de alertas ao Kafka
- Caching Redis end-to-end
- DeduplicaÃ§Ã£o de alertas
- Fluxo completo de monitoramento

### MÃ©tricas Adicionais

AlÃ©m das mÃ©tricas listadas acima, o sistema SLA tambÃ©m exporta:

```promql
# Tempo restante por workflow
orchestration_sla_remaining_seconds{workflow_id="...", risk_band="..."}

# Status do budget (0=HEALTHY, 1=WARNING, 2=CRITICAL, 3=EXHAUSTED)
orchestration_sla_budget_status{service_name="orchestrator-dynamic", status="..."}

# Deadline approaching por risk band
orchestration_deadline_approaching_total

# Erros no monitor SLA por tipo
orchestration_sla_monitor_errors_total{error_type="api_error|cache_error|..."}
```

## Policy Enforcement com OPA

O Orchestrator Dynamic integra com Open Policy Agent (OPA) para enforcement de polÃ­ticas de governanÃ§a em tempo de execuÃ§Ã£o.

### PolÃ­ticas Implementadas

#### 1. Resource Limits (`neuralhive/orchestrator/resource_limits`)

Valida limites de recursos em execution tickets:
- Timeout mÃ¡ximo por risk_band (critical: 2h, high: 1h, medium: 30min, low: 15min)
- NÃºmero mÃ¡ximo de retries por risk_band (critical: 5, high: 3, medium: 2, low: 1)
- Capabilities permitidas (whitelist configurÃ¡vel)
- ParÃ¢metros de recursos (CPU, memÃ³ria)
- Limite de tickets concorrentes (default: 100)

#### 2. SLA Enforcement (`neuralhive/orchestrator/sla_enforcement`)

Enforce constraints de SLA:
- Deadline vÃ¡lido (futuro, nÃ£o muito distante)
- Alinhamento QoS/risk_band (critical/high exigem EXACTLY_ONCE + STRONG)
- Alinhamento priority/risk_band
- Timeout suficiente para estimated_duration (>= 1.5x)
- Budget de SLA disponÃ­vel

#### 3. Feature Flags (`neuralhive/orchestrator/feature_flags`)

Controle dinÃ¢mico de funcionalidades:
- **Intelligent Scheduler**: Habilitado para namespaces permitidos e risk_bands critical/high
- **Burst Capacity**: Habilitado para tenants premium quando carga < threshold
- **Predictive Allocation**: Habilitado para beta testing com model_accuracy > 0.85
- **Auto-scaling**: Habilitado quando queue_depth > threshold e dentro de horÃ¡rio comercial

### Pontos de IntegraÃ§Ã£o

#### C1: ValidaÃ§Ã£o de Plano Cognitivo

ApÃ³s validaÃ§Ã£o de schema, o plano completo Ã© validado contra polÃ­ticas OPA:

```python
policy_result = await policy_validator.validate_cognitive_plan(cognitive_plan)
```

Se violaÃ§Ãµes forem encontradas, o workflow Ã© rejeitado antes de gerar tickets.

#### C3: AlocaÃ§Ã£o de Recursos

Antes de alocar recursos, cada ticket Ã© validado individualmente:

```python
policy_result = await policy_validator.validate_execution_ticket(ticket)
```

Feature flags sÃ£o obtidos das decisÃµes de polÃ­ticas e usados para controlar comportamento do scheduler.

### ConfiguraÃ§Ã£o OPA

Configurar via variÃ¡veis de ambiente ou Helm values:

```yaml
config:
  opa:
    enabled: true
    host: opa.neural-hive-orchestration.svc.cluster.local
    port: 8181
    timeoutSeconds: 2
    failOpen: false  # fail-closed por padrÃ£o

    policies:
      maxConcurrentTickets: 100
      allowedCapabilities: [code_generation, deployment, testing, validation]
      resourceLimits:
        maxCpu: "4000m"
        maxMemory: "8Gi"

    featureFlags:
      intelligentSchedulerEnabled: true
      burstCapacityEnabled: true
```

### MÃ©tricas OPA

MÃ©tricas Prometheus disponÃ­veis:
- `opa_validations_total{policy_name, result}` - Total de validaÃ§Ãµes por polÃ­tica
- `opa_validation_duration_seconds{policy_name}` - LatÃªncia das avaliaÃ§Ãµes
- `opa_policy_rejections_total{policy_name, rule, severity}` - RejeiÃ§Ãµes por regra
- `opa_policy_warnings_total{policy_name, rule}` - Avisos por regra
- `opa_evaluation_errors_total{error_type}` - Erros de avaliaÃ§Ã£o ou indisponibilidade do OPA

### Troubleshooting OPA

**Erro: "OPA connection timeout"**
- Verificar se OPA server estÃ¡ rodando: `kubectl get pods -n neural-hive-orchestration -l app=opa`
- Verificar logs do OPA: `kubectl logs -n neural-hive-orchestration -l app=opa`

**Tickets sendo rejeitados inesperadamente**
- Verificar mÃ©tricas de rejeiÃ§Ãµes: `orchestration_opa_policy_rejections_total`
- Revisar polÃ­ticas Rego em `policies/rego/orchestrator/`

## ML Predictions e DetecÃ§Ã£o de Anomalias

O Orchestrator Dynamic incorpora um subsistema de Machine Learning para prediÃ§Ã£o inteligente de duraÃ§Ã£o de tickets, estimativa de recursos e detecÃ§Ã£o de anomalias.

### VisÃ£o Geral

O sistema ML enriquece tickets com prediÃ§Ãµes antes da alocaÃ§Ã£o de recursos, permitindo:
- **PrediÃ§Ã£o de duraÃ§Ã£o**: Estimativa mais precisa do tempo de execuÃ§Ã£o usando RandomForest Regression
- **Estimativa de recursos**: CÃ¡lculo dinÃ¢mico de CPU e memÃ³ria necessÃ¡rios baseado em duraÃ§Ã£o prevista
- **DetecÃ§Ã£o de anomalias**: IdentificaÃ§Ã£o de tickets com configuraÃ§Ãµes atÃ­picas usando Isolation Forest
- **Treinamento incremental**: Retreinamento periÃ³dico com dados histÃ³ricos do MongoDB

### Componentes

#### DurationPredictor
RandomForest Regressor para prediÃ§Ã£o de `actual_duration_ms` baseado em 15+ features:
- Features de risco e QoS: `risk_weight`, `qos_delivery_score`, `qos_consistency_score`
- Features de complexidade: `capabilities_count`, `task_type_encoded`, `parameters_size`
- Features histÃ³ricas: `avg_duration_by_task`, `success_rate_by_task`, `std_duration_by_task`
- Features temporais: `hour_of_day`, `retry_count`

MÃ©tricas de performance: MAE, RMSE, R2, MAE% (target < 15%)

#### AnomalyDetector
Isolation Forest para detecÃ§Ã£o de tickets anÃ´malos:
- **resource_mismatch**: Risk band baixo mas muitas capabilities
- **qos_inconsistency**: QoS incompatÃ­vel com task_type
- **duration_outlier**: DuraÃ§Ã£o muito diferente do histÃ³rico
- **capability_anomaly**: NÃºmero anormal de capabilities

Contamination rate: 5% (configurÃ¡vel)

#### ModelRegistry
IntegraÃ§Ã£o com MLflow para ciclo de vida de modelos:
- Versionamento automÃ¡tico de modelos treinados
- PromoÃ§Ã£o para Production se mÃ©tricas atingirem thresholds
- Cache LRU de modelos carregados
- Experimento MLflow: `orchestrator-predictive-models`

#### TrainingPipeline
Pipeline de treinamento incremental:
- Query automÃ¡tica de dados histÃ³ricos (MongoDB `execution_tickets`)
- Feature engineering com estatÃ­sticas agregadas
- Treinamento paralelo de ambos os modelos
- Agendamento periÃ³dico (padrÃ£o: 24h)
- MÃ­nimo de amostras: 100 tickets completados

### IntegraÃ§Ã£o com Workflow C3

As prediÃ§Ãµes ML sÃ£o integradas na etapa **allocate_resources** (C3):

1. **ValidaÃ§Ã£o OPA** â†’ polÃ­ticas aplicadas
2. **ML Predictions** â†’ ticket enriquecido com campo `predictions`:
   ```python
   {
       "duration_ms": 75230.5,           # DuraÃ§Ã£o prevista
       "duration_confidence": 0.85,       # ConfianÃ§a (0-1)
       "resource_estimate": {
           "cpu_m": 650,                  # Millicores
           "memory_mb": 768               # MiB
       },
       "anomaly": {
           "is_anomaly": false,
           "anomaly_score": 0.12,
           "anomaly_type": null,
           "explanation": "Ticket dentro do padrÃ£o esperado"
       }
   }
   ```
3. **Intelligent Scheduler** â†’ ajusta prioridade se `predicted_duration > 1.5 * estimated_duration`
4. **Allocation Metadata** â†’ inclui `predicted_duration_ms` e `anomaly_detected`

### Features ExtraÃ­das

| Feature | Tipo | Range | DescriÃ§Ã£o |
|---------|------|-------|-----------|
| `risk_weight` | float | 0.3-1.0 | Peso do risk_band (critical=1.0) |
| `qos_delivery_score` | float | 0.5-1.0 | Score de delivery_guarantee |
| `qos_consistency_score` | float | 0.85-1.0 | Score de consistency_level |
| `capabilities_count` | int | 0-n | NÃºmero de capabilities requeridas |
| `task_type_encoded` | int | 0-6 | Task type codificado (BUILD=0, ...) |
| `parameters_size` | int | 0-n | Tamanho serializado de parameters |
| `estimated_duration_ms` | float | >0 | DuraÃ§Ã£o estimada do ticket |
| `sla_timeout_ms` | float | >0 | Timeout de SLA |
| `avg_duration_by_task` | float | >0 | MÃ©dia histÃ³rica por task_type |
| `avg_duration_by_risk` | float | >0 | MÃ©dia histÃ³rica por risk_band |
| `success_rate_by_task` | float | 0-1 | Taxa de sucesso histÃ³rica |
| `std_duration_by_task` | float | â‰¥0 | Desvio padrÃ£o histÃ³rico |
| `retry_count` | int | â‰¥0 | NÃºmero de retries do ticket |
| `hour_of_day` | int | 0-23 | Hora de criaÃ§Ã£o (padrÃ£o temporal) |

### MÃ©tricas Prometheus

8 novas mÃ©tricas para observabilidade do subsistema ML:

```promql
# Total de prediÃ§Ãµes executadas
orchestration_ml_predictions_total{model_type="duration|anomaly", status="success|error"}

# LatÃªncia de prediÃ§Ãµes (P50, P95, P99)
histogram_quantile(0.95, rate(orchestration_ml_prediction_duration_seconds_bucket[5m]))

# Erro de prediÃ§Ã£o (actual - predicted)
orchestration_ml_prediction_error{model_type="duration"}

# Anomalias detectadas por tipo
orchestration_ml_anomalies_detected_total{anomaly_type="resource_mismatch|qos_inconsistency|..."}

# Erros de carregamento de modelos
orchestration_ml_model_load_errors_total{model_name="ticket-duration-predictor|ticket-anomaly-detector"}

# DuraÃ§Ã£o de treinamento
orchestration_ml_training_duration_seconds{model_type="duration|anomaly"}

# MÃ©tricas de acurÃ¡cia dos modelos
orchestration_ml_model_accuracy{model_name="...", metric_type="mae_pct|r2|precision|recall|f1"}

# Erros de extraÃ§Ã£o de features
orchestration_ml_feature_extraction_errors_total
```

### ConfiguraÃ§Ã£o

VariÃ¡veis de ambiente para ML Predictions:

```bash
# Habilitar/desabilitar prediÃ§Ãµes ML
ML_PREDICTIONS_ENABLED=true

# MLflow Tracking Server
MLFLOW_TRACKING_URI=http://mlflow.mlflow.svc.cluster.local:5000
MLFLOW_EXPERIMENT_NAME=orchestrator-predictive-models

# ParÃ¢metros de treinamento
ML_TRAINING_WINDOW_DAYS=30               # Janela de dados histÃ³ricos
ML_TRAINING_INTERVAL_HOURS=24            # Intervalo de retreinamento
ML_MIN_TRAINING_SAMPLES=100              # MÃ­nimo de amostras
ML_DURATION_ERROR_THRESHOLD=0.15         # MAE mÃ¡ximo: 15%
ML_ANOMALY_CONTAMINATION=0.05            # Taxa esperada de anomalias: 5%

# Cache
ML_MODEL_CACHE_TTL_SECONDS=3600          # TTL de modelos (1h)
ML_FEATURE_CACHE_TTL_SECONDS=3600        # TTL de features (1h)
```

### Troubleshooting

**MLflow connection failed**
```bash
# Verificar MLflow disponÃ­vel
kubectl port-forward -n mlflow svc/mlflow 5000:5000
curl http://localhost:5000/health

# Verificar logs do predictor
kubectl logs -n orchestrator deployment/orchestrator-dynamic | grep "ml_predictor"
```

**Insufficient training data**
- Verificar tickets no MongoDB: `db.execution_tickets.countDocuments({status: 'COMPLETED'})`
- Ajustar `ML_MIN_TRAINING_SAMPLES` se necessÃ¡rio
- Aguardar acÃºmulo de dados histÃ³ricos (30 dias padrÃ£o)

**High prediction errors (MAE > 15%)**
```bash
# Verificar mÃ©tricas de acurÃ¡cia
kubectl port-forward -n orchestrator svc/prometheus 9090:9090
# Query: orchestration_ml_model_accuracy{metric_type="mae_pct"}

# ForÃ§ar retreinamento
kubectl exec -n orchestrator deployment/orchestrator-dynamic -- python -c "
from src.ml import TrainingPipeline
import asyncio
asyncio.run(pipeline.run_training_cycle())
"
```

**Models not being promoted**
- Verificar critÃ©rios de promoÃ§Ã£o:
  - Duration predictor: MAE% < 15%
  - Anomaly detector: Precision > 0.75
- Ajustar thresholds via `ML_DURATION_ERROR_THRESHOLD`
- Verificar logs de treinamento para mÃ©tricas

**Predictions nÃ£o aparecem nos tickets**
- Verificar `ML_PREDICTIONS_ENABLED=true`
- Verificar logs de inicializaÃ§Ã£o do worker
- Validar MongoDB disponÃ­vel (required)
- Checar mÃ©tricas: `orchestration_ml_predictions_total`

### Dashboards e Alertas

**Grafana Dashboard**: `monitoring/dashboards/orchestrator-ml-predictions.json`
- Overview de prediÃ§Ãµes e anomalias
- Performance de modelos (latÃªncia, acurÃ¡cia)
- DistribuiÃ§Ã£o de erros de prediÃ§Ã£o
- Status de treinamento

**Prometheus Alerts**: `monitoring/alerts/orchestrator-ml-alerts.yaml`
- `MLPredictionHighErrorRate`: Taxa de erro > 20%
- `MLPredictionLatencyHigh`: P95 > 2s
- `MLModelLoadFailure`: Falhas ao carregar modelos
- `MLDurationPredictionInaccurate`: MAE > 15%
- `MLTrainingFailed`: Erros em treinamento
- `MLTrainingStale`: Sem treinamento > 48h

## ğŸ¤– ML Feedback Loop

O Orchestrator Dynamic implementa um feedback loop completo para treinamento contÃ­nuo de modelos ML:

### Componentes

1. **PrediÃ§Ãµes em Tempo Real:**
   - PrediÃ§Ã£o de duraÃ§Ã£o de tickets (RandomForest)
   - DetecÃ§Ã£o de anomalias (Isolation Forest)
   - PrediÃ§Ã£o de queue time e carga de workers
2. **Priority Boosting:**
   - Tickets com `duration_ratio > 1.5`: +20% prioridade
   - Tickets com anomalia detectada: +20% prioridade
3. **Error Tracking:**
   - Calcula erro: `actual_duration_ms - predicted_duration_ms`
   - Registra em Prometheus: `ml_prediction_error`
   - Log estruturado com erro percentual
4. **Allocation Outcome Feedback:**
   - Publica outcomes no Kafka `ml.allocation_outcomes`
   - Usado para treinamento de RL policy (Q-learning)
   - MÃ©tricas de allocation quality
5. **Treinamento Offline:**
   - CronJob periÃ³dico (24h) ou por drift detection
   - Retreina modelos com dados histÃ³ricos (18 meses)
   - Promove modelos para Production no MLflow

### ConfiguraÃ§Ã£o

```yaml
ML_PREDICTIONS_ENABLED: true
ML_ALLOCATION_OUTCOMES_ENABLED: true
ML_TRAINING_WINDOW_DAYS: 540
ML_DURATION_ERROR_THRESHOLD: 0.15
```

### MÃ©tricas

- `orchestration_ml_prediction_error`: Erro de prediÃ§Ã£o (Histogram)
- `orchestration_ml_model_accuracy`: AcurÃ¡cia do modelo (Gauge)
- `orchestration_scheduler_allocation_quality_score`: Qualidade de alocaÃ§Ã£o (Histogram)

### DocumentaÃ§Ã£o Detalhada

Ver `docs/ML_FEEDBACK_LOOP_ARCHITECTURE.md` para arquitetura completa.

## Schemas

### Execution Ticket (Avro)
Ver: `schemas/execution-ticket/execution-ticket.avsc`

**Campos principais**:
- `ticket_id`, `plan_id`, `intent_id`, `decision_id`
- `task_id`, `task_type`, `description`, `dependencies`
- `status`, `priority`, `risk_band`
- `sla` (deadline, timeout_ms, max_retries)
- `qos` (delivery_mode, consistency, durability)
- `created_at`, `started_at`, `completed_at`
- `retry_count`, `error_message`, `compensation_ticket_id`

## ConfiguraÃ§Ã£o

Todas as configuraÃ§Ãµes sÃ£o gerenciadas via variÃ¡veis de ambiente ou arquivo `.env`:

```bash
# Temporal
TEMPORAL_HOST=temporal-frontend.temporal.svc.cluster.local
TEMPORAL_PORT=7233
TEMPORAL_NAMESPACE=neural-hive-mind
TEMPORAL_TASK_QUEUE=orchestration-tasks

# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka-bootstrap.kafka.svc.cluster.local:9092
KAFKA_CONSENSUS_TOPIC=plans.consensus
KAFKA_TICKETS_TOPIC=execution.tickets
KAFKA_CONSUMER_GROUP_ID=orchestrator-dynamic

# PostgreSQL (Temporal State)
POSTGRES_HOST=postgres-temporal-headless.temporal-postgres.svc.cluster.local
POSTGRES_PORT=5432
POSTGRES_DATABASE=temporal
POSTGRES_USER=temporal
POSTGRES_PASSWORD=<secret>

# MongoDB (Auditoria)
MONGODB_URI=mongodb://mongodb-0.mongodb-headless:27017,.../?replicaSet=rs0
MONGODB_DATABASE=neural_hive_orchestration

# Redis (Cache)
REDIS_CLUSTER_NODES=redis-cluster.redis-cluster.svc.cluster.local:6379

# Service Registry
SERVICE_REGISTRY_HOST=service-registry.neural-hive-execution.svc.cluster.local
SERVICE_REGISTRY_PORT=50051
SERVICE_REGISTRY_TIMEOUT_SECONDS=3
SERVICE_REGISTRY_MAX_RESULTS=5
SERVICE_REGISTRY_CACHE_TTL_SECONDS=10

# SLA e Scheduler
ENABLE_INTELLIGENT_SCHEDULER=true
SCHEDULER_MAX_PARALLEL_TICKETS=100
SLA_DEFAULT_TIMEOUT_MS=3600000

# OPA / Policy Validation
OPA_ENABLED=true
OPA_HOST=opa.neural-hive-orchestration.svc.cluster.local
OPA_FAIL_OPEN=false
OPA_INTELLIGENT_SCHEDULER_ENABLED=true
OPA_BURST_CAPACITY_ENABLED=true

# Observabilidade
OTEL_EXPORTER_ENDPOINT=http://otel-collector:4317
LOG_LEVEL=INFO
```

## MÃ©tricas Prometheus

O serviÃ§o exporta 20+ mÃ©tricas em `/metrics`:

**Workflows**:
- `orchestration_workflows_started_total`
- `orchestration_workflows_completed_total`
- `orchestration_workflow_duration_seconds`
- `orchestration_workflows_active`

**Tickets**:
- `orchestration_tickets_generated_total`
- `orchestration_tickets_published_total`
- `orchestration_tickets_completed_total`
- `orchestration_ticket_generation_duration_seconds`

**SLA**:
- `orchestration_sla_violations_total`
- `orchestration_sla_remaining_seconds`
- `orchestration_deadline_approaching_total`

**Kafka**:
- `orchestration_kafka_messages_consumed_total`
- `orchestration_kafka_messages_produced_total`
- `orchestration_kafka_consumer_lag`
- `orchestration_kafka_errors_total`

**Scheduler**:
- `orchestration_scheduler_allocations_total`
- `orchestration_scheduler_allocation_duration_seconds`
- `orchestration_scheduler_workers_discovered`
- `orchestration_scheduler_discovery_failures_total`
- `orchestration_scheduler_priority_score`
- `orchestration_scheduler_cache_hits_total`

**Outros**: retries, compensations, validations, resources

## Deployment

### Via Script (Recomendado)
```bash
cd /path/to/Neural-Hive-Mind

# Deploy completo (build, push, secrets, helm)
./scripts/deploy/deploy-orchestrator-dynamic.sh

# ValidaÃ§Ã£o completa
./scripts/validation/validate-orchestrator-dynamic.sh
```

### Via Helm Manual
```bash
cd helm-charts/orchestrator-dynamic

# Lint
helm lint .

# Install/Upgrade
helm upgrade --install orchestrator-dynamic . \
  --namespace neural-hive-orchestration \
  --create-namespace \
  --values values.yaml \
  --set image.tag=1.0.0 \
  --wait
```

## Desenvolvimento Local

### Prerequisites
- Python 3.11+
- Docker
- Temporal CLI (opcional, para debugging)
- Kafka running
- PostgreSQL running
- MongoDB running

### Setup
```bash
cd services/orchestrator-dynamic

# Criar virtualenv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar .env
cp .env.example .env
# Editar .env com credenciais locais

# Run
python -m src.main
```

### Testes
```bash
# Unit tests
pytest tests/

# ML feedback loop
pytest tests/integration/test_ml_feedback_loop_integration.py tests/unit/test_ml_prediction_integration.py -v

# OPA integration (C1-C3)
pytest tests/test_policy_integration_c3.py tests/test_policy_integration_e2e.py -v

# Linting
black src/
flake8 src/
mypy src/

# Integration test
./tests/phase2-orchestrator-test.sh
```

## Monitoramento

### Grafana Dashboard
Ver: `docs/observability/dashboards/orchestration-flow-c.json`

**Rows**:
1. Overview (workflows started/completed, success rate)
2. Workflow Duration (P50/P95/P99)
3. Tickets (generated, published, completed)
4. SLA Tracking (violations, remaining time, compliance)
5. Retry and Compensation
6. Kafka Integration
7. Validations and Optimizations
8. Resources (CPU, Memory, Pods)
9. Logs and Traces

### Jaeger
Traces disponÃ­veis em: `http://jaeger-query:16686`
- Filtrar por service: `orchestrator-dynamic`
- Buscar por workflow_id ou plan_id
- Visualizar correlaÃ§Ã£o intent_id â†’ plan_id â†’ workflow_id â†’ ticket_ids

## Troubleshooting

### Workflow nÃ£o inicia
```bash
# Verificar consumer Kafka
kubectl logs -n neural-hive-orchestration -l app.kubernetes.io/name=orchestrator-dynamic | grep "Consumer"

# Verificar mensagens no tÃ³pico
kubectl exec -n kafka kafka-0 -- kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic plans.consensus \
  --from-beginning --max-messages 10
```

### Tickets nÃ£o sÃ£o publicados
```bash
# Verificar logs de activities
kubectl logs -n neural-hive-orchestration -l app.kubernetes.io/name=orchestrator-dynamic | grep "publish_ticket"

# Verificar tÃ³pico execution.tickets
kubectl exec -n kafka kafka-0 -- kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic execution.tickets
```

### SLA violations altos
```bash
# Verificar mÃ©tricas
curl http://<pod-ip>:9090/metrics | grep sla_violations

# Ajustar timeouts em values.yaml
helm upgrade orchestrator-dynamic . \
  --set config.sla.defaultTimeoutMs=7200000  # 2 horas
```

## Roadmap

### Fase 2.2 - QoS e PolÃ­ticas (PrÃ³ximo)
- [ ] Scheduler Inteligente com balanceamento de carga
- [ ] IntegraÃ§Ã£o OPA para validaÃ§Ã£o de polÃ­ticas
- [ ] Alertas automÃ¡ticos para SLA violations
- [ ] Modelos preditivos para estimativa de duraÃ§Ã£o

### Fase 2.3 - IntegraÃ§Ãµes AvanÃ§adas
- [ ] Service Registry para discovery de Worker Agents
- [ ] Tokens efÃªmeros via Vault/SPIFFE
- [ ] FeromÃ´nios digitais para ajuste dinÃ¢mico
- [ ] Replay de workflows para debugging

## ReferÃªncias

- [Documento 06 - Fluxos e Processos](../../documento-06-fluxos-processos-neural-hive-mind.md)
- [OrquestraÃ§Ã£o - VisÃ£o Detalhada](../../docs/observability/services/orquestracao.md)
- [Execution Ticket Schema](../../schemas/execution-ticket/execution-ticket.avsc)
- [Temporal Documentation](https://docs.temporal.io/)
- [PHASE2_IMPLEMENTATION_STATUS.md](../../PHASE2_IMPLEMENTATION_STATUS.md)

---

**Mantenedores**: Neural Hive-Mind Team
**Ãšltima atualizaÃ§Ã£o**: 2025-10-03
**LicenÃ§a**: ProprietÃ¡ria
