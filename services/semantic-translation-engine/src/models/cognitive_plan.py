"""
Cognitive Plan Data Models

Define os modelos Pydantic para Planos Cognitivos (artefato central do Fluxo B).
"""

import uuid
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from enum import Enum
from pydantic import BaseModel, Field, validator


class RiskBand(str, Enum):
    """Risk classification bands"""
    LOW = 'low'
    MEDIUM = 'medium'
    HIGH = 'high'
    CRITICAL = 'critical'


class PlanStatus(str, Enum):
    """Plan status"""
    DRAFT = 'draft'
    VALIDATED = 'validated'
    APPROVED = 'approved'
    REJECTED = 'rejected'


class TaskNode(BaseModel):
    """Individual task node in the DAG"""

    task_id: str = Field(..., description='Unique task ID')
    task_type: str = Field(..., description='Task type (query, transform, validate, etc.)')
    description: str = Field(..., description='Task description')
    dependencies: List[str] = Field(
        default_factory=list,
        description='IDs of predecessor tasks'
    )
    estimated_duration_ms: Optional[int] = Field(
        None,
        description='Estimated duration in milliseconds'
    )
    required_capabilities: List[str] = Field(
        default_factory=list,
        description='Required capabilities'
    )
    parameters: Dict[str, Any] = Field(
        default_factory=dict,
        description='Task parameters'
    )
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description='Additional metadata'
    )

    class Config:
        use_enum_values = True


class CognitivePlan(BaseModel):
    """
    Cognitive Plan generated by Semantic Translation Engine

    Represents the output of Fluxo B (B1-B6), containing:
    - DAG of executable tasks
    - Risk assessment
    - Explainability information
    - Execution metadata
    """

    # Plan identification
    plan_id: str = Field(
        default_factory=lambda: str(uuid.uuid4()),
        description='Unique plan ID'
    )
    version: str = Field(default='1.0.0', description='Plan version')
    intent_id: str = Field(..., description='Originating intent ID')
    correlation_id: Optional[str] = Field(None, description='Correlation ID')
    trace_id: Optional[str] = Field(None, description='OpenTelemetry trace ID')
    span_id: Optional[str] = Field(None, description='OpenTelemetry span ID')

    # DAG of tasks
    tasks: List[TaskNode] = Field(..., description='List of tasks in the plan')
    execution_order: List[str] = Field(..., description='Topological execution order')

    # Risk assessment
    risk_score: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description='Risk score (0-1)'
    )
    risk_band: RiskBand = Field(..., description='Risk classification')
    risk_factors: Dict[str, float] = Field(
        default_factory=dict,
        description='Individual risk factors'
    )

    # Explainability
    explainability_token: str = Field(..., description='Token for detailed explanation')
    reasoning_summary: str = Field(..., description='Reasoning summary')

    # Metadata
    status: PlanStatus = Field(default=PlanStatus.DRAFT, description='Plan status')
    created_at: datetime = Field(
        default_factory=datetime.utcnow,
        description='Creation timestamp'
    )
    valid_until: Optional[datetime] = Field(None, description='Plan validity')
    estimated_total_duration_ms: Optional[int] = Field(
        None,
        description='Total estimated duration'
    )
    complexity_score: float = Field(..., ge=0.0, description='Complexity score')

    # Original context
    original_domain: str = Field(..., description='Original intent domain')
    original_priority: str = Field(..., description='Original priority')
    original_security_level: str = Field(..., description='Original security level')

    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description='Additional metadata'
    )

    @validator('tasks')
    def validate_dag_acyclic(cls, v):
        """Validate that the DAG is acyclic"""
        import networkx as nx

        if not v:
            return v

        # Build graph
        G = nx.DiGraph()
        for task in v:
            G.add_node(task.task_id)
            for dep in task.dependencies:
                G.add_edge(dep, task.task_id)

        # Check for cycles
        if not nx.is_directed_acyclic_graph(G):
            cycles = list(nx.simple_cycles(G))
            raise ValueError(f'DAG contains cycles: {cycles}')

        return v

    @validator('execution_order')
    def validate_execution_order(cls, v, values):
        """Validate execution order matches tasks"""
        if 'tasks' not in values:
            return v

        task_ids = {task.task_id for task in values['tasks']}
        order_ids = set(v)

        if task_ids != order_ids:
            missing = task_ids - order_ids
            extra = order_ids - task_ids
            raise ValueError(
                f'Execution order mismatch. Missing: {missing}, Extra: {extra}'
            )

        return v

    def to_avro_dict(self) -> Dict[str, Any]:
        """Convert to Avro-compatible dictionary"""
        return {
            'plan_id': self.plan_id,
            'version': self.version,
            'intent_id': self.intent_id,
            'correlation_id': self.correlation_id,
            'trace_id': self.trace_id,
            'span_id': self.span_id,
            'tasks': [
                {
                    'task_id': task.task_id,
                    'task_type': task.task_type,
                    'description': task.description,
                    'dependencies': task.dependencies,
                    'estimated_duration_ms': task.estimated_duration_ms,
                    'required_capabilities': task.required_capabilities,
                    'parameters': task.parameters,
                    'metadata': task.metadata
                }
                for task in self.tasks
            ],
            'execution_order': self.execution_order,
            'risk_score': self.risk_score,
            'risk_band': self.risk_band.value,
            'risk_factors': self.risk_factors,
            'explainability_token': self.explainability_token,
            'reasoning_summary': self.reasoning_summary,
            'status': self.status.value,
            'created_at': int(self.created_at.timestamp() * 1000),
            'valid_until': int(self.valid_until.timestamp() * 1000) if self.valid_until else None,
            'estimated_total_duration_ms': self.estimated_total_duration_ms,
            'complexity_score': self.complexity_score,
            'original_domain': self.original_domain,
            'original_priority': self.original_priority,
            'original_security_level': self.original_security_level,
            'metadata': self.metadata,
            'schema_version': 1
        }

    def get_partition_key(self) -> str:
        """Get partition key for Kafka (by domain)"""
        return self.original_domain

    def to_cache_dict(self) -> Dict[str, Any]:
        """Compact version for Redis cache"""
        return {
            'plan_id': self.plan_id,
            'intent_id': self.intent_id,
            'risk_band': self.risk_band.value,
            'status': self.status.value,
            'num_tasks': len(self.tasks),
            'created_at': self.created_at.isoformat()
        }

    class Config:
        use_enum_values = True
        validate_assignment = True
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
