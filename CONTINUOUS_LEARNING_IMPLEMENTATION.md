# Sistema de Continuous Learning com Feedback Humano - Neural Hive Mind

## ğŸ“‹ VisÃ£o Geral

Sistema completo de **continuous learning** implementado para os especialistas do Neural Hive Mind, permitindo que revisores humanos forneÃ§am feedback sobre opiniÃµes e que o sistema re-treine automaticamente os modelos quando threshold de feedback Ã© atingido.

## ğŸ¯ Funcionalidades Implementadas

### 1. Coleta de Feedback Humano
- âœ… API REST para submissÃ£o de feedback via HTTP
- âœ… ValidaÃ§Ã£o rigorosa com Pydantic schemas
- âœ… AutenticaÃ§Ã£o JWT para controle de acesso
- âœ… PersistÃªncia em MongoDB com Ã­ndices otimizados
- âœ… Auditoria completa via AuditLogger
- âœ… Circuit breaker para resiliÃªncia

### 2. Trigger AutomÃ¡tico de Re-treinamento
- âœ… Monitoramento de threshold de feedback (default: â‰¥100 feedbacks/semana)
- âœ… Cooldown de 24h para evitar triggers duplicados
- âœ… IntegraÃ§Ã£o com MLflow para disparar pipelines
- âœ… HistÃ³rico completo de triggers no MongoDB
- âœ… CronJob Kubernetes para verificaÃ§Ã£o periÃ³dica

### 3. Pipeline MLflow de Treinamento
- âœ… Script Python completo de treinamento
- âœ… Enriquecimento de dataset base com feedback humano
- âœ… Suporte para mÃºltiplos tipos de modelo (Random Forest, Gradient Boosting, Neural Network)
- âœ… AvaliaÃ§Ã£o automÃ¡tica de performance (precision, recall, F1)
- âœ… ComparaÃ§Ã£o com modelo baseline
- âœ… PromoÃ§Ã£o automÃ¡tica para Production se melhor

### 4. MÃ©tricas e Observabilidade
- âœ… 12 mÃ©tricas Prometheus para feedback
- âœ… 6 mÃ©tricas Prometheus para re-treinamento
- âœ… IntegraÃ§Ã£o com Prometheus Pushgateway
- âœ… Dashboards Grafana ready

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Revisor Humano  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /api/v1/feedback
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Specialist HTTP Server (FastAPI)    â”‚
â”‚   - specialist-technical:8000          â”‚
â”‚   - specialist-business:8000           â”‚
â”‚   - specialist-behavior:8000           â”‚
â”‚   - specialist-evolution:8000          â”‚
â”‚   - specialist-architecture:8000       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FeedbackCollector                 â”‚
â”‚   - Valida opiniÃ£o existe              â”‚
â”‚   - Valida schema Pydantic             â”‚
â”‚   - Persiste no MongoDB                â”‚
â”‚   - Audita submissÃ£o                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB: specialist_feedback         â”‚
â”‚   - Ãndices: opinion_id, specialist    â”‚
â”‚   - Ãndice composto: type + timestamp  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CronJob: retraining-trigger-checker  â”‚
â”‚   - Executa: Domingo 3h UTC            â”‚
â”‚   - Script: run_retraining_trigger.py  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      RetrainingTrigger                 â”‚
â”‚   - Verifica threshold â‰¥100            â”‚
â”‚   - Verifica cooldown < 24h            â”‚
â”‚   - Dispara pipeline MLflow            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLflow Training Pipeline             â”‚
â”‚   - Carrega dataset base               â”‚
â”‚   - Carrega feedbacks do MongoDB       â”‚
â”‚   - Enriquece dataset                  â”‚
â”‚   - Treina modelo                      â”‚
â”‚   - Avalia performance                 â”‚
â”‚   - Registra no Model Registry         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLflow Model Registry                â”‚
â”‚   - Staging: modelo re-treinado        â”‚
â”‚   - Production: baseline atual         â”‚
â”‚   - PromoÃ§Ã£o se precision > base + 5%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura de Arquivos

### Bibliotecas Core
```
libraries/python/neural_hive_specialists/
â”œâ”€â”€ config.py                              # âœ… ConfiguraÃ§Ãµes de feedback/retraining
â”œâ”€â”€ metrics.py                             # âœ… MÃ©tricas Prometheus
â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ __init__.py                       # âœ… Exports do mÃ³dulo
â”‚   â”œâ”€â”€ feedback_collector.py             # âœ… FeedbackCollector + FeedbackDocument
â”‚   â”œâ”€â”€ retraining_trigger.py             # âœ… RetrainingTrigger + TriggerRecord
â”‚   â””â”€â”€ feedback_api.py                   # âœ… FastAPI router
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_retraining_trigger.py         # âœ… Script CLI para trigger
â””â”€â”€ tests/
    â”œâ”€â”€ test_feedback_collector.py        # âœ… Testes unitÃ¡rios
    â”œâ”€â”€ test_retraining_trigger.py        # âœ… Testes unitÃ¡rios
    â””â”€â”€ test_feedback_api.py              # âœ… Testes de integraÃ§Ã£o
```

### ServiÃ§os (Especialistas)
```
services/specialist-{type}/src/
â””â”€â”€ http_server_fastapi.py                # âœ… IntegraÃ§Ã£o FeedbackAPI
```
Aplicado em: technical, business, behavior, evolution, architecture

### Pipeline MLflow
```
ml_pipelines/training/
â”œâ”€â”€ MLproject                              # âœ… DefiniÃ§Ã£o do pipeline
â”œâ”€â”€ conda.yaml                             # âœ… Ambiente conda
â””â”€â”€ train_specialist_model.py             # âœ… Script de treinamento
```

### Infraestrutura Kubernetes
```
k8s/cronjobs/
â””â”€â”€ retraining-trigger-job.yaml           # âœ… CronJob semanal
```

### Build e Deploy
```
Makefile                                   # âœ… Targets de continuous learning
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# Feedback Collection
ENABLE_FEEDBACK_COLLECTION=true
FEEDBACK_MONGODB_COLLECTION=specialist_feedback
FEEDBACK_API_ENABLED=true
FEEDBACK_REQUIRE_AUTHENTICATION=true
FEEDBACK_ALLOWED_ROLES=admin,specialist_reviewer,human_expert
FEEDBACK_RATING_MIN=0.0
FEEDBACK_RATING_MAX=1.0

# Retraining Trigger
ENABLE_RETRAINING_TRIGGER=true
RETRAINING_FEEDBACK_THRESHOLD=100
RETRAINING_FEEDBACK_WINDOW_DAYS=7
RETRAINING_TRIGGER_SCHEDULE_CRON='0 3 * * 0'
RETRAINING_MLFLOW_PROJECT_URI=./ml_pipelines/training
RETRAINING_MIN_FEEDBACK_QUALITY=0.5

# Training Pipeline
TRAINING_DATASET_PATH=/data/training/specialist_{specialist_type}_base.parquet
TRAINING_VALIDATION_SPLIT=0.2
TRAINING_TEST_SPLIT=0.1
TRAINING_RANDOM_SEED=42
TRAINING_MODEL_TYPES=random_forest,gradient_boosting
TRAINING_HYPERPARAMETER_TUNING=false
TRAINING_PROMOTION_PRECISION_THRESHOLD=0.75
TRAINING_PROMOTION_RECALL_THRESHOLD=0.70
```

## ğŸš€ Uso

### 1. Submeter Feedback

```bash
curl -X POST http://specialist-technical:8000/api/v1/feedback \
  -H "Authorization: Bearer <jwt-token>" \
  -H "Content-Type: application/json" \
  -d '{
    "opinion_id": "opinion-abc123",
    "human_rating": 0.9,
    "human_recommendation": "approve",
    "feedback_notes": "AnÃ¡lise de seguranÃ§a correta e completa"
  }'
```

**Response:**
```json
{
  "feedback_id": "feedback-xyz789",
  "opinion_id": "opinion-abc123",
  "submitted_at": "2024-01-15T10:30:00Z",
  "status": "success"
}
```

### 2. Consultar Feedbacks

**Por opiniÃ£o:**
```bash
curl http://specialist-technical:8000/api/v1/feedback/opinion/opinion-abc123
```

**EstatÃ­sticas:**
```bash
curl "http://specialist-technical:8000/api/v1/feedback/stats?specialist_type=technical&window_days=30"
```

### 3. Verificar Threshold (Dry-run)

```bash
make check-retraining-trigger
```

ou

```bash
cd libraries/python/neural_hive_specialists
python -m scripts.run_retraining_trigger --dry-run
```

### 4. Disparar Re-treinamento Manual

```bash
make trigger-retraining SPECIALIST_TYPE=technical
```

ou

```bash
cd libraries/python/neural_hive_specialists
python -m scripts.run_retraining_trigger --specialist-type technical --force
```

### 5. Deploy CronJob

```bash
make deploy-retraining-cronjob
```

ou

```bash
kubectl apply -f k8s/cronjobs/retraining-trigger-job.yaml
```

### 6. Executar Testes

```bash
make test-feedback
```

ou

```bash
cd libraries/python/neural_hive_specialists
pytest tests/test_feedback_collector.py \
       tests/test_retraining_trigger.py \
       tests/test_feedback_api.py \
       -v --cov=neural_hive_specialists/feedback
```

## ğŸ“Š MÃ©tricas Prometheus

### Feedback Metrics

```promql
# Total de feedbacks submetidos
neural_hive_feedback_submissions_total{specialist_type="technical"}

# Rating mÃ©dio
neural_hive_feedback_avg_rating{specialist_type="technical"}

# DistribuiÃ§Ã£o de ratings
neural_hive_feedback_rating_distribution{specialist_type="technical"}

# DistribuiÃ§Ã£o de recomendaÃ§Ãµes
neural_hive_feedback_recommendation_distribution{specialist_type="technical", human_recommendation="approve"}

# Contagem atual na janela de trigger
neural_hive_feedback_count_current{specialist_type="technical"}

# Erros na API
neural_hive_feedback_api_errors_total{specialist_type="technical", error_type="validation"}
```

### Retraining Metrics

```promql
# Total de triggers disparados
neural_hive_retraining_triggers_total{specialist_type="technical", status="success"}

# Threshold configurado
neural_hive_retraining_feedback_threshold{specialist_type="technical"}

# Ãšltimo trigger
neural_hive_retraining_last_trigger_timestamp{specialist_type="technical"}

# DuraÃ§Ã£o de runs MLflow
neural_hive_retraining_mlflow_run_duration_seconds{specialist_type="technical"}

# Performance do modelo re-treinado
neural_hive_retraining_model_performance{specialist_type="technical", metric_name="precision"}

# Tamanho do dataset
neural_hive_retraining_dataset_size{specialist_type="technical", dataset_type="total"}
```

## ğŸ” AutenticaÃ§Ã£o

### Gerar Token JWT

```python
import jwt
from datetime import datetime, timedelta

payload = {
    'sub': 'reviewer@example.com',
    'role': 'human_expert',
    'iat': datetime.utcnow(),
    'exp': datetime.utcnow() + timedelta(hours=1)
}

token = jwt.encode(payload, 'your-secret-key', algorithm='HS256')
```

### Roles Permitidos

- `admin` - Acesso completo
- `specialist_reviewer` - Revisor de especialistas
- `human_expert` - Expert humano

## ğŸ§ª Testes

### Cobertura de Testes

```
test_feedback_collector.py:
  âœ… ValidaÃ§Ã£o de schema FeedbackDocument
  âœ… SubmissÃ£o de feedback (success, errors)
  âœ… ValidaÃ§Ã£o de opiniÃ£o existe
  âœ… Consulta de feedbacks
  âœ… CÃ¡lculo de estatÃ­sticas
  âœ… Auditoria de submissÃµes

test_retraining_trigger.py:
  âœ… VerificaÃ§Ã£o de threshold
  âœ… Cooldown logic
  âœ… InicializaÃ§Ã£o de MLflow run
  âœ… Trigger de re-treinamento
  âœ… Tratamento de erros
  âœ… Force mode

test_feedback_api.py:
  âœ… Endpoints REST (POST, GET)
  âœ… ValidaÃ§Ã£o de requests
  âœ… AutenticaÃ§Ã£o JWT
  âœ… Error handling (404, 422, 503)
```

## ğŸ“ˆ Fluxo de Continuous Learning

### Passo a Passo

1. **Especialista gera opiniÃ£o** â†’ Persiste no ledger (`cognitive_ledger`)

2. **Revisor humano avalia opiniÃ£o** â†’ Submete feedback via API
   - `POST /api/v1/feedback`
   - ValidaÃ§Ã£o: opiniÃ£o existe, rating vÃ¡lido, recomendaÃ§Ã£o vÃ¡lida
   - Persiste em `specialist_feedback` collection

3. **CronJob semanal executa** (Domingo 3h UTC)
   - Script: `run_retraining_trigger.py`
   - Conta feedbacks dos Ãºltimos 7 dias

4. **Threshold verificado** (â‰¥100 feedbacks)
   - Se atingido E sem cooldown â†’ Dispara trigger
   - Se nÃ£o atingido â†’ Aguarda mais feedbacks

5. **MLflow Pipeline iniciado**
   - Carrega dataset base (Parquet)
   - Carrega feedbacks do MongoDB (Ãºltimos 30 dias, rating â‰¥ 0.5)
   - Enriquece dataset: base + feedback

6. **Modelo treinado**
   - Random Forest / Gradient Boosting / Neural Network
   - Split: 70% train, 20% validation, 10% test
   - MÃ©tricas calculadas: precision, recall, F1, accuracy

7. **Modelo registrado no MLflow**
   - Model Registry: `{specialist_type}-model`
   - Stage inicial: **Staging**

8. **ComparaÃ§Ã£o com baseline**
   - Busca modelo atual em **Production**
   - Compara precision/recall
   - Se novo modelo melhor (precision > baseline + 5%):
     - âœ… Promove para **Production**
     - Arquiva baseline anterior
   - SenÃ£o:
     - â„¹ï¸ MantÃ©m em **Staging**

## ğŸ¯ CritÃ©rios de PromoÃ§Ã£o

Para um modelo ser promovido para Production, deve atender **TODOS** os critÃ©rios:

1. **Precision** â‰¥ 0.75 (threshold absoluto)
2. **Recall** â‰¥ 0.70 (threshold absoluto)
3. **Precision** > baseline_precision + 0.05 (melhoria de 5%)

## ğŸ› ï¸ Troubleshooting

### Problema: Feedback nÃ£o aceito (404)

**Causa:** OpiniÃ£o nÃ£o encontrada no ledger

**SoluÃ§Ã£o:**
```bash
# Verificar se opiniÃ£o existe
mongo neural_hive
db.cognitive_ledger.findOne({opinion_id: "opinion-abc123"})
```

### Problema: Re-treinamento nÃ£o dispara

**Causa 1:** Threshold nÃ£o atingido

**SoluÃ§Ã£o:**
```bash
# Verificar contagem de feedbacks
python -m scripts.run_retraining_trigger --dry-run
```

**Causa 2:** Cooldown ativo

**SoluÃ§Ã£o:**
```bash
# Verificar Ãºltimo trigger
mongo neural_hive
db.retraining_triggers.find({specialist_type: "technical"}).sort({triggered_at: -1}).limit(1)

# ForÃ§ar trigger ignorando cooldown
python -m scripts.run_retraining_trigger --specialist-type technical --force
```

### Problema: Modelo nÃ£o promovido

**Causa:** Performance abaixo do baseline

**SoluÃ§Ã£o:**
```bash
# Verificar mÃ©tricas no MLflow
mlflow ui

# Ajustar thresholds de promoÃ§Ã£o
export TRAINING_PROMOTION_PRECISION_THRESHOLD=0.70
export TRAINING_PROMOTION_RECALL_THRESHOLD=0.65
```

### Problema: CronJob nÃ£o executa

**SoluÃ§Ã£o:**
```bash
# Verificar CronJob
kubectl get cronjobs -n neural-hive-mind

# Verificar Ãºltima execuÃ§Ã£o
kubectl get jobs -n neural-hive-mind | grep retraining-trigger

# Verificar logs
kubectl logs -n neural-hive-mind -l job-name=retraining-trigger-checker-<timestamp>
```

## ğŸ”® Roadmap Futuro

### Funcionalidades Planejadas

- [ ] **Active Learning**: Selecionar opiniÃµes mais incertas para feedback
- [ ] **Feedback Ponderado**: Dar mais peso a revisores experientes
- [ ] **Feedback Negativo**: Reportar erros graves com alta prioridade
- [ ] **Dashboard de Feedback**: UI web para revisores
- [ ] **IntegraÃ§Ã£o com Tickets**: Feedback via sistema de tickets
- [ ] **AnÃ¡lise de Drift**: Detectar mudanÃ§as na distribuiÃ§Ã£o de feedbacks
- [ ] **Multi-Modal Feedback**: Suporte para feedback em Ã¡udio/vÃ­deo
- [ ] **Feedback Automatizado**: Usar LLMs para gerar feedback sintÃ©tico

## ğŸ“š ReferÃªncias

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Prometheus Metrics](https://prometheus.io/docs/concepts/metric_types/)
- [Kubernetes CronJobs](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/)

## âœ… Checklist de ImplementaÃ§Ã£o

- [x] ConfiguraÃ§Ã£o em `config.py`
- [x] MÃ³dulo `feedback/` completo
- [x] IntegraÃ§Ã£o com todos os 5 especialistas
- [x] MÃ©tricas Prometheus
- [x] Script `run_retraining_trigger.py`
- [x] Pipeline MLflow `train_specialist_model.py`
- [x] Arquivos MLproject e conda.yaml
- [x] CronJob Kubernetes
- [x] Testes unitÃ¡rios e de integraÃ§Ã£o
- [x] Makefile targets
- [x] DocumentaÃ§Ã£o

## ğŸ‰ ConclusÃ£o

Sistema de **continuous learning completo e funcional** implementado para o Neural Hive Mind, permitindo:

1. âœ… Coleta estruturada de feedback humano
2. âœ… Trigger automÃ¡tico de re-treinamento
3. âœ… Pipeline MLflow de treinamento
4. âœ… PromoÃ§Ã£o automÃ¡tica de modelos
5. âœ… Observabilidade completa com Prometheus
6. âœ… Testes unitÃ¡rios e de integraÃ§Ã£o
7. âœ… Deploy via Kubernetes CronJob

O sistema estÃ¡ pronto para uso em produÃ§Ã£o! ğŸš€
