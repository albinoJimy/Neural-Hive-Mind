# Metadados para templates comuns
component: "orchestrator-dynamic"
layer: "orchestration"

image:
  repository: 37.60.241.150:30500/orchestrator-dynamic
  tag: "1.2.0"
  pullPolicy: IfNotPresent

imagePullSecrets: []

replicaCount: 2

# Estratégia de deployment
deployment:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

resources:
  # Temporal + Kafka coordination peaks at ~1 vCPU when replaying workflows,
  # but steady state averages 250-300m CPU and <900Mi RAM.
  # Requests drop to 400m/1Gi and burst caps are reduced to 1.6 CPU / 3Gi.
  requests:
    cpu: 400m
    memory: 1Gi
  limits:
    cpu: 1600m
    memory: 3Gi

service:
  type: ClusterIP
  annotations: {}
  ports:
    http:
      port: 8000
      targetPort: 8000
      protocol: TCP
    grpc:
      port: 50053
      targetPort: 50053
      protocol: TCP
    metrics:
      port: 9090
      targetPort: 9090
      protocol: TCP

# Configuração de observabilidade para templates comuns
observability:
  prometheus:
    enabled: true

config:
  serviceName: orchestrator-dynamic
  serviceVersion: "1.0.0"
  environment: production
  logLevel: INFO

  temporal:
    enabled: true  # Set to false if Temporal is not deployed
    host: temporal-frontend.temporal.svc.cluster.local  # Can include port (host:port format)
    port: 7233  # Ignored if host includes port
    namespace: neural-hive-mind
    taskQueue: orchestration-tasks
    tlsEnabled: false

  kafka:
    bootstrapServers: neural-hive-kafka-kafka-bootstrap.kafka.svc.cluster.local:9092
    consensusTopic: plans.consensus
    ticketsTopic: execution.tickets
    consumerGroupId: orchestrator-dynamic
    securityProtocol: PLAINTEXT
    saslMechanism: SCRAM-SHA-512
    saslUsername: ""
    saslPassword: ""
    sslCaLocation: ""
    sslCertificateLocation: ""
    sslKeyLocation: ""
    schemaRegistryUrl: http://schema-registry.kafka.svc.cluster.local:8081
    schemasBasePath: /app/schemas

  postgres:
    host: pgbouncer-temporal.temporal-postgres.svc.cluster.local
    port: 6432
    database: temporal
    sslMode: require

  mongodb:
    uri: mongodb://root:local_dev_password@mongodb-0.mongodb-headless.mongodb-cluster.svc.cluster.local:27017,mongodb-1.mongodb-headless.mongodb-cluster.svc.cluster.local:27017,mongodb-2.mongodb-headless.mongodb-cluster.svc.cluster.local:27017/?replicaSet=rs0
    database: neural_hive_orchestration
    maxPoolSize: 100  # Tuneable via Helm for replica-based sizing
    minPoolSize: 10   # Maintain warm connections for burst traffic

  redis:
    clusterNodes: redis-cluster.redis-cluster.svc.cluster.local:6379
    sslEnabled: false

  scheduler:
    enableIntelligentScheduler: true
    enableMlEnhancedScheduling: true
    maxParallelTickets: 100

  # ML Scheduling Optimization (Dual-mode: Remote Optimizer + Local Fallback)
  # Remote Optimizer-Agents Integration (Prophet/ARIMA + Q-learning RL)
  optimizer:
    enabled: false  # Habilitar após validação em staging
    endpoint: optimizer-agents.neural-hive-estrategica.svc.cluster.local:50051
    grpcTimeout: 10
    forecastHorizonMinutes: 60  # Horizonte de previsão de carga
    recommendationConfidenceThreshold: 0.7  # Confiança mínima para aplicar recomendação RL (70%)
    fallbackOnFailure: true  # Permitir fallback se optimizer indisponível

  # ML Predictions e Feature Engineering
  ml:
    predictionsEnabled: true
    driftDetectionEnabled: true
    driftBaselineEnabled: true
    backfillErrors: false
    # Local Load Prediction (Fallback Heurístico)
    localLoadPrediction:
      enabled: true  # Sempre habilitado para fallback
      cacheTtlSeconds: 30  # TTL do cache Redis
      windowMinutes: 60  # Janela de dados históricos
      queuePredictionWeight: 0.2  # Peso de queue time no score
      loadPredictionWeight: 0.1  # Peso de carga no score

    # Allocation Outcomes Feedback Loop (para RL Training)
    allocationOutcomes:
      enabled: true
      topic: ml.allocation_outcomes
      publishAsync: true

    # Timeouts e Otimização
    optimizationTimeoutSeconds: 2

  # gRPC Server para comandos estratégicos da Queen Agent
  grpc:
    enabled: true
    port: 50053
    maxWorkers: 10

  sla:
    defaultTimeoutMs: 3600000
    checkIntervalSeconds: 30
    alertThresholdPercent: 0.8
    proactiveMonitoringEnabled: true  # Monitoramento proativo de SLA em C2/C4
    budgetCriticalThreshold: 0.2      # Threshold para alertas de budget crítico (20%)
    deadlineWarningThreshold: 0.8     # Threshold para alertas de deadline (80%)
    ticketMinTimeoutMs: 60000         # Timeout mínimo para tickets (60s)
    ticketTimeoutBufferMultiplier: 3.0  # Multiplicador de buffer para cálculo de timeout

  # SLA Management System Integration
  slaManagement:
    enabled: true
    host: sla-management-system.neural-hive-orchestration.svc.cluster.local
    port: 8000
    timeoutSeconds: 5
    cacheTtlSeconds: 10

  # Service Registry para descoberta de workers
  serviceRegistry:
    host: service-registry.neural-hive-execution.svc.cluster.local
    port: 50051
    timeoutSeconds: 3
    maxResults: 5
    cacheTtlSeconds: 10

  retry:
    maxAttempts: 3
    initialIntervalMs: 1000
    backoffCoefficient: 2.0
    maxIntervalMs: 60000
  circuitBreaker:
    enabled: true
    failMax: 5           # Trip after 5 failures
    timeoutSeconds: 60   # Open for 60s
    recoveryTimeoutSeconds: 30  # Half-open after 30s

  observability:
    otelExporterEndpoint: http://otel-collector.observability.svc.cluster.local:4317
    prometheusPort: 9090

  # Vault Integration
  # Habilitado por padrão em produção para gerenciamento seguro de credenciais
  vault:
    enabled: false  # Mudar para true em produção para zero-trust security
    address: http://vault.vault.svc.cluster.local:8200
    namespace: ""
    authMethod: kubernetes
    kubernetesRole: orchestrator-dynamic
    tokenPath: /vault/secrets/token
    mountKv: secret
    mountDatabase: database
    timeoutSeconds: 5
    maxRetries: 3
    failOpen: false  # Fail-closed por padrao em producao

  # SPIFFE Integration
  # Habilitado por padrão em produção para autenticação mTLS entre serviços
  spiffe:
    enabled: false  # Mudar para true em produção para zero-trust authentication
    socketPath: unix:///run/spire/sockets/agent.sock
    trustDomain: neural-hive.local
    jwtAudience: vault.neural-hive.local  # Audience para JWT-SVID
    enableX509: true  # Habilitar X.509-SVID para mTLS
    fallbackAllowed: false

    # ClickHouse para dados históricos (usado pelo Optimizer Agents)
    clickhouse:
      host: clickhouse.clickhouse.svc.cluster.local
      port: 9000
      user: optimizer
      passwordSecret: clickhouse-optimizer-password  # Secret name
      database: neural_hive
      queryTimeoutSeconds: 30
      connectionPoolSize: 10
      retryAttempts: 3

    # Prophet configuration (Facebook forecasting)
    prophet:
      seasonalityMode: additive  # additive ou multiplicative
      changepointPriorScale: 0.05  # Detecta mudanças de tendência (0.001-0.5)
      seasonalityPriorScale: 10  # Peso de sazonalidades
      dailySeasonality: true
      weeklySeasonality: true
      yearlySeasonality: true
      holidays: brazil  # Feriados brasileiros

    # Scheduling Optimizer (Q-learning Reinforcement Learning)
    scheduling:
      epsilon: 0.1  # Taxa de exploração vs exploitation (10% exploração)
      learningRate: 0.01  # Taxa de aprendizado
      discountFactor: 0.95  # Fator de desconto para recompensas futuras (gamma)
      snapshotInterval: 100  # Salvar Q-table a cada N updates
      rewardWeights:  # Pesos para reward function
        slaCompliance: 0.4
        throughput: 0.3
        resourceEfficiency: 0.2
        cost: 0.1

    # Training pipeline
    training:
      enabled: true
      intervalHours: 24  # Retreinamento diário
      windowDays: 540  # Janela de 18 meses (540 dias)
      minSamplesProphet: 1000  # Mínimo de amostras para Prophet
      minSamplesArima: 100  # Mínimo de amostras para ARIMA fallback
      validationSplit: 0.2  # 20% para validação
      earlyStoppingPatience: 5  # Parar se não melhorar por N epochs

    # Forecasting horizons e configurações
    forecasting:
      horizons: [60, 360, 1440]  # 1h, 6h, 24h em minutos
      defaultHorizon: 60
      confidenceIntervals: true  # Retornar bandas de confiança (yhat_lower/upper)
      interpolateGaps: true  # Interpolar gaps < 3h nos dados
      removeOutliers: true  # Remover outliers > 3 desvios padrão

    # Model and forecast caching (Redis)
    caching:
      enabled: true
      modelTTL: 3600  # Cache de modelos: 1h (segundos)
      forecastTTL: 300  # Cache de previsões: 5min (segundos)
      qTableTTL: 7200  # Cache de Q-table: 2h (segundos)
      redisKeyPrefix: optimizer_ml_

    # Feature engineering
    features:
      ticketVolumeHourly: true
      avgDurationByType: true
      slaComplianceRate: true
      resourceUtilizationP95: true
      queueDepthAvg: true
      bottleneckIndicators: true

    # A/B Testing configuration
    experimentManager:
      enabled: false  # Habilitar para A/B tests
      controlGroupPct: 0.2  # 20% usa heurística padrão
      treatmentGroupPct: 0.8  # 80% usa ML
      minSamplesSignificance: 1000
      confidenceLevel: 0.95

    # MLflow integration
    mlflow:
      enabled: true
      trackingUri: http://mlflow.mlflow.svc.cluster.local:5000
      experimentName: optimizer-scheduling
      registryUri: http://mlflow.mlflow.svc.cluster.local:5000
      artifactLocation: s3://neural-hive-mlflow/artifacts
      modelStage: Production  # Carregar modelos em stage Production

    # Drift Detection
    drift:
      enabled: true
      checkWindowDays: 7  # Janela de análise para drift
      psiThreshold: 0.25  # PSI > 0.25 = drift significativo
      maeRatioThreshold: 1.5  # MAE atual / MAE treino > 1.5 = degradação crítica
      ksPvalueThreshold: 0.05  # P-value K-S test < 0.05 = shift significativo
      cronSchedule: "0 3 * * *"  # Diário às 3 AM UTC (após training)

    # Training Job Configuration
    trainingJob:
      enabled: true
      schedule: "0 2 * * *"  # Diário às 2 AM UTC
      timeoutSeconds: 3600  # 1 hora
      backoffLimit: 2  # Retry até 2 vezes
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3
      minSamples: 100
      durationErrorThreshold: 0.15
      anomalyContamination: 0.05
      driftBaselineEnabled: true
      mlflowTrackingUri: http://mlflow.mlflow.svc.cluster.local:5000
      mlflowExperimentName: orchestrator-predictive-models
      resources:
        requests:
          cpu: 1000m
          memory: 2Gi
        limits:
          cpu: 2000m
          memory: 4Gi
      # Habilitar backfill de erros históricos
      backfillErrors: false
      # Override training window (default: usa ml.training.windowDays)
      windowDaysOverride: null

  # Prometheus Pushgateway (para métricas de CronJobs)
  prometheusPushgateway:
    url: http://prometheus-pushgateway.monitoring.svc.cluster.local:9091

  # OPA Policy Engine
  opa:
    enabled: true
    host: opa.neural-hive-orchestration.svc.cluster.local
    port: 8181
    timeoutSeconds: 2
    retryAttempts: 3
    cacheTtlSeconds: 30
    failOpen: false  # fail-closed por padrão

    # Policy Parameters
    policies:
      maxConcurrentTickets: 100
      allowedCapabilities:
        - code_generation
        - deployment
        - testing
        - validation
        - analysis
        - optimization
      resourceLimits:
        maxCpu: "4000m"
        maxMemory: "8Gi"
      timeoutLimits:
        critical: 7200000  # 2h
        high: 3600000      # 1h
        medium: 1800000    # 30min
        low: 900000        # 15min
      retryLimits:
        critical: 5
        high: 3
        medium: 2
        low: 1
      resource_limits: neuralhive/orchestrator/resource_limits
      sla_enforcement: neuralhive/orchestrator/sla_enforcement
      feature_flags: neuralhive/orchestrator/feature_flags
      security_constraints: neuralhive/orchestrator/security_constraints  # NOVO

    # Feature Flags
    featureFlags:
      intelligentSchedulerEnabled: true
      burstCapacityEnabled: true
      burstThreshold: 0.8
      predictiveAllocationEnabled: false
      autoScalingEnabled: false
      schedulerNamespaces:
        - production
        - staging
      premiumTenants: []

    security:  # NOVO
      enabled: true
      allowed_tenants: []  # Vazio = todos permitidos
      rbac_roles:
        admin@example.com:
          - admin
        developer@example.com:
          - developer
        viewer@example.com:
          - viewer
      data_residency_regions:
        - us-east-1
        - us-west-2
        - eu-west-1
      tenant_rate_limits:
        tenant-rate-limited: 100  # Override específico; demais usam default_tenant_rate_limit
      global_rate_limit: 1000
      default_tenant_rate_limit: 100

# OPA Deployment
opa:
  enabled: true
  replicas: 2
  image:
    repository: openpolicyagent/opa
    tag: 0.60.0-rootless
    pullPolicy: IfNotPresent

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

  service:
    type: ClusterIP
    port: 8181

  config:
    logLevel: info
    logFormat: json

secrets:
  postgresUser: temporal
  postgresPassword: "<sealed-secret-ref>"
  mongodbUri: "<sealed-secret-ref>"
  redisPassword: "<sealed-secret-ref>"  # Obrigatorio em producao (validacao automatica)
  kafkaSaslUsername: ""
  kafkaSaslPassword: ""

istio:
  enabled: true
  mtls:
    mode: STRICT

serviceMonitor:
  enabled: false
  interval: 30s
  scrapeTimeout: 10s

podDisruptionBudget:
  enabled: true
  minAvailable: 1

networkPolicy:
  enabled: true
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: neural-hive-mind
  egress:
    - to:
      - namespaceSelector:
          matchLabels:
            name: kafka
    - to:
      - namespaceSelector:
          matchLabels:
            name: temporal
    - to:
      - namespaceSelector:
          matchLabels:
            name: mongodb-cluster

# Volumes para o container
volumes:
  - name: tmp
    emptyDir: {}
  - name: logs
    emptyDir: {}

volumeMounts:
  - name: tmp
    mountPath: /tmp
  - name: logs
    mountPath: /app/logs

# Segurança no nível do pod
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"

podLabels:
  app.kubernetes.io/name: orchestrator-dynamic
  app.kubernetes.io/component: orchestration
  neural-hive.io/layer: orchestration

startupProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 30  # Temporal/Kafka reconexões podem levar até 5 minutos quando há replay
  successThreshold: 1

livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 0
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8000
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - orchestrator-dynamic
        topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: orchestrator-dynamic

tolerations: []
nodeSelector: {}

serviceAccount:
  create: true
  name: ""
