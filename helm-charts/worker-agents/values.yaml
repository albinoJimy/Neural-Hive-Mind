component: "worker-agents"
layer: "execution"

image:
  repository: 37.60.241.150:30500/worker-agents
  tag: "1.3.4"
  pullPolicy: IfNotPresent

replicaCount: 3

service:
  type: ClusterIP
  ports:
    http:
      port: 8080
      targetPort: 8080
      protocol: TCP
    metrics:
      port: 9090
      targetPort: 9090
      protocol: TCP

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

resources:
  # Workers pull Temporal/Kafka tasks but idle frequently; profiling shows 250-300m CPU steady state.
  # Right-size to 400m CPU / 640Mi requests with burst cap 1.5 CPU / 1.5Gi for parallel job spikes.
  requests:
    cpu: 400m
    memory: 640Mi
  limits:
    cpu: 1500m
    memory: 1536Mi

config:
  serviceName: worker-agents
  namespace: neural-hive-execution
  cluster: production
  supportedTaskTypes:
    - BUILD
    - DEPLOY
    - TEST
    - VALIDATE
    - EXECUTE
    - COMPENSATE
  maxConcurrentTasks: 5

  kafka:
    bootstrapServers: neural-hive-kafka-kafka-bootstrap.kafka.svc.cluster.local:9092
    ticketsTopic: execution.tickets
    resultsTopic: execution.results
    consumerGroupId: worker-agents
    schemaRegistryUrl: http://schema-registry.kafka.svc.cluster.local:8081
    securityProtocol: PLAINTEXT
    saslMechanism: SCRAM-SHA-512
    saslUsername: ""
    saslPassword: ""
    sslCaLocation: ""
    sslCertificateLocation: ""
    sslKeyLocation: ""
    schemasBasePath: /app/schemas
    # Dead Letter Queue
    dlq:
      enabled: true
      topic: execution.tickets.dlq
      maxRetriesBeforeDLQ: 3  # Numero de falhas antes de enviar para DLQ

  serviceRegistry:
    host: service-registry.neural-hive.svc.cluster.local
    port: 50051
    heartbeatIntervalSeconds: 30

  executionTicketService:
    url: http://execution-ticket-service.neural-hive-orchestration.svc.cluster.local:8080

  temporal:
    enabled: false
    host: temporal-frontend.temporal.svc.cluster.local
    port: 7233
    namespace: neural-hive-mind
    taskQueue: worker-tasks

  observability:
    otelEndpoint: http://otel-collector:4317
    prometheusPort: 9090
    httpPort: 8080
    logLevel: INFO

  codeForge:
    url: http://code-forge.neural-hive-execution.svc.cluster.local:8000
    enabled: true
    timeoutSeconds: 14400  # 4 hours

  argocd:
    url: ""  # e.g., https://argocd.example.com
    enabled: false
    token: ""  # Sera movido para Secret
    tokenSecretName: argocd-token
    tokenSecretKey: token
    timeoutSeconds: 600

  flux:
    enabled: false
    namespace: flux-system
    kubeconfigPath: ""  # Vazio para in-cluster config
    timeoutSeconds: 600

  opa:
    url: http://opa.neural-hive-governance.svc.cluster.local:8181
    enabled: true
    token: ""
    tokenSecretName: opa-token
    tokenSecretKey: token
    timeoutSeconds: 30
    verifySsl: true
    retryAttempts: 3
    retryBackoffBaseSeconds: 2
    retryBackoffMaxSeconds: 60
    pollIntervalSeconds: 5
    pollTimeoutSeconds: 300

  trivy:
    enabled: true
    timeoutSeconds: 300

  testExecution:
    timeoutSeconds: 600
    allowedCommands:
      - pytest
      - npm test
      - go test
      - mvn test
      - jest
      - cargo test

  # Saga Pattern - Compensacao Automatica
  compensation:
    enabled: true
    timeoutSeconds: 120
    # Configuracoes especificas por tipo de compensacao
    build:
      cleanupArtifacts: true
    deploy:
      argocdEnabled: true
      fluxEnabled: true
      rollbackRevisionDefault: "HEAD~1"
    test:
      cleanupNamespacePattern: "test-*"
      cleanupJobs: true

  vault:
    enabled: true  # Zero-trust security enabled
    address: http://vault.vault.svc.cluster.local:8200
    namespace: ""
    authMethod: kubernetes
    kubernetesRole: worker-agents
    tokenPath: /vault/secrets/token
    mountKv: secret
    mountDatabase: database
    timeoutSeconds: 5
    maxRetries: 3
    failOpen: false  # Fail-closed por padrao em producao

  spiffe:
    enabled: true  # Zero-trust authentication habilitado
    socketPath: unix:///run/spire/sockets/agent.sock
    trustDomain: neural-hive.local
    jwtAudience: service-registry.neural-hive.local
    jwtTtlSeconds: 3600
    enableX509: true
    fallbackAllowed: false  # Fail-closed em produção

  githubActions:
    enabled: false
    apiUrl: https://api.github.com
    tokenSecretName: github-token

  validation:
    opa:
      enabled: true
      url: http://opa.neural-hive-governance.svc.cluster.local:8181
    trivy:
      enabled: true
      timeout: 300
    sonarqube:
      enabled: false
      url: https://sonarqube.example.com
      tokenSecretName: sonarqube-token
    snyk:
      enabled: false
      tokenSecretName: snyk-token
    checkov:
      enabled: false

  # Runtime Configuration para ExecuteExecutor
  runtimes:
    # Docker Runtime
    docker:
      enabled: false
      baseUrl: "unix:///var/run/docker.sock"
      timeoutSeconds: 600
      verifySsl: true
      defaultCpuLimit: 1.0
      defaultMemoryLimit: "512m"
      networkMode: "bridge"
      cleanupContainers: true

    # Kubernetes Jobs
    k8s:
      enabled: false
      namespace: "neural-hive-execution"
      kubeconfigPath: ""  # Vazio para in-cluster config
      timeoutSeconds: 600
      pollIntervalSeconds: 5
      cleanup: true
      serviceAccount: "worker-agent-executor"
      defaultCpuRequest: "100m"
      defaultCpuLimit: "1000m"
      defaultMemoryRequest: "128Mi"
      defaultMemoryLimit: "512Mi"
      backoffLimit: 0

    # AWS Lambda
    lambda:
      enabled: false
      region: "us-east-1"
      functionName: "neural-hive-executor"
      timeoutSeconds: 900
      accessKeySecretName: lambda-credentials
      accessKeySecretKey: accessKey
      secretKeySecretKey: secretKey

    # Local Runtime
    local:
      enabled: true
      timeoutSeconds: 300
      enableSandbox: true
      allowedCommands:
        - python
        - python3
        - node
        - bash
        - sh
        - terraform
        - kubectl
        - helm
      workingDir: "/tmp/neural-hive-execution"

    # Runtime selection
    defaultRuntime: "local"
    fallbackChain:
      - k8s
      - docker
      - local
      - simulation

securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  readOnlyRootFilesystem: true

deployment:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

observability:
  prometheus:
    enabled: true
  # TLS Configuration para OpenTelemetry Exporter
  tls:
    enabled: false  # Habilitar em produção
    certSecret: "neural-hive-otel-client-certs"
    mountPath: "/etc/otel-tls"

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  readOnlyRootFilesystem: true

istio:
  enabled: true
  mtls:
    mode: STRICT

serviceMonitor:
  enabled: true
  interval: 30s

startupProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 20  # Dá 3.3min para registrar tasks no Service Registry/Temporal
  successThreshold: 1

livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

pdb:
  enabled: true
  minAvailable: 1

networkPolicy:
  enabled: true

secrets:
  kafkaSaslUsername: ""
  kafkaSaslPassword: ""
  argoCdToken: ""  # ArgoCD API token (base64 encoded in production)

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - worker-agents
          topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: worker-agents
