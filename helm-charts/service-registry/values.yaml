component: "service-registry"
layer: "infrastructure"

image:
  repository: ghcr.io/albinojimy/neural-hive-mind/service-registry
  tag: "1.2.0"
  pullPolicy: Always

imagePullSecrets:
  - name: ghcr-secret

replicaCount: 1

deployment:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 6
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

resources:
  # Registry brokers gRPC for every worker/orchestrator handshake; steady usage ~200m CPU / 600Mi.
  # Requests reduzidos temporariamente devido a limitação de recursos do cluster.
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 1200m
    memory: 2Gi

service:
  type: ClusterIP
  annotations: {}
  ports:
    grpc:
      port: 50051
      targetPort: 50051
      protocol: TCP
    metrics:
      port: 9090
      targetPort: 9090
      protocol: TCP

config:
  serviceName: service-registry
  serviceVersion: 1.0.0
  environment: development
  logLevel: INFO
  etcd:
    # NOTA: Apesar do nome "etcd", agora usa Redis como backend (migrado em v1.2.0)
    # Formato: host:port (sem protocolo http://)
    endpoints:
      - neural-hive-cache.redis-cluster.svc.cluster.local:6379
    prefix: neural-hive:agents
    timeoutSeconds: 5
  healthCheck:
    intervalSeconds: 60
  heartbeat:
    timeoutSeconds: 120
  redis:
    clusterNodes:
      - neural-hive-cache.redis-cluster.svc.cluster.local:6379
    # Senha do Redis - OBRIGATORIO em producao (validacao automatica)
    # Opcoes:
    # 1. External Secrets (recomendado): Defina existingSecret abaixo
    # 2. Manual: Configure password aqui (NAO recomendado para producao)
    password: ""
    # Nome do secret existente que contem a chave 'redis-password'
    # Se definido, o chart NAO criara o Secret (usa o existente)
    existingSecret: ""  # Ex: "service-registry-secret" criado por ExternalSecret
  otel:
    exporterEndpoint: http://otel-collector:4317

  vault:
    enabled: true  # Zero-trust security enabled
    address: http://vault.vault.svc.cluster.local:8200
    namespace: ""
    authMethod: kubernetes
    kubernetesRole: service-registry
    tokenPath: /vault/secrets/token
    mountKv: secret
    timeoutSeconds: 5
    maxRetries: 3
    failOpen: false  # Fail-closed por padrao em producao

  spiffe:
    enabled: false  # Desabilitado temporariamente - SPIRE agent não instalado nos nós
    enableX509: true
    verifyPeer: true  # Validar SPIFFE ID dos clientes
    socketPath: unix:///run/spire/sockets/agent.sock
    trustDomain: neural-hive.local

istio:
  enabled: true
  mtls:
    mode: STRICT

serviceMonitor:
  enabled: true
  interval: 30s
  scrapeTimeout: 10s

observability:
  prometheus:
    enabled: true
  # TLS Configuration para OpenTelemetry Exporter
  tls:
    enabled: false  # Habilitar em produção
    certSecret: "neural-hive-otel-client-certs"
    mountPath: "/etc/otel-tls"

podDisruptionBudget:
  enabled: true
  minAvailable: 1

networkPolicy:
  enabled: true
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: neural-hive-mind
        - namespaceSelector:
            matchLabels:
              name: neural-hive-orchestration
  egress:
    - to:
        - namespaceSelector:
            matchLabels:
              name: infrastructure
      ports:
        - protocol: TCP
          port: 2379  # etcd
        - protocol: TCP
          port: 6379  # redis
    - to:
        - namespaceSelector:
            matchLabels:
              name: observability
      ports:
        - protocol: TCP
          port: 4317  # otel-collector

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"

podLabels:
  app.kubernetes.io/name: service-registry
  app.kubernetes.io/component: coordination
  app.kubernetes.io/part-of: neural-hive-mind

startupProbe:
  grpc:
    port: 50051
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 20  # 200s para sincronizar com etcd/Redis antes de aceitar conexões
  successThreshold: 1

livenessProbe:
  grpc:
    port: 50051
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  grpc:
    port: 50051
  initialDelaySeconds: 0
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - service-registry
          topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: service-registry

serviceAccount:
  create: true
  name: service-registry
  automountServiceAccountToken: true

# Remover nodeSelector para permitir scheduling em qualquer nó
nodeSelector: {}
