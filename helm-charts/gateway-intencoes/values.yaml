# Configurações do Gateway de Intenções
#
# Estratégia de Image Pull Policy por Ambiente:
# ┌─────────────┬──────────────┬─────────────────┬────────────────────────────────────────┐
# │ Ambiente    │ Pull Policy  │ Tag Strategy    │ Justificativa                          │
# ├─────────────┼──────────────┼─────────────────┼────────────────────────────────────────┤
# │ Production  │ IfNotPresent │ Semver (1.1.2)  │ Otimização: reduz latência e custos    │
# │ Staging     │ Always       │ Semver/latest   │ Testes: garante versão mais recente    │
# │ Development │ Always       │ latest/branch   │ Iteração rápida com builds frequentes  │
# │ K8s Direct  │ IfNotPresent │ Semver (1.1.2)  │ Deployment direto com tag fixa         │
# └─────────────┴──────────────┴─────────────────┴────────────────────────────────────────┘
#
# Regra Geral:
# - Tags fixas/versionadas (1.x.x, v1.x.x) → IfNotPresent
# - Tags mutáveis (latest, main, develop) → Always
#
image:
  repository: ghcr.io/albinojimy/neural-hive-mind/gateway-intencoes
  pullPolicy: Always
  tag: "1.1.2"
imagePullSecrets:
  - name: ghcr-secret

# Configurações globais (usadas por templates comuns)
global:
  cluster: "neural-hive-main"
  environment: "production"

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Deployment strategy
deployment:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

replicaCount: 3

nameOverride: ""
fullnameOverride: ""

# Init Containers
initContainers:
  modelDownloader:
    enabled: true
    image: python:3.11-slim
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 512Mi

# Metadados para templates comuns
component: "gateway-intencoes"
layer: "application"

# Configurações do serviço
service:
  type: ClusterIP
  annotations:
    neural-hive-mind.org/component: "gateway-intencoes"
  ports:
    http:
      port: 80
      targetPort: 8000
      protocol: TCP
    metrics:
      port: 8080
      targetPort: 8080
      protocol: TCP

# Configurações de ingress
ingress:
  enabled: false
  className: "istio"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: gateway-intencoes.neural-hive-mind.org
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: gateway-intencoes-tls
      hosts:
        - gateway-intencoes.neural-hive-mind.org

# Resources
resources:
  limits:
    cpu: 1500m
    memory: 3Gi
  requests:
    cpu: 750m
    memory: 1536Mi

# Autoscaling
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Node selection
nodeSelector:
  neural-hive-mind.org/workload-type: "compute-intensive"

tolerations:
  - key: "neural-hive-mind.org/gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values: [gateway-intencoes]
        topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: gateway-intencoes

# Security context
podSecurityContext:
  fsGroup: 1001
  runAsGroup: 1001
  runAsUser: 1001
  runAsNonRoot: true

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop: [ALL]
  readOnlyRootFilesystem: false  # Necessário para modelos ML
  runAsNonRoot: true

# Health checks
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 0
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: http
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 15
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 40

# Configurações da aplicação
config:
  environment: "prod"
  logLevel: "INFO"
  debug: false

  # Kafka
  kafka:
    bootstrapServers: "neural-hive-kafka-kafka-bootstrap.kafka.svc.cluster.local:9092"
    schemaRegistryUrl: "http://schema-registry.kafka.svc.cluster.local:8081"
    # TLS/SSL configuration
    tls:
      enabled: false
      caVerifyMode: "none"  # none, optional, required
      protocol: "TLSv1_2"
    # SASL configuration
    sasl:
      enabled: false
      mechanism: "SCRAM-SHA-512"  # PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, GSSAPI, OAUTHBEARER
      # OAuth2 for SASL_OAUTHBEARER
      oauth2:
        enabled: false
        tokenEndpoint: ""
        scope: ""
    # Performance configuration
    performance:
      batchSize: 16384     # bytes
      lingerMs: 10         # milliseconds
      compressionType: "snappy"  # none, gzip, snappy, lz4, zstd

  # Redis Cache
  redis:
    clusterNodes: "neural-hive-cache.redis-cluster.svc.cluster.local:6379"
    defaultTtl: 600
    maxConnections: 100
    poolSize: 10
    timeout: 5000
    retryOnTimeout: true
    connectionPoolMaxConnections: 100
    # TLS/SSL configuration
    ssl:
      enabled: false
      certReqs: "none"  # none, optional, required
      caCerts: "/etc/ssl/certs/redis-ca.crt"
      certFile: ""  # Client certificate path
      keyFile: ""   # Client key path

  # OAuth2/Keycloak
  keycloak:
    url: "https://keycloak.neural-hive.local"
    realm: "neural-hive"
    clientId: "gateway-intencoes"
    jwksUri: "https://keycloak.neural-hive.local/auth/realms/neural-hive/protocol/openid-connect/certs"
    tokenValidationEnabled: true

  # ASR Pipeline
  asr:
    modelName: "tiny"
    device: "cpu"
    lazyLoading: true
    modelCacheDir: "/app/models/whisper"

  # NLU Pipeline
  nlu:
    languageModel: "pt_core_news_sm"
    # IMPORTANTE: confidenceThreshold é usado APENAS para análise interna do NLU,
    # NÃO para decisões de roteamento. Para controlar o roteamento de intents,
    # ajuste routingThresholdHigh e routingThresholdLow abaixo.
    # Valor mantido em 0.6 para compatibilidade com análises internas do pipeline.
    confidenceThreshold: 0.6  # Base threshold para análise NLU (não usado para roteamento)
    confidenceThresholdStrict: 0.75
    adaptiveThresholdEnabled: true
    rulesConfigPath: "/app/config/nlu_rules.yaml"

    # Routing Thresholds - controla decisões de roteamento de intents
    # Matriz de Decisão de Roteamento:
    # - confidence >= routingThresholdHigh (0.5): status="processed" → intentions.captured
    # - routingThresholdLow <= confidence < routingThresholdHigh: status="processed_low_confidence" → intentions.captured (com flag)
    # - confidence < routingThresholdLow (0.3): status="routed_to_validation" → intentions.validation
    #
    # Para reduzir roteamento para validação manual:
    # - Reduzir routingThresholdLow (ex: 0.2) permite mais intents serem processadas
    # - Reduzir routingThresholdHigh (ex: 0.4) aumenta volume de "low confidence" mas ainda processa
    #
    # Recomendações por ambiente:
    # - Dev: routingThresholdHigh=0.4, routingThresholdLow=0.2 (mais permissivo para testes)
    # - Staging: routingThresholdHigh=0.5, routingThresholdLow=0.3 (balanceado)
    # - Prod: routingThresholdHigh=0.6, routingThresholdLow=0.35 (mais conservador)
    routingThresholdHigh: 0.5  # >= 0.5: processamento normal
    routingThresholdLow: 0.3   # 0.3-0.5: processamento com baixa confiança
                                # < 0.3: roteamento para validação manual
    routingUseAdaptiveForDecisions: false  # Se true, usa adaptive threshold para roteamento

  # Limites
  limits:
    maxAudioSizeMb: 10
    maxTextLength: 10000

  # Rate Limiting
  rateLimit:
    enabled: true
    requestsPerMinute: 1000
    burstSize: 100
    failOpen: true
    # Limites especificos por tenant (JSON)
    tenantOverrides: '{}'
    # Limites especificos por usuario (JSON)
    userOverrides: '{}'

  # CORS
  cors:
    allowedOrigins: ["*"]
    allowedHosts: ["*"]

# Secrets
secrets:
  jwtSecretKey: "change-in-production"

  # Kafka secrets
  kafka:
    username: ""
    password: ""
    # OAuth2 for SASL_OAUTHBEARER
    oauth2:
      clientId: ""
      clientSecret: ""
      tokenEndpoint: ""
    # mTLS certificates
    tls:
      clientCert: ""  # Base64 encoded client certificate
      clientKey: ""   # Base64 encoded client private key
      caCert: ""      # Base64 encoded CA certificate

  # Redis secrets
  redis:
    password: "change-in-production"
    caCert: ""  # Base64 encoded CA certificate

  # Keycloak secrets
  keycloak:
    clientSecret: "change-in-production"

  # Schema Registry secrets
  schemaRegistry:
    username: ""
    password: ""

# Service Monitor para Prometheus
serviceMonitor:
  enabled: true
  interval: 30s
  path: /metrics
  labels:
    neural-hive-mind.org/monitoring: "enabled"

# Network Policy
networkPolicy:
  enabled: true
  ingress:
    ingressNamespace: "istio-system"
    ingressPodLabels:
      istio: ingressgateway
  egress:
    kafkaNamespace: "neural-hive-kafka"
    kafkaPodLabels:
      app.kubernetes.io/name: kafka
    jaegerNamespace: "monitoring"
    allowMLModelDownload: true

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Istio configuration
istio:
  enabled: true
  sidecar:
    inject: true
  virtualService:
    enabled: false
  gateway:
    enabled: false

# Observabilidade
# otelEnabled controla a inicialização do OpenTelemetry no startup da aplicação
observability:
  otelEnabled: true  # Habilitar OpenTelemetry em produção
  otelEndpoint: "http://opentelemetry-collector.observability.svc.cluster.local:4317"
  # Neural Hive Metadata - identificação do serviço no ecossistema
  neuralHive:
    serviceName: "gateway-intencoes"
    component: "gateway"
    layer: "experiencia"
    domain: "captura-intencoes"
  # TLS Configuration para OpenTelemetry Exporter
  tls:
    enabled: false  # Habilitar em produção
    certSecret: "neural-hive-otel-client-certs"
    mountPath: "/etc/otel-tls"
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s
      path: /metrics
      labels:
        neural-hive-mind.org/monitoring: "enabled"
  jaeger:
    enabled: true
    endpoint: "http://jaeger-collector.monitoring.svc.cluster.local:14268/api/traces"
  tracing:
    enabled: true

# Volume mounts para modelos ML
volumes:
  - name: model-cache
    emptyDir: {}  # Será sobrescrito por PVC se persistence.models.enabled for true

volumeMounts:
  - name: model-cache
    mountPath: /app/models

# Persistent volumes para modelos ML
persistence:
  models:
    enabled: true
    storageClass: "gp3"
    accessMode: ReadWriteMany
    size: 2Gi
    annotations:
      neural-hive-mind.org/backup: "false"

# Environment específicos
environments:
  dev:
    replicaCount: 1
    resources:
      limits:
        cpu: 1000m
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi
    config:
      debug: true
      logLevel: "DEBUG"
      nlu:
        routingThresholdHigh: 0.4  # Mais permissivo em dev
        routingThresholdLow: 0.2
        routingUseAdaptiveForDecisions: true  # Testar adaptive em dev

  staging:
    replicaCount: 2
    config:
      logLevel: "INFO"
      nlu:
        # Configuração para testes A/B: adaptive desabilitado para usar thresholds fixos
        # Esta configuração é temporária para experimentos de validação
        adaptiveThresholdEnabled: false  # Desabilitado para A/B test com thresholds fixos
        routingUseAdaptiveForDecisions: false  # Usar apenas thresholds fixos para roteamento
        routingThresholdHigh: 0.5  # Balanceado
        routingThresholdLow: 0.3

  prod:
    replicaCount: 3
    config:
      logLevel: "WARNING"
      nlu:
        routingThresholdHigh: 0.6  # Mais conservador
        routingThresholdLow: 0.35
