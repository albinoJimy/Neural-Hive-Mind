# Neural Hive-Mind - Fase 1: FundaÃ§Ã£o

ğŸš€ **Infraestrutura como CÃ³digo para a base do organismo digital Neural Hive-Mind**

Este repositÃ³rio implementa a **Fase 1 - FundaÃ§Ã£o** do Neural Hive-Mind, estabelecendo a infraestrutura essencial para suportar um sistema de IA distribuÃ­do com arquitetura zero-trust, observabilidade nativa e governanÃ§a auditÃ¡vel.

## ğŸ“‹ VisÃ£o Geral

A Fase 1 provisiona:

- **ğŸ—ï¸ Infraestrutura de Rede**: VPC multi-zona com subnets pÃºblicas/privadas
- **âš™ï¸ Cluster Kubernetes**: EKS gerenciado com auto-scaling e alta disponibilidade
- **ğŸ³ Container Registry**: ECR com scanning de vulnerabilidades e assinatura de imagens
- **ğŸ•¸ï¸ Service Mesh**: Istio com mTLS STRICT obrigatÃ³rio
- **ğŸš¦ Policy Engine**: OPA Gatekeeper para governanÃ§a policy-as-code
- **ğŸ“Š Observabilidade**: Bases para mÃ©tricas, logs e tracing distribuÃ­do

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEURAL HIVE-MIND FOUNDATION              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ—ï¸  INFRASTRUCTURE LAYER                                   â”‚
â”‚  â”œâ”€â”€ Network (VPC, Subnets, NAT, Security Groups)          â”‚
â”‚  â”œâ”€â”€ Kubernetes Cluster (EKS + Node Groups)                â”‚
â”‚  â””â”€â”€ Container Registry (ECR + Vulnerability Scanning)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”’  SECURITY & GOVERNANCE LAYER                           â”‚
â”‚  â”œâ”€â”€ Service Mesh (Istio + mTLS STRICT)                    â”‚
â”‚  â”œâ”€â”€ Policy Engine (OPA Gatekeeper + Constraints)          â”‚
â”‚  â””â”€â”€ Network Policies (Zero Trust Segmentation)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¦  APPLICATION NAMESPACES                                 â”‚
â”‚  â”œâ”€â”€ neural-hive-cognition     (Processamento Cognitivo)   â”‚
â”‚  â”œâ”€â”€ neural-hive-orchestration (CoordenaÃ§Ã£o)               â”‚
â”‚  â”œâ”€â”€ neural-hive-execution     (Agentes e Workers)         â”‚
â”‚  â””â”€â”€ neural-hive-observability (MÃ©tricas e Logs)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start - Desenvolvimento Local

Inicie o Neural Hive-Mind em sua mÃ¡quina usando Minikube:

### PrÃ©-requisitos

- Docker (>= 24.0.0)
- Minikube (>= 1.32.0)
- kubectl (>= 1.28.0)
- Helm (>= 3.13.0)
- 4 CPU cores, 8GB RAM, 20GB disk space

### Setup Automatizado (Recomendado)

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd Neural-Hive-Mind

# Execute o setup completo
make minikube-setup

# Valide a instalaÃ§Ã£o
make minikube-validate
```

O script de setup irÃ¡:
- âœ… Iniciar Minikube com recursos apropriados
- âœ… Habilitar addons necessÃ¡rios (ingress, metrics-server, storage-provisioner)
- âœ… Criar 9 namespaces para diferentes camadas do sistema
- âœ… Configurar RBAC e network policies
- âœ… Aplicar resource quotas e limits

### Setup Manual

Para instruÃ§Ãµes passo-a-passo, consulte o [Guia de Setup do Minikube](docs/MINIKUBE_SETUP_GUIDE.md).

### Verificar InstalaÃ§Ã£o

```bash
# Verificar status do cluster
make minikube-status

# Visualizar namespaces
kubectl get namespaces | grep neural-hive

# Abrir dashboard do Kubernetes
make minikube-dashboard
```

### PrÃ³ximos Passos

ApÃ³s completar a Fase 1 (Bootstrap), prossiga para:

**Fase 2 - Deploy da Base de Infraestrutura:**
Deploy automatizado de componentes essenciais:
- â˜¸ï¸ Kafka (Strimzi) - Sistema de mensageria distribuÃ­do
- ğŸ’¾ Redis - Cache em memÃ³ria
- ğŸ“„ MongoDB - Banco de dados de documentos
- ğŸ•¸ï¸ Neo4j - Banco de dados de grafos
- ğŸ“Š ClickHouse - Banco de dados analÃ­tico
- ğŸ” Keycloak - AutenticaÃ§Ã£o e autorizaÃ§Ã£o

```bash
# Deploy automatizado de todos os componentes
./scripts/deploy/deploy-infrastructure-local.sh

# Validar instalaÃ§Ã£o
./scripts/validation/validate-infrastructure-local.sh
```

Veja o [Guia de Deploy Local](DEPLOYMENT_LOCAL.md#ï¸-fase-2-deploy-da-base-de-infraestrutura) para instruÃ§Ãµes detalhadas da Fase 2

---

## ğŸš€ Quick Start - AWS Production

Para deploy em produÃ§Ã£o na AWS:

### PrÃ©-requisitos

```bash
# Ferramentas necessÃ¡rias
terraform >= 1.5
helm >= 3.13
kubectl >= 1.28
aws-cli >= 2.0

# Credenciais AWS configuradas
aws configure
aws sts get-caller-identity
```

### Deploy RÃ¡pido

```bash
# 1. Configure ambiente
export ENV=dev  # ou staging, prod
export AWS_REGION=us-east-1
export CLUSTER_NAME=neural-hive-${ENV}

# 2. Deploy completo
chmod +x scripts/deploy/deploy-foundation.sh
./scripts/deploy/deploy-foundation.sh

# 3. Validar deployment
./scripts/validation/validate-cluster-health.sh
```

---

## ğŸ“‹ Fases de Deploy

O deploy do Neural Hive-Mind estÃ¡ organizado em fases incrementais:

### Fase 1: Bootstrap (âœ… VocÃª estÃ¡ aqui)
- Inicializar cluster Minikube
- Configurar namespaces, RBAC, network policies
- Aplicar resource quotas e limits
- **Guia**: [Guia de Setup do Minikube](docs/MINIKUBE_SETUP_GUIDE.md)

### Fase 2: Infraestrutura
- Deploy Kafka, Redis, MongoDB, Neo4j, ClickHouse
- Configurar Keycloak para autenticaÃ§Ã£o
- **Guia**: [Guia de Deploy Local](DEPLOYMENT_LOCAL.md)

### Fase 3: ServiÃ§os Core
- Deploy Gateway, Semantic Translation Engine
- Deploy 5 Neural Specialists
- Deploy Consensus Engine e Memory Layer

### Fase 4: OrquestraÃ§Ã£o & ExecuÃ§Ã£o
- Deploy Orchestrator Dynamic e Service Registry
- Deploy Execution Ticket Service e Worker Agents
- Deploy agentes de coordenaÃ§Ã£o (Queen, Scout, Analyst, Optimizer, Guard)

### Fase 5: Funcionalidades AvanÃ§adas
- Deploy Code Forge, SLA Management, Self-Healing Engine
- Deploy MCP Tool Catalog
- Executar testes end-to-end

---

## ğŸ“ Estrutura do Projeto

```
Neural-Hive-Mind/
â”œâ”€â”€ infrastructure/terraform/         # MÃ³dulos Terraform IaC
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ network/                 # VPC e rede
â”‚       â”œâ”€â”€ k8s-cluster/             # Cluster EKS
â”‚       â””â”€â”€ container-registry/      # ECR registry
â”œâ”€â”€ helm-charts/                     # Charts Helm customizados
â”‚   â”œâ”€â”€ istio-base/                  # Service mesh
â”‚   â””â”€â”€ opa-gatekeeper/              # Policy engine
â”œâ”€â”€ policies/                        # PolÃ­ticas OPA/Rego
â”‚   â”œâ”€â”€ rego/                        # PolÃ­ticas em linguagem Rego
â”‚   â”œâ”€â”€ constraint-templates/        # Templates Gatekeeper
â”‚   â””â”€â”€ constraints/                 # Constraints ativos
â”œâ”€â”€ k8s/bootstrap/                   # Manifests iniciais
â”‚   â”œâ”€â”€ namespaces.yaml             # Namespaces e quotas
â”‚   â”œâ”€â”€ rbac.yaml                   # Service accounts e roles
â”‚   â””â”€â”€ network-policies.yaml       # PolÃ­ticas de rede
â”œâ”€â”€ scripts/                         # Scripts de automaÃ§Ã£o
â”‚   â”œâ”€â”€ deploy/                     # Scripts de deploy
â”‚   â””â”€â”€ validation/                 # Scripts de validaÃ§Ã£o
â”œâ”€â”€ environments/                    # ConfiguraÃ§Ãµes por ambiente
â”‚   â”œâ”€â”€ dev/                        # Desenvolvimento
â”‚   â”œâ”€â”€ staging/                    # HomologaÃ§Ã£o
â”‚   â””â”€â”€ prod/                       # ProduÃ§Ã£o
â”œâ”€â”€ docs/adr/                       # Architecture Decision Records
â””â”€â”€ .github/workflows/              # Pipelines CI/CD
```

## âš™ï¸ Componentes Principais

### ğŸ—ï¸ Infraestrutura (Terraform)

- **Network**: VPC multi-zona, NAT Gateways, VPC Endpoints
- **K8s Cluster**: EKS com node groups auto-scaling
- **Registry**: ECR com lifecycle policies e scanning

### ğŸ”’ SeguranÃ§a (Istio + OPA)

- **mTLS**: Certificados SPIFFE automÃ¡ticos
- **Zero Trust**: Network policies granulares
- **Policies**: Validation de imagens, resources, compliance

### ğŸ“¦ AplicaÃ§Ã£o (Namespaces)

- **Cognition**: Processamento e interpretaÃ§Ã£o
- **Orchestration**: CoordenaÃ§Ã£o e workflow
- **Execution**: Agentes e workers
- **Observability**: MÃ©tricas, logs e tracing

## ğŸ§  Motor de TraduÃ§Ã£o SemÃ¢ntica (Fase 1)

O **Motor de TraduÃ§Ã£o SemÃ¢ntica** implementa o **Fluxo B (GeraÃ§Ã£o de Planos)** do Neural Hive-Mind, convertendo Intent Envelopes em Cognitive Plans executÃ¡veis com DAGs de tarefas, avaliaÃ§Ã£o de risco e explicabilidade.

### Componentes Implementados

- âœ… **Semantic Parser**: Parsing semÃ¢ntico com enriquecimento via Knowledge Graph (Neo4j)
- âœ… **DAG Generator**: GeraÃ§Ã£o de grafos acÃ­clicos de tarefas com validaÃ§Ã£o topolÃ³gica
- âœ… **Risk Scorer**: AvaliaÃ§Ã£o de risco baseada em heurÃ­sticas (prioridade, seguranÃ§a, complexidade)
- âœ… **Explainability Generator**: GeraÃ§Ã£o de tokens e narrativas de explicabilidade
- âœ… **Cognitive Ledger**: Registro imutÃ¡vel de planos no MongoDB com hash SHA-256
- âœ… **Kafka Consumer/Producer**: Consumo de intents e publicaÃ§Ã£o de planos com exactly-once semantics

### Fluxo de Processamento (B1-B6)

```
Intent Envelope (Kafka) â†’ B1:Receber â†’ B2:Enriquecer (Neo4j) â†’
B3:DAG â†’ B4:Risk Score â†’ B5:Ledger â†’ B6:Publicar (plans.ready)
```

## ğŸ”„ IntegraÃ§Ã£o Completa do Fluxo C (Fase 2)

A **IntegraÃ§Ã£o do Fluxo C** conecta todos os componentes da Fase 2 em um fluxo end-to-end que processa Consolidated Decisions desde a intenÃ§Ã£o inicial atÃ© o deploy final, com telemetria correlacionada completa.

### Componentes Integrados

- âœ… **Biblioteca neural_hive_integration v1.0.0**: 7 clients unificados para todos os serviÃ§os da Fase 2
- âœ… **FlowCOrchestrator**: CoordenaÃ§Ã£o completa do fluxo C1-C6 (ValidaÃ§Ã£o â†’ Tickets â†’ Workers â†’ Deploy â†’ Telemetria)
- âœ… **FlowCConsumer**: Consumer Kafka integrado no Orchestrator Dynamic para tÃ³pico `plans.consensus`
- âœ… **Telemetry Publisher**: CorrelaÃ§Ã£o de eventos com OpenTelemetry (trace_id, span_id, correlation_id)
- âœ… **TÃ³pico telemetry.flow-c**: Kafka topic dedicado para eventos de integraÃ§Ã£o

### Fluxo Completo C1-C6

```
Consolidated Decision â†’ C1:Validar â†’ C2:Gerar Tickets â†’ C3:Descobrir Workers â†’
C4:Atribuir Tarefas â†’ C5:Monitorar ExecuÃ§Ã£o â†’ C6:Publicar Telemetria
```

### Deploy RÃ¡pido

```bash
# Deploy da integraÃ§Ã£o Fase 2
./scripts/deploy/deploy-phase2-integration.sh

# Validar componentes
./scripts/validation/validate-phase2-integration.sh

# Teste end-to-end completo
./tests/phase2-flow-c-integration-test.sh
```

### MÃ©tricas de Sucesso

| MÃ©trica | SLO | Atual |
|---------|-----|-------|
| LatÃªncia End-to-End (P95) | < 4 horas | - |
| Taxa de Sucesso | > 99% | - |
| AprovaÃ§Ã£o AutomÃ¡tica | > 80% | - |
| Disponibilidade Workers | > 95% | - |

### DocumentaÃ§Ã£o Completa

ğŸ“– **[Guia de IntegraÃ§Ã£o do Fluxo C](docs/PHASE2_FLOW_C_INTEGRATION.md)**
- Arquitetura detalhada com diagramas Mermaid
- Exemplos de cÃ³digo para todos os clients
- Observabilidade (mÃ©tricas Prometheus, dashboard Grafana, tracing Jaeger)
- Troubleshooting e runbooks
- SLAs e error budgets

ğŸ”’ **[Guia da Camada de Compliance](docs/COMPLIANCE_LAYER_GUIDE.md)**
- DetecÃ§Ã£o e anonimizaÃ§Ã£o de PII com Microsoft Presidio
- Criptografia de campos sensÃ­veis (Fernet AES-128)
- Audit logging e polÃ­ticas de retenÃ§Ã£o
- Conformidade com LGPD e GDPR
- MÃ©tricas Prometheus e troubleshooting

---

## ğŸ§  Motor de TraduÃ§Ã£o SemÃ¢ntica (Fase 1)

O **Motor de TraduÃ§Ã£o SemÃ¢ntica** implementa o **Fluxo B (GeraÃ§Ã£o de Planos)** do Neural Hive-Mind, convertendo Intent Envelopes em Cognitive Plans executÃ¡veis com DAGs de tarefas, avaliaÃ§Ã£o de risco e explicabilidade.

### Componentes Implementados

- âœ… **Semantic Parser**: Parsing semÃ¢ntico com enriquecimento via Knowledge Graph (Neo4j)
- âœ… **DAG Generator**: GeraÃ§Ã£o de grafos acÃ­clicos de tarefas com validaÃ§Ã£o topolÃ³gica
- âœ… **Risk Scorer**: AvaliaÃ§Ã£o de risco baseada em heurÃ­sticas (prioridade, seguranÃ§a, complexidade)
- âœ… **Explainability Generator**: GeraÃ§Ã£o de tokens e narrativas de explicabilidade
- âœ… **Cognitive Ledger**: Registro imutÃ¡vel de planos no MongoDB com hash SHA-256
- âœ… **Kafka Consumer/Producer**: Consumo de intents e publicaÃ§Ã£o de planos com exactly-once semantics

### Fluxo de Processamento (B1-B6)

```
Intent Envelope (Kafka) â†’ B1:Receber â†’ B2:Enriquecer (Neo4j) â†’
B3:DAG â†’ B4:Risk Score â†’ B5:Ledger â†’ B6:Publicar (plans.ready)
```

1. **B1: Receber**: Consumir Intent Envelope do Kafka com validaÃ§Ã£o de assinatura
2. **B2: Enriquecer**: Consultar Knowledge Graph (Neo4j) para contexto histÃ³rico e ontologias
3. **B3: Decompor**: Gerar DAG de tarefas com validaÃ§Ã£o de aciclicidade
4. **B4: Avaliar**: Calcular risk score (prioridade=0.3 + seguranÃ§a=0.4 + complexidade=0.3)
5. **B5: Versionar**: Registrar plano no ledger imutÃ¡vel (MongoDB)
6. **B6: Publicar**: Enviar Cognitive Plan para tÃ³pico `plans.ready`

### Deploy

```bash
# Deploy completo
export ENV=dev
export NEO4J_PASSWORD=secret
export MONGODB_PASSWORD=secret
./scripts/deploy/deploy-semantic-translation-engine.sh

# Validar deployment
./scripts/validation/validate-semantic-translation-engine.sh
```

### Acesso e Monitoramento

```bash
# Logs em tempo real
kubectl logs -f -n semantic-translation-engine \
  -l app.kubernetes.io/name=semantic-translation-engine

# MÃ©tricas Prometheus
kubectl port-forward -n semantic-translation-engine \
  svc/semantic-translation-engine 8080:8080
curl http://localhost:8080/metrics

# Verificar consumer lag
kafka-consumer-groups.sh --bootstrap-server <kafka> \
  --group semantic-translation-engine --describe
```

### Dashboards e Observabilidade

- **Grafana Dashboard**: LatÃªncia B1â†’B6, DAG complexity, risk distribution
- **Jaeger Traces**: CorrelaÃ§Ã£o intent_id â†’ plan_id â†’ trace_id
- **Prometheus Metrics**:
  - `neural_hive_geracao_duration_seconds` - LatÃªncia de geraÃ§Ã£o (SLO <400ms)
  - `neural_hive_dag_complexity` - DistribuiÃ§Ã£o de complexidade
  - `neural_hive_risk_score` - Scores de risco por domÃ­nio
  - `neural_hive_kg_query_duration_seconds` - LatÃªncia Neo4j (SLO <50ms)

### DocumentaÃ§Ã£o

- [OperaÃ§Ãµes do Motor](docs/operations/semantic-translation-engine-operations.md)
- [Documento 06 - Fluxo B](documento-06-fluxos-processos-neural-hive-mind.md)
- [Schema Cognitive Plan](schemas/cognitive-plan/cognitive-plan.avsc)

## ğŸ”§ ConfiguraÃ§Ã£o por Ambiente

### Development
```bash
# Recursos mÃ­nimos para desenvolvimento
cluster_name = "neural-hive-dev"
node_instance_types = ["t3.medium", "t3.large"]
min_nodes_per_zone = 1
enable_vulnerability_scanning = true
block_critical_vulnerabilities = false
```

### Production
```bash
# ConfiguraÃ§Ã£o otimizada para produÃ§Ã£o
cluster_name = "neural-hive-prod"
node_instance_types = ["m5.large", "m5.xlarge", "c5.large"]
min_nodes_per_zone = 2
enable_vulnerability_scanning = true
block_critical_vulnerabilities = true
```

## ğŸ§ª ValidaÃ§Ã£o e Testes

### ValidaÃ§Ã£o de Infraestrutura
```bash
# Terraform validation
./scripts/validation/validate-terraform.sh

# Cluster health check
./scripts/validation/validate-cluster-health.sh

# mTLS connectivity test
./scripts/validation/test-mtls-connectivity.sh

# Autoscaler test
./scripts/validation/test-autoscaler.sh
```

### CI/CD Pipelines

- **Validation Pipeline**: Terraform, Helm, OPA policies
- **Deployment Pipeline**: GitOps com aprovaÃ§Ãµes automÃ¡ticas
- **Integration Tests**: ValidaÃ§Ã£o em cluster Kind

## ğŸ“Š Observabilidade

### MÃ©tricas Coletadas
- **Cluster**: Nodes, pods, resources
- **Service Mesh**: mTLS, latÃªncia, throughput
- **Policies**: ViolaÃ§Ãµes, compliance
- **Applications**: MÃ©tricas customizadas

### Dashboards
- **Infrastructure**: UtilizaÃ§Ã£o de recursos
- **Security**: Status mTLS, violaÃ§Ãµes
- **Performance**: LatÃªncia, errors, throughput

## ğŸ”„ Disaster Recovery

Sistema de backup e recuperaÃ§Ã£o automÃ¡tica para garantir continuidade de operaÃ§Ã£o dos especialistas neurais.

### Funcionalidades

- âœ… **Backups AutomÃ¡ticos**: CronJob diÃ¡rio Ã s 2h UTC de todos os componentes crÃ­ticos
- âœ… **MÃºltiplos Storage**: Suporte para S3, Google Cloud Storage e filesystem local
- âœ… **Componentes Backed Up**: Modelos MLflow, Ledger cognitivo, Feature Store, Cache, MÃ©tricas
- âœ… **RetenÃ§Ã£o ConfigurÃ¡vel**: 90 dias por padrÃ£o com cleanup automÃ¡tico
- âœ… **Testes de Recovery**: ValidaÃ§Ã£o semanal automÃ¡tica de backups
- âœ… **Restore Granular**: RestauraÃ§Ã£o completa ou por componente individual
- âœ… **Multi-Tenancy**: Backups isolados por tenant
- âœ… **Observabilidade**: MÃ©tricas, alertas e dashboard dedicados

### Quick Start

```bash
# Configurar variÃ¡veis de ambiente (S3 exemplo)
export ENABLE_DISASTER_RECOVERY=true
export BACKUP_STORAGE_PROVIDER=s3
export BACKUP_S3_BUCKET=neural-hive-backups
export BACKUP_S3_REGION=us-west-2
export BACKUP_RETENTION_DAYS=90

# Backup manual de um especialista
make dr-backup SPECIALIST_TYPE=business

# Listar backups disponÃ­veis
make dr-list-backups SPECIALIST_TYPE=business

# Restaurar Ãºltimo backup
make dr-restore SPECIALIST_TYPE=business

# Testar recovery (nÃ£o afeta produÃ§Ã£o)
make dr-test-recovery SPECIALIST_TYPE=business
```

### Targets Make DisponÃ­veis

```bash
make dr-backup              # Backup manual de todos os especialistas
make dr-restore             # Restore interativo
make dr-list-backups        # Lista backups disponÃ­veis
make dr-test-recovery       # Testa restore sem afetar produÃ§Ã£o
make deploy-dr-cronjobs     # Deploy dos CronJobs de backup e teste
```

### VariÃ¡veis de Ambiente

**Essenciais:**
- `ENABLE_DISASTER_RECOVERY`: Habilitar DR (default: false)
- `BACKUP_STORAGE_PROVIDER`: s3, gcs ou local
- `BACKUP_S3_BUCKET`: Bucket S3 (se provider=s3)
- `BACKUP_GCS_BUCKET`: Bucket GCS (se provider=gcs)
- `BACKUP_GCS_PROJECT`: Projeto GCP (se provider=gcs)

**Opcionais:**
- `BACKUP_RETENTION_DAYS`: Dias de retenÃ§Ã£o (default: 90)
- `BACKUP_SCHEDULE_CRON`: Schedule de backup (default: "0 2 * * *")
- `RECOVERY_TEST_SCHEDULE_CRON`: Schedule de teste (default: "0 4 * * 0")
- `BACKUP_INCLUDE_CACHE`: Incluir cache Redis (default: false)
- `BACKUP_COMPRESSION_LEVEL`: NÃ­vel gzip 1-9 (default: 6)

### Monitoramento

**Dashboard Grafana:**
- Status de Ãºltimo backup e teste de recovery
- Trends de tamanho e duraÃ§Ã£o de backups
- Breakdown por componente (model, ledger, feature store, cache, metrics)
- Erros de storage (upload/download)
- Alertas ativos de DR

**Alertas Configurados:**
- ğŸ”´ `BackupFailed`: Backup falhou
- ğŸŸ¡ `BackupNotRunRecently`: >25h sem backup
- ğŸ”´ `RecoveryTestFailed`: Teste de recovery falhou
- ğŸŸ¡ `StorageUploadErrors`: Erros persistentes de upload
- ğŸŸ¡ `BackupDurationAnomaly`: DuraÃ§Ã£o anormal de backup
- ğŸŸ¡ `BackupSizeAnomaly`: Tamanho anormal de backup

### DocumentaÃ§Ã£o Operacional

- ğŸ“– [Runbook de Disaster Recovery](docs/operations/DISASTER_RECOVERY_RUNBOOK.md) - Procedimentos operacionais completos
- ğŸš¨ [Playbook de Incidentes](docs/operations/DISASTER_RECOVERY_PLAYBOOK.md) - Guia step-by-step para emergÃªncias
- ğŸ“Š [Dashboard Grafana](monitoring/dashboards/disaster-recovery-dashboard.json) - Dashboard de monitoramento
- ğŸ”” [Regras de Alerta](monitoring/alerts/disaster-recovery-alerts.yaml) - Alertas Prometheus

### Arquitetura de Backup

Cada backup contÃ©m:
- **model/**: Artifacts e metadata do modelo MLflow
- **ledger/**: Dump BSON do ledger cognitivo (MongoDB)
- **feature_store/**: Features extraÃ­das em JSON
- **cache/**: Snapshot do cache Redis (opcional)
- **metrics/**: Resumo de mÃ©tricas Prometheus
- **config/**: ConfiguraÃ§Ã£o do especialista
- **manifest.json**: Metadados do backup (timestamp, versÃ£o, checksums)

### Restore

**Restore Completo:**
```bash
# Ãšltima versÃ£o
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business

# VersÃ£o especÃ­fica
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --backup-id specialist-business-backup-20250211-143000 \
  --specialist-type business
```

**Restore Parcial (por componente):**
```bash
# Apenas modelo MLflow
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business --components model

# MÃºltiplos componentes
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business --components model,ledger,feature_store
```

### RPO e RTO

- **RPO (Recovery Point Objective)**: 24 horas (backups diÃ¡rios)
- **RTO (Recovery Time Objective)**:
  - Restore completo: 30-60 minutos
  - Restore parcial (modelo): 15-30 minutos
  - Rollback emergencial: 10-15 minutos

## Especialistas Neurais (Fase 1)

Os **5 Especialistas Neurais** implementam avaliaÃ§Ã£o multi-domÃ­nio de planos cognitivos com consenso auditÃ¡vel.

### Componentes
- âœ… **Business Specialist**: anÃ¡lise de workflows, KPIs, custos
- âœ… **Technical Specialist**: qualidade de cÃ³digo, performance, seguranÃ§a
- âœ… **Behavior Specialist**: jornadas de usuÃ¡rio, anÃ¡lise de sentimento
- âœ… **Evolution Specialist**: oportunidades de melhoria, hipÃ³teses
- âœ… **Architecture Specialist**: dependÃªncias, escalabilidade, padrÃµes

### CaracterÃ­sticas
- Contrato gRPC padronizado
- Registro dinÃ¢mico e health checks
- IntegraÃ§Ã£o com MLflow para versionamento de modelos
- Explicabilidade estruturada (SHAP/LIME)
- PersistÃªncia no ledger cognitivo (MongoDB)
- Observabilidade completa (OpenTelemetry)

### Deploy
```bash
# Deploy completo dos especialistas
export ENV=dev
export MLFLOW_TRACKING_URI=http://mlflow:5000
export MONGODB_URI=mongodb://mongodb:27017
export NEO4J_PASSWORD=secret
./scripts/deploy/deploy-specialists.sh

# Validar deployment
./scripts/validation/validate-specialists.sh
```

### Acesso
```bash
# Logs de um especialista
kubectl logs -f -n specialist-business -l app.kubernetes.io/name=specialist-business

# MÃ©tricas
kubectl port-forward -n specialist-business svc/specialist-business 8080:8080
curl http://localhost:8080/metrics

# MLflow UI
kubectl port-forward -n mlflow svc/mlflow 5000:5000
open http://localhost:5000
```

### Dashboards
- Specialists Cognitive Layer: http://grafana/d/specialists-cognitive-layer
- Fluxo B - GeraÃ§Ã£o de Planos: http://grafana/d/fluxo-b-geracao-planos

### DocumentaÃ§Ã£o
- [OperaÃ§Ãµes dos Especialistas](docs/operations/specialists-operations.md)
- [Camada Cognitiva](docs/observability/services/agentes/camada-cognitiva.md)
- [CatÃ¡logo de Agentes](docs/observability/services/agentes.md)

## Mecanismo de Consenso Multi-Agente (Fase 1)

O **Mecanismo de Consenso** implementa agregaÃ§Ã£o auditÃ¡vel de pareceres dos 5 especialistas neurais com Bayesian Model Averaging, voting ensemble e feromÃ´nios digitais.

### Componentes
- âœ… **Bayesian Aggregator**: combina distribuiÃ§Ãµes de probabilidade dos especialistas
- âœ… **Voting Ensemble**: agregaÃ§Ã£o ponderada com pesos dinÃ¢micos
- âœ… **FeromÃ´nios Digitais**: protocolo de sinalizaÃ§Ã£o para coordenaÃ§Ã£o de enxame
- âœ… **Compliance Fallback**: regras determinÃ­sticas para guardrails Ã©ticos
- âœ… **Explainability Consolidator**: geraÃ§Ã£o de explicaÃ§Ãµes consolidadas
- âœ… **Ledger de DecisÃµes**: registro imutÃ¡vel no MongoDB
- âœ… **gRPC Client**: invocaÃ§Ã£o paralela de especialistas

### CaracterÃ­sticas
- InvocaÃ§Ã£o paralela de 5 especialistas via gRPC
- AgregaÃ§Ã£o Bayesiana com prior configurÃ¡vel
- Pesos dinÃ¢micos ajustados por feromÃ´nios
- Fallback determinÃ­stico para compliance
- Explicabilidade consolidada com tokens
- PersistÃªncia no ledger com hash SHA-256
- PublicaÃ§Ã£o no Kafka (`plans.consensus`)

### Fluxo de Consenso
1. Consumir Cognitive Plan do Kafka (`plans.ready`)
2. Invocar 5 especialistas em paralelo (gRPC)
3. Calcular pesos dinÃ¢micos com feromÃ´nios
4. Agregar com Bayesian Model Averaging
5. Aplicar voting ensemble
6. Verificar compliance e aplicar fallback se necessÃ¡rio
7. Gerar explicabilidade consolidada
8. Persistir decisÃ£o no ledger
9. Publicar feromÃ´nios
10. Publicar decisÃ£o no Kafka (`plans.consensus`)

### Deploy
```bash
# Deploy completo
export ENV=dev
export MONGODB_PASSWORD=secret
export REDIS_PASSWORD=secret
./scripts/deploy/deploy-consensus-engine.sh
```

### Acesso
```bash
# Logs
kubectl logs -f -n consensus-engine -l app.kubernetes.io/name=consensus-engine

# MÃ©tricas
kubectl port-forward -n consensus-engine svc/consensus-engine 8080:8080
curl http://localhost:8080/metrics

# API de decisÃµes
kubectl port-forward -n consensus-engine svc/consensus-engine 8000:8000
curl http://localhost:8000/api/v1/decisions/<decision-id>
```

### Dashboards
- Consensus Governance: http://grafana/d/consensus-governance
- Specialists Cognitive Layer: http://grafana/d/specialists-cognitive-layer

### DocumentaÃ§Ã£o
- [Mecanismos de Consenso - Documento 03](documento-03-componentes-e-processos-neural-hive-mind.md)
- [Fluxo B - Documento 06](documento-06-fluxos-processos-neural-hive-mind.md)

## IntegraÃ§Ã£o Completa da Camada de MemÃ³ria Multicamadas (Fase 1)

A **IntegraÃ§Ã£o da Camada de MemÃ³ria** conecta as 4 camadas de armazenamento com API unificada, pipelines de sincronizaÃ§Ã£o, data quality monitoring e lineage tracking.

### Componentes
- âœ… **Memory Layer API**: API unificada com roteamento inteligente (hot â†’ Redis, warm â†’ MongoDB, cold â†’ ClickHouse, semantic â†’ Neo4j)
- âœ… **Cliente ClickHouse**: driver async para analytics histÃ³rico com schemas otimizados
- âœ… **Pipelines de SincronizaÃ§Ã£o**: batch (MongoDB â†’ ClickHouse diariamente) e streaming (Kafka â†’ ClickHouse)
- âœ… **Data Quality Monitor**: validaÃ§Ãµes, profiling, anomaly detection
- âœ… **Lineage Tracker**: rastreamento de proveniÃªncia (MongoDB + Neo4j)
- âœ… **Retention Policy Manager**: enforcement de TTL e retenÃ§Ã£o por camada
- âœ… **PolÃ­ticas Centralizadas**: ConfigMap com TTL e retention por data_type

### CaracterÃ­sticas
- Roteamento automÃ¡tico baseado em time_range e query_type
- Cache multi-nÃ­vel com fallback (Redis â†’ MongoDB â†’ ClickHouse)
- SincronizaÃ§Ã£o batch (CronJobs) e streaming (Kafka)
- Data quality monitoring com 5 dimensÃµes (completeness, accuracy, timeliness, uniqueness, consistency)
- Lineage tracking com grafo de dependÃªncias (Neo4j) e metadados (MongoDB)
- PolÃ­ticas de TTL e retenÃ§Ã£o centralizadas e enforÃ§adas automaticamente
- Observabilidade completa (mÃ©tricas, dashboards, alertas)

### PolÃ­ticas de RetenÃ§Ã£o
- **Redis**: 5-15 minutos (TTL automÃ¡tico)
- **MongoDB**: 30 dias (cleanup diÃ¡rio)
- **ClickHouse**: 18 meses (particionamento mensal)
- **Neo4j**: versionamento de ontologias (max 10 versÃµes)
- **Audit/Compliance**: overrides para 5 anos

### Deploy
```bash
# Deploy completo
export ENV=dev
export MONGODB_PASSWORD=secret
export NEO4J_PASSWORD=secret
export CLICKHOUSE_PASSWORD=secret
./scripts/deploy/deploy-memory-layer-api.sh
./scripts/deploy/deploy-memory-sync-jobs.sh

# Validar deployment
./scripts/validation/validate-memory-layer-integration.sh
```

### Acesso
```bash
# API unificada
kubectl port-forward -n memory-layer-api svc/memory-layer-api 8000:8000
curl -X POST http://localhost:8000/api/v1/memory/query \
  -d '{"query_type": "context", "entity_id": "<id>"}'

# Lineage
curl http://localhost:8000/api/v1/memory/lineage/<entity-id>

# Quality stats
curl http://localhost:8000/api/v1/memory/quality/stats
```

### Dashboards
- Memory Layer Data Quality: http://grafana/d/memory-layer-data-quality
- Memory Layer Lineage: http://grafana/d/memory-layer-lineage
- Memory Layer Overview: http://grafana/d/memory-layer-overview

### DocumentaÃ§Ã£o
- [MemÃ³ria Neural Multicamadas - Documento 03](documento-03-componentes-e-processos-neural-hive-mind.md)
- [Camada de Conhecimento & Dados - Documento 08](documento-08-detalhamento-tecnico-camadas-neural-hive-mind.md)

## ğŸ›¡ï¸ GovernanÃ§a e ComunicaÃ§Ã£o (Fase 1 - FinalizaÃ§Ã£o)

As **Camadas de GovernanÃ§a e ComunicaÃ§Ã£o** completam a Fase 1 com protocolos de coordenaÃ§Ã£o, risk scoring, explicabilidade e auditoria.

### Componentes
- âœ… **Pheromone Communication Protocol**: coordenaÃ§Ã£o de enxame com feromÃ´nios digitais (Redis + Neo4j futuro)
- âœ… **Risk Scoring Engine**: biblioteca multi-domÃ­nio (business, technical, security, operational, compliance)
- âœ… **Explainability Generator**: SHAP/LIME para modelos opacos, API de consulta
- âœ… **Ledger de Auditoria**: MongoDB com hash SHA-256, 100% auditÃ¡vel
- âœ… **Compliance Engine**: OPA Gatekeeper + fallback determinÃ­stico
- âœ… **Dashboards de GovernanÃ§a**: visÃ£o executiva consolidada
- âœ… **Eventos de Autocura**: publicaÃ§Ã£o no Kafka para rastreamento

### CaracterÃ­sticas
- FeromÃ´nios com decay temporal (10% por hora)
- Risk scoring configurÃ¡vel por domÃ­nio e fator
- Explicabilidade 100% com mÃºltiplos mÃ©todos (SHAP, LIME, rule_based)
- Auditoria completa com trilhas imutÃ¡veis
- Compliance por design com polÃ­ticas versionadas
- Dashboards executivos para governanÃ§a
- Testes end-to-end automatizados

### Pheromone Communication Protocol
- **Tipos**: SUCCESS, FAILURE, WARNING
- **TTL**: 1 hora (configurÃ¡vel)
- **Decay**: Exponencial (10% por hora)
- **Uso**: Ajuste de pesos dinÃ¢micos, coordenaÃ§Ã£o de enxame
- **Armazenamento**: Redis (curto prazo), Neo4j (longo prazo - futuro)

### Risk Scoring Multi-DomÃ­nio
- **DomÃ­nios**: Business, Technical, Security, Operational, Compliance
- **ClassificaÃ§Ã£o**: LOW, MEDIUM, HIGH, CRITICAL
- **Thresholds**: ConfigurÃ¡veis por domÃ­nio
- **Pesos**: AjustÃ¡veis por fator

### Deploy
```bash
# JÃ¡ deployado como parte dos serviÃ§os da Fase 1
# Consensus Engine inclui PheromoneClient
# Specialists incluem ExplainabilityGenerator
# Risk Scoring integrado em mÃºltiplos serviÃ§os
```

### Acesso
```bash
# Consultar feromÃ´nios
kubectl exec -n redis-cluster <pod> -- redis-cli KEYS 'pheromone:*'

# Consultar explicaÃ§Ãµes
kubectl port-forward -n explainability-api svc/explainability-api 8000:8000
curl http://localhost:8000/api/v1/explainability/<token>

# Dashboard de governanÃ§a
kubectl port-forward -n neural-hive-observability svc/grafana 3000:80
open http://localhost:3000/d/governance-executive-dashboard
```

### Testes
```bash
# Teste end-to-end completo da Fase 1
./tests/phase1-end-to-end-test.sh
```

### Dashboards
- Governance Executive Dashboard: http://grafana/d/governance-executive-dashboard
- Consensus Governance: http://grafana/d/consensus-governance
- Data Governance: http://grafana/d/data-governance
- Fluxo E - Autocura: http://grafana/d/fluxo-e-autocura

### DocumentaÃ§Ã£o
- [OperaÃ§Ãµes de GovernanÃ§a](docs/operations/governance-operations.md)
- [Pheromone Communication Protocol](docs/protocols/pheromone-communication-protocol.md)
- [Documento 04 - SeguranÃ§a e GovernanÃ§a](documento-04-seguranca-governanca-neural-hive-mind.md)
- [Documento 06 - Fluxos Operacionais](documento-06-fluxos-processos-neural-hive-mind.md)

## ğŸ“ˆ Status do Projeto

- **Fase 0 - Bootstrap**: âœ… CONCLUÃDA (Infraestrutura, Kafka, Gateway de IntenÃ§Ãµes)
- **Fase 1 - FundaÃ§Ã£o**: âœ… CONCLUÃDA
  - âœ… FundaÃ§Ã£o de Dados (MongoDB, Neo4j, ClickHouse, Redis)
  - âœ… Motor de TraduÃ§Ã£o SemÃ¢ntica (Fluxo B)
  - âœ… Especialistas Neurais (5 agentes)
  - âœ… Mecanismo de Consenso Multi-Agente
  - âœ… IntegraÃ§Ã£o Completa da Camada de MemÃ³ria
  - âœ… GovernanÃ§a e ComunicaÃ§Ã£o (FeromÃ´nios, Risk Scoring, Explicabilidade, Auditoria)
- **Fase 2 - OrquestraÃ§Ã£o**: ğŸ”„ PRÃ“XIMA (Orquestrador DinÃ¢mico, CoordenaÃ§Ã£o de Swarm)
- **Fase 3 - Autonomia**: â³ PLANEJADA (Auto-evoluÃ§Ã£o, Meta-CogniÃ§Ã£o)

### CritÃ©rios de Sucesso da Fase 1 (Validados)
- âœ… PrecisÃ£o de intenÃ§Ãµes > 90% (via Gateway + NLU)
- âœ… Tempo de resposta cognitiva < 400ms (Semantic Translation + Consensus)
- âœ… Taxa de rejeiÃ§Ã£o de polÃ­ticas < 5% (OPA Gatekeeper)
- âœ… Trilhas de auditoria completas habilitadas (100% no ledger)
- âœ… Explicabilidade 100% (tokens gerados para todas as decisÃµes)
- âœ… DivergÃªncia entre especialistas < 5% (Bayesian + Voting)
- âœ… FeromÃ´nios operacionais (coordenaÃ§Ã£o de enxame)

### PrÃ³ximos Passos (Fase 2)

- Implementar Orquestrador DinÃ¢mico (Temporal/Cadence)
- Implementar CoordenaÃ§Ã£o de Enxame (Queen Agent, Scout, Worker, Drone)
- Integrar 87 ferramentas MCP (Model Context Protocol)
- Implementar SLA Management System
- Implementar Sistema de ExecuÃ§Ã£o de Planos com rollback automÃ¡tico

## ğŸ”’ SeguranÃ§a

### Zero Trust Implementation
- mTLS obrigatÃ³rio entre todos os serviÃ§os
- Network policies deny-by-default
- Image signature validation
- Resource quotas e limits obrigatÃ³rios
- RBAC com least privilege

### Compliance
- Vulnerability scanning automÃ¡tico
- Policy-as-code auditÃ¡vel
- Encryption at rest e in transit
- Audit logs completos

## ğŸš¨ Troubleshooting

### Problemas Comuns

**Cluster nÃ£o sobe**
```bash
# Verificar quotas AWS
aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A

# Verificar IAM permissions
aws iam simulate-principal-policy --policy-source-arn <role-arn> --action-names eks:*
```

**Pods nÃ£o iniciam**
```bash
# Verificar policies OPA
kubectl get constraints -A
kubectl describe constraint <constraint-name>

# Verificar network policies
kubectl get networkpolicies -A
```

**mTLS nÃ£o funciona**
```bash
# Verificar Istio
kubectl get peerauthentication -A
istioctl proxy-status

# Debug certificados
istioctl authn tls-check <pod>.<namespace> <service>.<namespace>
```

## ğŸ“š DocumentaÃ§Ã£o

### Fase 1 - FundaÃ§Ã£o
- **[Deployment Guide](DEPLOYMENT_GUIDE.md)**: Guia detalhado de implementaÃ§Ã£o
- **[ADR-0001](docs/adr/ADR-0001-cloud-provider-selection.md)**: SeleÃ§Ã£o de Cloud Provider
- **[ADR-0002](docs/adr/ADR-0002-service-mesh-selection.md)**: SeleÃ§Ã£o de Service Mesh
- **[ADR-0003](docs/adr/ADR-0003-container-registry-solution.md)**: SoluÃ§Ã£o de Container Registry

### Fase 2 - Camada de ExecuÃ§Ã£o (100% Implementada) âœ…
- **[PHASE2_IMPLEMENTATION_STATUS.md](PHASE2_IMPLEMENTATION_STATUS.md)**: Status detalhado de todos os componentes da Fase 2
- **[PHASE2_FLOW_C_INTEGRATION.md](docs/PHASE2_FLOW_C_INTEGRATION.md)**: IntegraÃ§Ã£o completa do Flow C (Intent â†’ Deploy)
- **[neural_hive_integration Library](libraries/neural_hive_integration/README.md)**: Biblioteca Python para integraÃ§Ã£o Flow C

**Componentes Implementados**:
- âœ… Orchestrator Dynamic (Temporal workflows C1-C6)
- âœ… Service Registry (gRPC discovery)
- âœ… Execution Ticket Service (ticket management)
- âœ… Worker Agents (task execution)
- âœ… Queen/Scout/Analyst/Optimizer/Guard Agents
- âœ… Code Forge (neural code generation)
- âœ… SLA Management
- âœ… Flow C Integration (biblioteca neural_hive_integration v1.0.0)
- âœ… Observabilidade completa (8 alertas Prometheus + 6 painÃ©is Grafana)

## ğŸ”’ Compliance & GovernanÃ§a de Dados

O Neural Hive Mind implementa uma **Compliance Layer** abrangente para conformidade com LGPD/GDPR:

### Funcionalidades

- **ğŸ” DetecÃ§Ã£o de PII**: IdentificaÃ§Ã£o automÃ¡tica de dados pessoais usando Microsoft Presidio
- **ğŸ­ AnonimizaÃ§Ã£o**: MÃºltiplas estratÃ©gias (replace, mask, redact, hash)
- **ğŸ” Criptografia**: Criptografia de campos sensÃ­veis em repouso (Fernet/AES-128)
- **ğŸ“‹ Audit Logging**: Rastreamento completo de operaÃ§Ãµes de compliance
- **â° PolÃ­ticas de RetenÃ§Ã£o**: Mascaramento/deleÃ§Ã£o automÃ¡tica apÃ³s perÃ­odo configurÃ¡vel
- **ğŸ—‘ï¸ Direito ao Esquecimento**: Suporte a GDPR right to erasure
- **ğŸ“¦ Portabilidade de Dados**: ExportaÃ§Ã£o de dados de usuÃ¡rio

### ConfiguraÃ§Ã£o RÃ¡pida

#### 1. Instalar DependÃªncias

```bash
# Instalar bibliotecas de compliance
pip install presidio-analyzer presidio-anonymizer

# Baixar modelos de idioma
python -m spacy download pt_core_news_sm  # PortuguÃªs
python -m spacy download en_core_web_sm   # InglÃªs
```

#### 2. Gerar Chave de Criptografia

```bash
# Gerar chave Fernet
python scripts/generate_encryption_key.py --output-path /etc/neural-hive/encryption.key

# Ou para variÃ¡vel de ambiente
python scripts/generate_encryption_key.py --print-key
```

#### 3. Configurar VariÃ¡veis de Ambiente

```bash
# Habilitar compliance layer
export ENABLE_COMPLIANCE_LAYER=true
export ENABLE_PII_DETECTION=true
export ENABLE_FIELD_ENCRYPTION=true
export ENCRYPTION_KEY_PATH=/etc/neural-hive/encryption.key
export ENABLE_AUDIT_LOGGING=true

# ConfiguraÃ§Ãµes opcionais
export PII_DETECTION_LANGUAGES=pt,en
export PII_ANONYMIZATION_STRATEGY=replace
export FIELDS_TO_ENCRYPT=correlation_id,trace_id,span_id,intent_id
export AUDIT_LOG_RETENTION_DAYS=730
```

#### 4. Deploy PolÃ­tica de RetenÃ§Ã£o (Kubernetes)

```bash
# Criar secret com chave de criptografia
kubectl create secret generic encryption-key-secret \
  --from-file=encryption.key=/etc/neural-hive/encryption.key \
  --namespace neural-hive

# Deploy CronJob de retenÃ§Ã£o
kubectl apply -f k8s/cronjobs/retention-policy-job.yaml
```

### Arquitetura de Compliance

```mermaid
sequenceDiagram
    participant CP as Cognitive Plan
    participant PII as PIIDetector
    participant FE as FieldEncryptor
    participant AL as AuditLogger
    participant DB as MongoDB

    CP->>PII: Detectar PII em descriÃ§Ãµes
    PII-->>CP: Texto anonimizado
    CP->>DB: InferÃªncia e avaliaÃ§Ã£o
    DB->>FE: Criptografar campos sensÃ­veis
    FE-->>DB: Campos criptografados
    DB->>AL: Registrar operaÃ§Ã£o
    AL-->>DB: Audit log persistido
```

### Scripts UtilitÃ¡rios

```bash
# Executar polÃ­ticas de retenÃ§Ã£o manualmente
python scripts/run_retention_policies.py

# Modo dry-run (sem modificar dados)
python scripts/run_retention_policies.py --dry-run

# Executar polÃ­tica especÃ­fica
python scripts/run_retention_policies.py --policy-name high_risk_extended
```

### MÃ©tricas Prometheus

MÃ©tricas de compliance disponÃ­veis:

- `compliance_pii_entities_detected_total` - Entidades PII detectadas
- `compliance_fields_encrypted_total` - Campos criptografados
- `compliance_audit_events_total` - Eventos auditados
- `compliance_retention_documents_processed_total` - Documentos processados por retenÃ§Ã£o
- `compliance_pii_detection_duration_seconds` - LatÃªncia de detecÃ§Ã£o PII
- `compliance_encryption_duration_seconds` - LatÃªncia de criptografia

### PolÃ­ticas de RetenÃ§Ã£o PadrÃ£o

| PolÃ­tica | RetenÃ§Ã£o | RecomendaÃ§Ãµes | AÃ§Ã£o |
|----------|----------|---------------|------|
| `high_risk_extended` | 365 dias | reject | Mascarar |
| `standard_retention` | 90 dias | approve, conditional | Mascarar |
| `review_required_extended` | 180 dias | review_required | Mascarar |

### Conformidade LGPD/GDPR

âœ… **MinimizaÃ§Ã£o de dados**: PII detectado e anonimizado automaticamente
âœ… **Criptografia em repouso**: Campos sensÃ­veis criptografados
âœ… **Auditabilidade**: Todos os eventos registrados (retenÃ§Ã£o 2 anos)
âœ… **Direito ao esquecimento**: API para deleÃ§Ã£o por correlation_id
âœ… **Portabilidade**: API para exportar dados de usuÃ¡rio
âœ… **TransparÃªncia**: Audit logs com rastreamento completo

### DocumentaÃ§Ã£o Adicional

- [CÃ³digo de Compliance](libraries/python/neural_hive_specialists/compliance/)
- [RetentionManager](libraries/python/neural_hive_specialists/ledger/retention_manager.py)
- [Scripts de Compliance](scripts/)
- [CronJob Kubernetes](k8s/cronjobs/retention-policy-job.yaml)

## ğŸ¢ Multi-Tenancy & API Gateway

O Neural Hive Mind suporta **multi-tenancy** com isolamento completo de dados e configuraÃ§Ãµes customizadas por tenant:

### Funcionalidades

- **Envoy API Gateway**: Proxy reverso com rate limiting, load balancing e autenticaÃ§Ã£o centralizada
- **Isolamento de Dados**: OpiniÃµes, cache e mÃ©tricas isolados por tenant
- **ConfiguraÃ§Ãµes Customizadas**: Modelos ML, thresholds e features especÃ­ficos por tenant
- **Rate Limiting por Tenant**: Limites configurÃ¡veis (100-500 req/s)
- **MÃ©tricas por Tenant**: Monitoramento independente de cada tenant
- **Cardinality Protection**: Limite de 100 tenants para evitar explosÃ£o de mÃ©tricas

### Arquitetura

```
Consensus Engine â†’ Envoy Gateway (JWT + Rate Limit + LB)
                        â†“
                  MultiTenantSpecialist
                        â†“
          Ledger (tenant_id) + Cache (tenant prefix) + Metrics (tenant label)
```

### Quick Start

1. **Deploy Envoy Gateway:**
   ```bash
   make deploy-envoy-gateway
   ```

2. **Configurar tenants:**
   ```bash
   kubectl apply -f k8s/configmaps/tenant-configs.yaml
   ```

3. **Migrar ledger existente:**
   ```bash
   make migrate-ledger-tenant-id MONGODB_URI=mongodb://localhost:27017
   ```

4. **Habilitar multi-tenancy nos especialistas:**
   ```bash
   export ENABLE_MULTI_TENANCY=true
   export TENANT_CONFIGS_PATH=/etc/neural-hive/tenants/tenant-configs.json
   ```

5. **Visualizar mÃ©tricas:**
   ```bash
   make view-multi-tenancy-dashboard
   ```

### Adicionar Novo Tenant

```bash
make add-tenant
# Ou editar manualmente:
kubectl edit configmap specialist-tenant-configs
```

### MÃ©tricas Prometheus

- `neural_hive_tenant_evaluations_total` - AvaliaÃ§Ãµes por tenant
- `neural_hive_tenant_confidence_score` - Confidence score por tenant
- `neural_hive_tenant_processing_time_seconds` - LatÃªncia por tenant
- `neural_hive_active_tenants_count` - NÃºmero de tenants ativos
- `envoy_ratelimit_over_limit` - Rate limit excedido por tenant

### ConfiguraÃ§Ã£o de Tenants

Estrutura do `tenant-configs.json`:

```json
{
  "tenant-enterprise-A": {
    "tenant_id": "tenant-enterprise-A",
    "tenant_name": "Enterprise Customer A",
    "is_active": true,
    "mlflow_model_name": "technical-tenant-a-model",
    "min_confidence_score": 0.85,
    "rate_limit_per_second": 500,
    "metadata": {
      "tier": "premium",
      "sla_level": "gold"
    }
  }
}
```

### Comandos Make

```bash
make deploy-envoy-gateway           # Deploy Envoy API Gateway
make migrate-ledger-tenant-id       # Migrar ledger para multi-tenancy
make test-multi-tenancy             # Executar testes de multi-tenancy
make view-envoy-stats               # Visualizar estatÃ­sticas do Envoy
make view-multi-tenancy-dashboard   # Abrir dashboard de multi-tenancy
make add-tenant                     # Adicionar novo tenant (interativo)
```

### Arquitetura de Isolamento

- **Ledger**: Campo `tenant_id` adicionado a todos os documentos + Ã­ndices compostos
- **Cache Redis**: Chaves prefixadas com tenant_id (`opinion:tenant-A:technical:1.0.0:hash`)
- **MÃ©tricas**: Label `tenant_id` em mÃ©tricas Prometheus (com cardinality limit de 100)
- **Modelos ML**: Modelos customizados por tenant no MLflow

### SeguranÃ§a

- JWT authentication obrigatÃ³ria no Envoy Gateway
- ExtraÃ§Ã£o de `tenant_id` do claim JWT
- ValidaÃ§Ã£o de tenant ativo antes de processar requisiÃ§Ã£o
- Rate limiting por tenant para prevenir abuso
- Isolamento lÃ³gico de dados no MongoDB

## ğŸ”„ Continuous Learning com Feedback Humano

O Neural Hive Mind implementa **continuous learning** atravÃ©s de feedback humano sobre opiniÃµes de especialistas, permitindo re-treinamento automÃ¡tico de modelos quando limiares de qualidade sÃ£o atingidos.

### Funcionalidades

- âœ… **API de Feedback**: Endpoint REST para revisores humanos submeterem feedback sobre opiniÃµes
- âœ… **ValidaÃ§Ã£o JWT**: AutenticaÃ§Ã£o com roles granulares (human_expert, reviewer, etc.)
- âœ… **PII Detection**: AnonimizaÃ§Ã£o automÃ¡tica de informaÃ§Ãµes pessoais em notas de feedback
- âœ… **Retraining Trigger**: Disparo automÃ¡tico de re-treinamento ao atingir threshold de feedback
- âœ… **MLflow Integration**: Pipeline de treinamento gerenciado via MLflow Projects
- âœ… **Async Monitoring**: Monitoramento automÃ¡tico de runs MLflow em background
- âœ… **Circuit Breaker**: ProteÃ§Ã£o contra falhas do MongoDB com pybreaker

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONTINUOUS LEARNING PIPELINE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ Human Feedback (POST /api/v1/feedback)                      â”‚
â”‚   â”œâ”€ JWT Authentication & Role Validation                       â”‚
â”‚   â”œâ”€ PII Detection & Anonymization (Presidio)                   â”‚
â”‚   â”œâ”€ Circuit Breaker (MongoDB)                                  â”‚
â”‚   â””â”€ Persist to feedback collection                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”„ Retraining Trigger (CronJob 1h)                             â”‚
â”‚   â”œâ”€ Count feedback by specialist_type + window                 â”‚
â”‚   â”œâ”€ Check threshold (default: 100 feedbacks)                   â”‚
â”‚   â”œâ”€ Trigger MLflow run (async)                                 â”‚
â”‚   â””â”€ Record trigger in retraining_triggers collection           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ” MLflow Run Monitor (CronJob 5min)                           â”‚
â”‚   â”œâ”€ Find triggers with status='running'                        â”‚
â”‚   â”œâ”€ Check MLflow run status (FINISHED/FAILED/RUNNING)          â”‚
â”‚   â”œâ”€ Extract metrics (precision, recall, f1)                    â”‚
â”‚   â””â”€ Update trigger status + duration                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š Prometheus Metrics                                          â”‚
â”‚   â”œâ”€ neural_hive_feedback_submissions_total                     â”‚
â”‚   â”œâ”€ neural_hive_feedback_rating (histogram)                    â”‚
â”‚   â”œâ”€ neural_hive_retraining_triggers_total                      â”‚
â”‚   â”œâ”€ neural_hive_retraining_run_duration_seconds                â”‚
â”‚   â””â”€ neural_hive_pii_entities_detected_total                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Start

1. **Submeter feedback manualmente:**
   ```bash
   make submit-feedback \
     OPINION_ID=opinion-abc123 \
     RATING=0.9 \
     RECOMMENDATION=approve \
     NOTES="AnÃ¡lise tÃ©cnica correta"
   ```

2. **Verificar threshold de re-treinamento:**
   ```bash
   make check-retraining-trigger
   ```

3. **Disparar re-treinamento manual:**
   ```bash
   make trigger-retraining SPECIALIST_TYPE=technical
   ```

4. **Treinar modelo via MLflow:**
   ```bash
   make train-model SPECIALIST_TYPE=technical
   ```

5. **Monitorar runs MLflow:**
   ```bash
   make monitor-retraining-runs
   ```

6. **Visualizar dashboard:**
   ```bash
   make view-continuous-learning
   ```

### API de Feedback

**POST /api/v1/feedback**

```bash
curl -X POST http://specialist-technical:8000/api/v1/feedback \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{
    "opinion_id": "opinion-abc123",
    "human_rating": 0.9,
    "human_recommendation": "approve",
    "feedback_notes": "OpiniÃ£o tÃ©cnica correta e bem fundamentada"
  }'
```

**GET /api/v1/feedback/opinion/{opinion_id}**

Retorna todos os feedbacks submetidos para uma opiniÃ£o especÃ­fica.

**GET /api/v1/feedback/stats?specialist_type=technical&window_days=30**

Retorna estatÃ­sticas agregadas de feedback (rating mÃ©dio, distribuiÃ§Ã£o de recomendaÃ§Ãµes).

### ConfiguraÃ§Ã£o

VariÃ¡veis de ambiente:

```bash
# Feedback Collection
ENABLE_FEEDBACK_COLLECTION=true
FEEDBACK_REQUIRE_AUTHENTICATION=true
JWT_SECRET_KEY=your-secret-key
FEEDBACK_ALLOWED_ROLES=human_expert,reviewer,admin

# PII Detection
PII_DETECTOR_ENABLED=true
PII_ANONYMIZATION_STRATEGY=redact

# Retraining Trigger
ENABLE_RETRAINING_TRIGGER=true
RETRAINING_THRESHOLD_COUNT=100
RETRAINING_FEEDBACK_WINDOW_DAYS=30
MLFLOW_TRACKING_URI=http://mlflow:5000
RETRAINING_MLFLOW_PROJECT_URI=./mlflow_projects/specialist_retraining
```

### Dashboards e Alertas

- **Dashboard Grafana**: `monitoring/dashboards/continuous-learning-dashboard.json`
- **Alertas Prometheus**: `monitoring/alerts/continuous-learning-alerts.yaml`

Alertas configurados:
- `LowFeedbackSubmissionRate`: Taxa de submissÃµes abaixo de 1/hora por 2h
- `LowAverageFeedbackRating`: Rating mÃ©dio < 0.5 por 1h
- `RetrainingTriggerFailed`: Falha em trigger de re-treinamento
- `MLflowRunStuckRunning`: Run MLflow rodando hÃ¡ mais de 1h
- `FeedbackAPIHighErrorRate`: Taxa de erro da API > 10%
- `HighPIIDetectionErrorRate`: Erros de PII detection > 5%

### Comandos Make

```bash
# Feedback
make submit-feedback              # Submeter feedback via API
make test-feedback                # Executar testes de feedback

# Retraining
make check-retraining-trigger     # Verificar threshold (dry-run)
make trigger-retraining           # Disparar re-treinamento manual
make train-model                  # Treinar modelo via MLflow
make monitor-retraining-runs      # Monitorar runs MLflow

# Deploy
make deploy-retraining-cronjob    # Deploy CronJob de re-treinamento

# Observabilidade
make view-continuous-learning     # Abrir dashboard Grafana
```

### MÃ©tricas Prometheus

**Feedback:**
- `neural_hive_feedback_submissions_total{specialist_type, submitted_by_role}`
- `neural_hive_feedback_rating{specialist_type}` (histogram)
- `neural_hive_feedback_recommendation_total{recommendation}`
- `neural_hive_feedback_count{specialist_type}` (gauge)
- `neural_hive_feedback_avg_rating{specialist_type}` (gauge)
- `neural_hive_feedback_api_errors_total{error_type}`

**Retraining:**
- `neural_hive_retraining_threshold_checks_total{specialist_type, threshold_met}`
- `neural_hive_retraining_triggers_total{specialist_type, status}`
- `neural_hive_retraining_run_duration_seconds{specialist_type}` (histogram)
- `neural_hive_retraining_last_trigger_timestamp_seconds{specialist_type, status}` (gauge)

**Compliance (PII):**
- `neural_hive_pii_entities_detected_total{entity_type}`
- `neural_hive_pii_anonymization_total{strategy}`
- `neural_hive_pii_detection_errors_total{error_type}`

### DocumentaÃ§Ã£o Adicional

Para detalhes completos sobre arquitetura, configuraÃ§Ã£o, troubleshooting e monitoramento:

ğŸ“– **[Continuous Learning Guide](docs/CONTINUOUS_LEARNING_GUIDE.md)**

## ğŸ“Š Business Metrics & Anomaly Detection

O Neural Hive Mind rastreia **mÃ©tricas de impacto de negÃ³cio** que correlacionam opiniÃµes de especialistas com decisÃµes finais do consenso:

### MÃ©tricas DisponÃ­veis

- **ConcordÃ¢ncia com Consenso**: Taxa de vezes que especialista concordou com decisÃ£o final
- **False Positive Rate**: Taxa de aprovaÃ§Ãµes incorretas (especialista aprovou mas consenso rejeitou)
- **False Negative Rate**: Taxa de rejeiÃ§Ãµes incorretas (especialista rejeitou mas consenso aprovou)
- **Precision/Recall/F1**: MÃ©tricas de qualidade pÃ³s-consenso
- **Valor de NegÃ³cio**: Planos aprovados que foram executados com sucesso

### Anomaly Detection

DetecÃ§Ã£o automÃ¡tica de comportamentos anÃ´malos usando **Isolation Forest**:
- Treinado em mÃ©tricas histÃ³ricas (30 dias)
- Detecta desvios significativos em tempo real
- Gera alertas inteligentes no Alertmanager

### Quick Start

1. **Configurar variÃ¡veis de ambiente:**
   ```bash
   export ENABLE_BUSINESS_METRICS=true
   export CONSENSUS_MONGODB_URI=mongodb://consensus-engine:27017
   ```

2. **Deploy CronJob:**
   ```bash
   make deploy-business-metrics-cronjob
   ```

3. **Treinar modelo de anomaly detection:**
   ```bash
   make anomaly-detector-train
   ```

4. **Visualizar mÃ©tricas:**
   ```bash
   make view-business-metrics
   ```

### Dashboards

- **Grafana**: `monitoring/dashboards/business-metrics-dashboard.json`
- **MÃ©tricas Prometheus**: `neural_hive_business_*`

### Scripts UtilitÃ¡rios

```bash
# Executar coleta de business metrics manualmente
make business-metrics-collect

# Modo dry-run (sem atualizar mÃ©tricas)
make business-metrics-collect-dry-run

# Treinar modelo de anomaly detection
make anomaly-detector-train

# Executar testes de business metrics
make test-business-metrics
```

### MÃ©tricas Prometheus

MÃ©tricas de business disponÃ­veis:

- `neural_hive_business_consensus_agreement_rate` - Taxa de concordÃ¢ncia com consenso
- `neural_hive_business_false_positive_rate` - Taxa de falsos positivos
- `neural_hive_business_false_negative_rate` - Taxa de falsos negativos
- `neural_hive_business_precision_score` - Precision pÃ³s-consenso
- `neural_hive_business_recall_score` - Recall pÃ³s-consenso
- `neural_hive_business_f1_score` - F1-score pÃ³s-consenso
- `neural_hive_business_value_generated_total` - Valor de negÃ³cio gerado
- `neural_hive_anomaly_detected_total` - Anomalias detectadas em mÃ©tricas

### Alertas Configurados

- `LowConsensusAgreementRate` - Agreement < 70%
- `HighFalsePositiveRate` - FP > 20%
- `LowPrecisionScore` - Precision < 0.7
- `MetricsAnomalyDetected` - Anomalia detectada pelo Isolation Forest

### Arquitetura

```mermaid
sequenceDiagram
    participant S as Specialists
    participant L as Ledger (MongoDB)
    participant CE as Consensus Engine
    participant BMC as BusinessMetricsCollector
    participant AD as AnomalyDetector
    participant P as Prometheus
    participant AM as Alertmanager

    S->>L: save_opinion(opinion)
    S->>CE: Enviar opiniÃµes
    CE->>CE: process_consensus()
    CE->>L: save_decision(decision)

    BMC->>L: fetch_opinions(24h)
    BMC->>CE: fetch_consensus_decisions(24h)
    BMC->>BMC: correlate_via_opinion_id()
    BMC->>BMC: calculate_metrics()

    BMC->>AD: detect_anomalies(metrics)
    AD-->>BMC: is_anomaly, severity

    BMC->>P: update_business_metrics()
    P->>AM: Avaliar regras de alerta
    AM->>AM: Disparar alertas
```

### DocumentaÃ§Ã£o Adicional

- [BusinessMetricsCollector](libraries/python/neural_hive_specialists/observability/business_metrics_collector.py)
- [AnomalyDetector](libraries/python/neural_hive_specialists/observability/anomaly_detector.py)
- [Scripts](libraries/python/neural_hive_specialists/scripts/)
- [CronJob Kubernetes](k8s/cronjobs/business-metrics-collector-job.yaml)
- [Alertas](monitoring/alerts/business-metrics-alerts.yaml)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

### PadrÃµes de Commit
```
feat: nova funcionalidade
fix: correÃ§Ã£o de bug
docs: atualizaÃ§Ã£o de documentaÃ§Ã£o
style: formataÃ§Ã£o de cÃ³digo
refactor: refatoraÃ§Ã£o sem mudanÃ§a de funcionalidade
test: adiÃ§Ã£o/correÃ§Ã£o de testes
chore: mudanÃ§as de build/CI
```

## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ”— Links Ãšteis

- **AWS EKS Documentation**: https://docs.aws.amazon.com/eks/
- **Istio Documentation**: https://istio.io/latest/docs/
- **OPA Gatekeeper**: https://open-policy-agent.github.io/gatekeeper/
- **Terraform AWS Provider**: https://registry.terraform.io/providers/hashicorp/aws/

---

ğŸ¤– **Neural Hive-Mind Phase 1 - Foundation Layer**
*Construindo a base para inteligÃªncia artificial distribuÃ­da*