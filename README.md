# Neural Hive-Mind - Fase 1: Funda√ß√£o

[![codecov](https://codecov.io/gh/albinoJimy/Neural-Hive-Mind/branch/main/graph/badge.svg)](https://codecov.io/gh/albinoJimy/Neural-Hive-Mind)
[![Tests](https://github.com/albinoJimy/Neural-Hive-Mind/actions/workflows/test-and-coverage.yml/badge.svg)](https://github.com/albinoJimy/Neural-Hive-Mind/actions/workflows/test-and-coverage.yml)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

üöÄ **Infraestrutura como C√≥digo para a base do organismo digital Neural Hive-Mind**

Este reposit√≥rio implementa a **Fase 1 - Funda√ß√£o** do Neural Hive-Mind, estabelecendo a infraestrutura essencial para suportar um sistema de IA distribu√≠do com arquitetura zero-trust, observabilidade nativa e governan√ßa audit√°vel.

## üìã Vis√£o Geral

A Fase 1 provisiona:

- **üèóÔ∏è Infraestrutura de Rede**: VPC multi-zona com subnets p√∫blicas/privadas
- **‚öôÔ∏è Cluster Kubernetes**: EKS gerenciado com auto-scaling e alta disponibilidade
- **üê≥ Container Registry**: ECR com scanning de vulnerabilidades e assinatura de imagens
- **üï∏Ô∏è Service Mesh**: Istio com mTLS STRICT obrigat√≥rio
- **üö¶ Policy Engine**: OPA Gatekeeper para governan√ßa policy-as-code
- **üìä Observabilidade**: Bases para m√©tricas, logs e tracing distribu√≠do

## üöÄ Quick Start com CLIs Unificados
O Neural Hive-Mind agora possui **6 CLIs unificados** que consolidam 178+ scripts em interfaces consistentes:

### Build
```bash
# Build local
./scripts/build.sh --target local

# Build e push para ECR
./scripts/build.sh --target ecr --push --version 1.0.8
```

### Deploy
```bash
# Deploy local (Minikube)
./scripts/deploy.sh --env local --phase 1

# Deploy EKS completo
./scripts/deploy.sh --env eks --phase all
```

### Testes
```bash
# Testes E2E
./tests/run-tests.sh --type e2e

# Testes com cobertura
./tests/run-tests.sh --type all --coverage
```

### Valida√ß√£o
```bash
# Validar tudo
./scripts/validate.sh --target all

# Validar specialists
./scripts/validate.sh --target specialists
```

### Seguran√ßa
```bash
# Inicializar Vault
./scripts/security.sh vault init

# Deploy SPIRE
./scripts/security.sh spire deploy
```

### Machine Learning
```bash
# Treinar modelos
./ml_pipelines/ml.sh train --all

# Promover modelo
./ml_pipelines/ml.sh promote --model technical-evaluator --version 3
```

### Makefile Simplificado
```bash
make build-local      # Build local
make deploy-eks       # Deploy EKS
make test             # Executar testes
make validate         # Validar deployment
make security-init    # Inicializar seguran√ßa
make ml-train         # Treinar modelos
```

üìö **Documenta√ß√£o Completa**: [docs/scripts/](docs/scripts/)
- [Vis√£o Geral da Estrutura](docs/scripts/README.md)
- [Guia de Migra√ß√£o](docs/scripts/MIGRATION_GUIDE.md)
- [Refer√™ncia de CLIs](docs/scripts/CLI_REFERENCE.md)
- [Exemplos](docs/scripts/EXAMPLES.md)

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    NEURAL HIVE-MIND FOUNDATION              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üèóÔ∏è  INFRASTRUCTURE LAYER                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Network (VPC, Subnets, NAT, Security Groups)          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Kubernetes Cluster (EKS + Node Groups)                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Container Registry (ECR + Vulnerability Scanning)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üîí  SECURITY & GOVERNANCE LAYER                           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Service Mesh (Istio + mTLS STRICT)                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Policy Engine (OPA Gatekeeper + Constraints)          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Network Policies (Zero Trust Segmentation)            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üì¶  APPLICATION NAMESPACES                                 ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ neural-hive-cognition     (Processamento Cognitivo)   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ neural-hive-orchestration (Coordena√ß√£o)               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ neural-hive-execution     (Agentes e Workers)         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ neural-hive-observability (M√©tricas e Logs)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure
```
Neural-Hive-Mind/
‚îú‚îÄ‚îÄ scripts/                    # üÜï CLIs unificados e m√≥dulos
‚îÇ   ‚îú‚îÄ‚îÄ build.sh               # CLI de build (consolida 15 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh              # CLI de deploy (consolida 38 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ validate.sh            # CLI de valida√ß√£o (consolida 75 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ security.sh            # CLI de seguran√ßa (consolida 23 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ lib/                   # üÜï Bibliotecas compartilhadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common.sh          # Logging, valida√ß√µes, retry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker.sh          # Opera√ß√µes Docker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ k8s.sh             # Opera√ß√µes Kubernetes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aws.sh             # Opera√ß√µes AWS
‚îÇ   ‚îú‚îÄ‚îÄ build/                 # M√≥dulos de build
‚îÇ   ‚îú‚îÄ‚îÄ deploy/                # M√≥dulos de deploy
‚îÇ   ‚îú‚îÄ‚îÄ validation/            # M√≥dulos de valida√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ security/              # M√≥dulos de seguran√ßa
‚îú‚îÄ‚îÄ tests/                     # üÜï Testes organizados
‚îÇ   ‚îú‚îÄ‚îÄ run-tests.sh           # CLI de testes (consolida 45 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ unit/                  # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ integration/           # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ e2e/                   # Testes end-to-end
‚îú‚îÄ‚îÄ ml_pipelines/              # üÜï ML operations
‚îÇ   ‚îú‚îÄ‚îÄ ml.sh                  # CLI de ML (consolida 25 scripts)
‚îÇ   ‚îú‚îÄ‚îÄ training/              # Scripts de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/            # Monitoramento de modelos
‚îú‚îÄ‚îÄ services/                  # Microservi√ßos
‚îú‚îÄ‚îÄ k8s/                       # Manifestos Kubernetes
‚îú‚îÄ‚îÄ helm-charts/               # Helm charts
‚îú‚îÄ‚îÄ infrastructure/            # Terraform
‚îî‚îÄ‚îÄ docs/                      # Documenta√ß√£o
    ‚îî‚îÄ‚îÄ scripts/               # üÜï Documenta√ß√£o de scripts
        ‚îú‚îÄ‚îÄ README.md          # Vis√£o geral
        ‚îú‚îÄ‚îÄ MIGRATION_GUIDE.md # Guia de migra√ß√£o
        ‚îú‚îÄ‚îÄ CLI_REFERENCE.md   # Refer√™ncia de CLIs
        ‚îî‚îÄ‚îÄ EXAMPLES.md        # Exemplos pr√°ticos
```
> **Nota**: A estrutura de scripts foi reorganizada em 11 fases, consolidando 178 scripts em 6 CLIs unificados. Veja [docs/scripts/MIGRATION_GUIDE.md](docs/scripts/MIGRATION_GUIDE.md) para migra√ß√£o.

## ü§ñ Machine Learning

O Neural Hive Mind utiliza modelos ML para avaliar planos cognitivos:

- **5 Especialistas**: Technical, Business, Behavior, Evolution, Architecture
- **Retreinamento Autom√°tico**: Semanal via CronJob Kubernetes
- **MLflow Integration**: Model Registry com stages (Production/Staging)
- **Feedback Loop**: Incorpora opini√µes humanas do MongoDB

üìö **Documenta√ß√£o**: [Guia de Modelos de Especialistas](docs/ml/SPECIALIST_MODELS_GUIDE.md)

## ü§ñ Modelos Preditivos

O Neural Hive-Mind utiliza Machine Learning para otimizar scheduling e detectar anomalias:

- **SchedulingPredictor** - Prediz dura√ß√£o e recursos de tickets (XGBoost)
- **LoadPredictor** - Prev√™ carga futura do sistema (Prophet)
- **AnomalyDetector** - Detecta tickets an√¥malos (Isolation Forest)

### Treinamento

Modelos s√£o treinados automaticamente toda semana (domingos 2 AM UTC) via CronJob Kubernetes.

Para treinar manualmente:

```bash
kubectl create job --from=cronjob/predictive-models-training \
  manual-training-$(date +%Y%m%d-%H%M%S) \
  -n neural-hive-ml
```

### Valida√ß√£o

```bash
# Validar modelos registrados no MLflow
./ml_pipelines/training/validate_model_promotion.sh

# Validar modelos carregados no Orchestrator
./scripts/validation/validate_orchestrator_ml.sh

# Executar testes E2E
./scripts/testing/run_ml_e2e_tests.sh
```

Veja [Guia de Modelos Preditivos](docs/ml/PREDICTIVE_MODELS_GUIDE.md) para detalhes.

## üöÄ Quick Start - Desenvolvimento Local

Inicie o Neural Hive-Mind em sua m√°quina usando Minikube:

### Pr√©-requisitos

- Docker (>= 24.0.0)
- Minikube (>= 1.32.0)
- kubectl (>= 1.28.0)
- Helm (>= 3.13.0)
- 4 CPU cores, 8GB RAM, 20GB disk space

### Build Paralelo de Imagens Docker

Para fazer build local de todas as imagens Docker com paraleliza√ß√£o:

```bash
# Build padr√£o (4 jobs paralelos, vers√£o 1.0.7)
./scripts/build.sh --target local --parallel 4

# Build com mais paraleliza√ß√£o (8 jobs)
./scripts/build.sh --target local --parallel 8

# Build de servi√ßos espec√≠ficos
./scripts/build.sh --target local --services "gateway-intencoes,consensus-engine"

# Build com vers√£o customizada
./scripts/build.sh --target local --version 1.0.8

# Build sem cache (for√ßa rebuild completo)
./scripts/build.sh --target local --no-cache
```

**Caracter√≠sticas:**
- ‚úÖ Build paralelo de 9 servi√ßos da Fase 1 (padr√£o: 4 simult√¢neos)
- ‚úÖ Tags duplas: `latest` + vers√£o espec√≠fica (ex: `1.0.7`)
- ‚úÖ Logs coloridos e barra de progresso
- ‚úÖ Logs individuais em `logs/build-<service>.log`
- ‚úÖ Resumo final com estat√≠sticas

**Requisitos:**
- Docker instalado e rodando
- M√≠nimo 10GB de espa√ßo em disco
- 4GB+ RAM recomendado para builds paralelos

### Push de Imagens para ECR

Ap√≥s buildar as imagens localmente, fa√ßa push para ECR:

```bash
# Push padr√£o (4 jobs paralelos)
./scripts/build.sh --target ecr --push

# Push com mais paraleliza√ß√£o
./scripts/build.sh --target ecr --push --parallel 8

# Push de servi√ßos espec√≠ficos
./scripts/build.sh --target ecr --push --services "gateway-intencoes,consensus-engine"

# Push com vers√£o customizada
./scripts/build.sh --target ecr --push --version 1.0.8

# Override de ambiente e regi√£o
./scripts/build.sh --target ecr --push --env staging --region us-west-2
```

**Pr√©-requisitos:**
- AWS CLI configurado (`aws configure`)
- Credenciais AWS v√°lidas
- Vari√°veis de ambiente em `~/.neural-hive-env` (ENV, AWS_REGION)
- Imagens buildadas localmente (executar `./scripts/build.sh --target local` ou `make build-local` primeiro)

**Features:**
- ‚úÖ Push paralelo (4 jobs simult√¢neos por padr√£o)
- ‚úÖ Retry autom√°tico (3 tentativas com backoff exponencial)
- ‚úÖ Cria√ß√£o autom√°tica de reposit√≥rios ECR
- ‚úÖ Valida√ß√£o de imagens locais antes do push
- ‚úÖ Push de ambas as tags (`latest` e vers√£o espec√≠fica)
- ‚úÖ Logs detalhados em `logs/push-*.log`
- ‚úÖ Barra de progresso e estat√≠sticas

**Verificar imagens no ECR:**
```bash
aws ecr list-images --repository-name neural-hive-dev/gateway-intencoes --region us-east-1
```

### Build e Deploy Automatizado para EKS

Para build local, push para ECR e atualiza√ß√£o de manifestos em um √∫nico fluxo usando os CLIs:

```bash
# Build + push para ECR
./scripts/build.sh --target ecr --push --version 1.0.8 --parallel 8

# Deploy completo em EKS
./scripts/deploy.sh --env eks --phase all --version 1.0.8
```

Use o deploy CLI para aplicar manifests com vers√£o/tag corretas; tags v√™m do `build.sh --version` e s√£o propagadas no deploy via `--version`.
- `--services <list>`: Lista de servi√ßos separados por v√≠rgula
- `--dry-run`: Preview das mudan√ßas sem aplicar
- `--no-backup`: N√£o criar backup antes de modificar
- `--help`: Exibir ajuda completa

**Fluxo completo usando CLIs (equivalente aos scripts legados):**
```bash
# Equiv. a build-local-parallel.sh
./scripts/build.sh --target local --parallel 4 --version 1.0.7

# Equiv. a push-to-ecr.sh
./scripts/build.sh --target ecr --push --version 1.0.7

# Equiv. a update-manifests-ecr.sh + deploy
./scripts/deploy.sh --env eks --phase all --version 1.0.7
```

Ver tamb√©m: `QUICK_START_EKS.md` para guia completo de deployment no EKS (atualizado para os CLIs).

## Gerenciamento de Depend√™ncias

### Estrutura de Requirements

Cada servi√ßo possui arquivos de depend√™ncias:

- **requirements.txt**: Depend√™ncias de produ√ß√£o (instaladas na imagem Docker). **FONTE DE VERDADE**.
- **requirements-dev.txt**: Depend√™ncias de desenvolvimento e testes (n√£o inclu√≠das em produ√ß√£o).
- **pyproject.toml** (opcional): Metadados do projeto e compatibilidade com Poetry. Deve ser mantido sincronizado com requirements.txt.

**Importante**: Em caso de conflito entre `pyproject.toml` e `requirements.txt`, o `requirements.txt` prevalece pois √© usado nos builds Docker de produ√ß√£o.

### Arquivo Central de Vers√µes

O arquivo `versions.txt` na raiz cont√©m vers√µes can√¥nicas de depend√™ncias compartilhadas. Consulte `docs/DEPENDENCY_MANAGEMENT.md` para detalhes.

### Consolida√ß√£o de Vers√µes

O projeto mant√©m vers√µes consolidadas de depend√™ncias cr√≠ticas para evitar conflitos:

| Depend√™ncia | Vers√£o Consolidada | Justificativa |
|-------------|-------------------|---------------|
| grpcio / grpcio-tools | >= 1.75.1 | Compatibilidade com protobuf 5.x |
| protobuf | >= 5.27.0 | Suporte a runtime_version (protoc 6.x) |
| fastapi | >= 0.104.1 | Vers√£o est√°vel com corre√ß√µes de seguran√ßa |
| pydantic | >= 2.5.2 | Valida√ß√£o de dados robusta |
| aiokafka | >= 0.10.0 | Melhorias de performance |

Ver [docs/DEPENDENCY_AUDIT.md](docs/DEPENDENCY_AUDIT.md) para matriz completa de vers√µes.

### Auditoria de Depend√™ncias

Auditoria manual:

```bash
# Auditoria completa com verifica√ß√£o de seguran√ßa
./scripts/audit-dependencies.sh --check-security

# Escanear imports n√£o utilizados
python scripts/scan-unused-imports.py --output reports/unused-imports.json

# Validar mudan√ßas antes de commit
./scripts/validate-dependency-changes.sh
```

Auditoria autom√°tica via GitHub Actions:
- Execu√ß√£o semanal (segundas-feiras).
- Execu√ß√£o em PRs que modificam `requirements*.txt`.
- Relat√≥rios dispon√≠veis como artifacts do workflow **Dependency Audit**.

### Adicionando Novas Depend√™ncias

1. **Produ√ß√£o**: Adicionar em `requirements.txt` com vers√£o m√≠nima (`>=X.Y.Z`).
2. **Desenvolvimento**: Adicionar em `requirements-dev.txt`.
3. **Valida√ß√£o**: Executar `./scripts/validate-dependency-changes.sh`.
4. **Documenta√ß√£o**: Depend√™ncias pesadas (>50MB) devem ser descritas em `docs/DEPENDENCY_AUDIT.md`.

### Depend√™ncias Cr√≠ticas

Consulte `docs/DEPENDENCY_AUDIT.md` (se√ß√£o *Depend√™ncias Cr√≠ticas e Justificativas*) para entender o motivo de cada pacote pesado permanecer na base.

### Setup Automatizado (Recomendado)

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd Neural-Hive-Mind

# Passo 1: Build das imagens Docker (recomendado antes do deploy)
# Equivalente ao script legado build-local-parallel.sh via CLI unificado
./scripts/build.sh --target local --parallel 4

# Passo 2: Execute o setup completo do cluster
make minikube-setup

# Passo 3: Valide a instala√ß√£o
make minikube-validate
```

O script de setup ir√°:
- ‚úÖ Iniciar Minikube com recursos apropriados
- ‚úÖ Habilitar addons necess√°rios (ingress, metrics-server, storage-provisioner)
- ‚úÖ Criar 9 namespaces para diferentes camadas do sistema
- ‚úÖ Configurar RBAC e network policies
- ‚úÖ Aplicar resource quotas e limits

### Setup Manual

Para instru√ß√µes passo-a-passo, consulte o [Guia de Setup do Minikube](docs/MINIKUBE_SETUP_GUIDE.md).

### Verificar Instala√ß√£o

```bash
# Verificar status do cluster
make minikube-status

# Visualizar namespaces
kubectl get namespaces | grep neural-hive

# Abrir dashboard do Kubernetes
make minikube-dashboard
```

### Pr√≥ximos Passos

Ap√≥s completar a Fase 1 (Bootstrap), prossiga para:

**Fase 2 - Deploy da Base de Infraestrutura:**
Deploy automatizado de componentes essenciais:
- ‚ò∏Ô∏è Kafka (Strimzi) - Sistema de mensageria distribu√≠do
- üíæ Redis - Cache em mem√≥ria
- üìÑ MongoDB - Banco de dados de documentos
- üï∏Ô∏è Neo4j - Banco de dados de grafos
- üìä ClickHouse - Banco de dados anal√≠tico
- üîê Keycloak - Autentica√ß√£o e autoriza√ß√£o

```bash
# Deploy automatizado de todos os componentes
./scripts/deploy/deploy-infrastructure-local.sh

# Validar instala√ß√£o
./scripts/validation/validate-infrastructure-local.sh
```

Veja o [Guia de Deploy Local](DEPLOYMENT_LOCAL.md#Ô∏è-fase-2-deploy-da-base-de-infraestrutura) para instru√ß√µes detalhadas da Fase 2

---

## üöÄ Quick Start - AWS Production (EKS)

Para deploy em produ√ß√£o na AWS usando Amazon EKS:

### Pr√©-requisitos

```bash
# Ferramentas necess√°rias
terraform >= 1.5
helm >= 3.13
kubectl >= 1.28
aws-cli >= 2.0
docker >= 24.0

# Credenciais AWS configuradas
aws configure
aws sts get-caller-identity
```

### Deploy R√°pido (Automatizado) ‚ö°

```bash
# 0. (Opcional) Build local das imagens antes do push para ECR (equivalente ao build-local-parallel.sh)
./scripts/build.sh --target local --parallel 4

# 1. Configure ambiente e senhas
export ENV=dev  # ou staging, prod
export AWS_REGION=us-east-1
export TF_VAR_mongodb_root_password="<senha-forte>"
export TF_VAR_neo4j_password="<senha-forte>"
export TF_VAR_clickhouse_admin_password="<senha-forte>"
export TF_VAR_clickhouse_readonly_password="<senha-forte>"
export TF_VAR_clickhouse_writer_password="<senha-forte>"

# 2. Deploy completo automatizado (20-30 min) - equivalente ao deploy-eks-complete.sh
./scripts/build.sh --target ecr --push --version ${ENV_VERSION:-latest}
./scripts/deploy.sh --env ${ENV:-dev} --phase all --version ${ENV_VERSION:-latest}

# 3. Validar deployment
kubectl get pods --all-namespaces
./tests/run-tests.sh --type e2e --phase 1
```

### Documenta√ß√£o Completa

- **[Quick Start EKS](QUICK_START_EKS.md)** - Deploy em 30 minutos
- **[Guia Completo EKS](DEPLOYMENT_EKS_GUIDE.md)** - Guia detalhado com troubleshooting
- **[Checklist EKS](EKS_DEPLOYMENT_CHECKLIST.md)** - Checklist completo de deployment
- **[Resource Tuning Guide](docs/RESOURCE_TUNING_GUIDE.md)** - Rightsizing, probes e topology spread 2.0 para especialistas/core

### Custos Estimados AWS

| Ambiente | Custo/m√™s | Descri√ß√£o |
|----------|-----------|-----------|
| **Dev** | ~$267 | 3x t3.medium, recursos m√≠nimos |
| **Staging** | ~$600 | 6x t3.large, HA moderado |
| **Prod** | ~$1,127 | 6x m5.large, HA completo |

*Custos podem ser reduzidos em at√© 70% usando Spot Instances para dev/staging*

---

## üìã Fases de Deploy

O deploy do Neural Hive-Mind est√° organizado em fases incrementais:

### Fase 1: Bootstrap (‚úÖ Voc√™ est√° aqui)
- Inicializar cluster Minikube
- Configurar namespaces, RBAC, network policies
- Aplicar resource quotas e limits
- **Guia**: [Guia de Setup do Minikube](docs/MINIKUBE_SETUP_GUIDE.md)

### Fase 2: Infraestrutura
- Deploy Kafka, Redis, MongoDB, Neo4j, ClickHouse
- Configurar Keycloak para autentica√ß√£o
- **Guia**: [Guia de Deploy Local](DEPLOYMENT_LOCAL.md)

### Fase 3: Servi√ßos Core
- Deploy Gateway, Semantic Translation Engine
- Deploy 5 Neural Specialists
- Deploy Consensus Engine e Memory Layer

### Fase 4: Orquestra√ß√£o & Execu√ß√£o
- Deploy Orchestrator Dynamic e Service Registry
- Deploy Execution Ticket Service e Worker Agents
- Deploy agentes de coordena√ß√£o (Queen, Scout, Analyst, Optimizer, Guard)

### Fase 5: Funcionalidades Avan√ßadas
- Deploy Code Forge, SLA Management, Self-Healing Engine
- Deploy MCP Tool Catalog
- Executar testes end-to-end

---

## üìÅ Estrutura do Projeto

```
Neural-Hive-Mind/
‚îú‚îÄ‚îÄ infrastructure/terraform/         # M√≥dulos Terraform IaC
‚îÇ   ‚îî‚îÄ‚îÄ modules/
‚îÇ       ‚îú‚îÄ‚îÄ network/                 # VPC e rede
‚îÇ       ‚îú‚îÄ‚îÄ k8s-cluster/             # Cluster EKS
‚îÇ       ‚îî‚îÄ‚îÄ container-registry/      # ECR registry
‚îú‚îÄ‚îÄ helm-charts/                     # Charts Helm customizados
‚îÇ   ‚îú‚îÄ‚îÄ istio-base/                  # Service mesh
‚îÇ   ‚îî‚îÄ‚îÄ opa-gatekeeper/              # Policy engine
‚îú‚îÄ‚îÄ policies/                        # Pol√≠ticas OPA/Rego
‚îÇ   ‚îú‚îÄ‚îÄ rego/                        # Pol√≠ticas em linguagem Rego
‚îÇ   ‚îú‚îÄ‚îÄ constraint-templates/        # Templates Gatekeeper
‚îÇ   ‚îî‚îÄ‚îÄ constraints/                 # Constraints ativos
‚îú‚îÄ‚îÄ k8s/bootstrap/                   # Manifests iniciais
‚îÇ   ‚îú‚îÄ‚îÄ namespaces.yaml             # Namespaces e quotas
‚îÇ   ‚îú‚îÄ‚îÄ rbac.yaml                   # Service accounts e roles
‚îÇ   ‚îî‚îÄ‚îÄ network-policies.yaml       # Pol√≠ticas de rede
‚îú‚îÄ‚îÄ scripts/                         # Scripts de automa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ deploy/                     # Scripts de deploy
‚îÇ   ‚îî‚îÄ‚îÄ validation/                 # Scripts de valida√ß√£o
‚îú‚îÄ‚îÄ environments/                    # Configura√ß√µes por ambiente
‚îÇ   ‚îú‚îÄ‚îÄ dev/                        # Desenvolvimento
‚îÇ   ‚îú‚îÄ‚îÄ staging/                    # Homologa√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ prod/                       # Produ√ß√£o
‚îú‚îÄ‚îÄ docs/adr/                       # Architecture Decision Records
‚îî‚îÄ‚îÄ .github/workflows/              # Pipelines CI/CD
```

## ‚öôÔ∏è Componentes Principais

### üèóÔ∏è Infraestrutura (Terraform)

- **Network**: VPC multi-zona, NAT Gateways, VPC Endpoints
- **K8s Cluster**: EKS com node groups auto-scaling
- **Registry**: ECR com lifecycle policies e scanning

### üîí Seguran√ßa (Istio + OPA)

- **mTLS**: Certificados SPIFFE autom√°ticos
- **Zero Trust**: Network policies granulares
- **Policies**: Validation de imagens, resources, compliance

### üì¶ Aplica√ß√£o (Namespaces)

- **Cognition**: Processamento e interpreta√ß√£o
- **Orchestration**: Coordena√ß√£o e workflow
- **Execution**: Agentes e workers
- **Observability**: M√©tricas, logs e tracing

### ü§ñ Estrat√©gia de Modelos ML

**Modelos Fora da Imagem Docker:**
- Modelos ML n√£o s√£o empacotados nas imagens Docker
- Init containers baixam modelos durante inicializa√ß√£o do pod
- Volumes persistentes (PVC) armazenam modelos compartilhados
- Lazy loading carrega modelos sob demanda em runtime

**Benef√≠cios:**
- **60% de redu√ß√£o** no tamanho das imagens Docker
- **86% de redu√ß√£o** no tempo de startup (lazy loading)
- **43% de redu√ß√£o** no consumo de mem√≥ria base
- Cache compartilhado entre pods (economia de armazenamento)

**Modelos Utilizados:**
- Whisper ASR: `tiny` (39MB) com fallback para `base` e `small`
- spaCy NLU: `pt_core_news_sm`, `en_core_web_sm`, `es_core_news_sm` (~15MB cada)

Ver [Guia de Otimiza√ß√£o de Depend√™ncias](docs/DEPENDENCY_OPTIMIZATION.md) para detalhes completos.

## üß† Motor de Tradu√ß√£o Sem√¢ntica (Fase 1)

O **Motor de Tradu√ß√£o Sem√¢ntica** implementa o **Fluxo B (Gera√ß√£o de Planos)** do Neural Hive-Mind, convertendo Intent Envelopes em Cognitive Plans execut√°veis com DAGs de tarefas, avalia√ß√£o de risco e explicabilidade.

### Componentes Implementados

- ‚úÖ **Semantic Parser**: Parsing sem√¢ntico com enriquecimento via Knowledge Graph (Neo4j)
- ‚úÖ **DAG Generator**: Gera√ß√£o de grafos ac√≠clicos de tarefas com valida√ß√£o topol√≥gica
- ‚úÖ **Risk Scorer**: Avalia√ß√£o de risco baseada em heur√≠sticas (prioridade, seguran√ßa, complexidade)
- ‚úÖ **Explainability Generator**: Gera√ß√£o de tokens e narrativas de explicabilidade
- ‚úÖ **Cognitive Ledger**: Registro imut√°vel de planos no MongoDB com hash SHA-256
- ‚úÖ **Kafka Consumer/Producer**: Consumo de intents e publica√ß√£o de planos com exactly-once semantics

### Fluxo de Processamento (B1-B6)

```
Intent Envelope (Kafka) ‚Üí B1:Receber ‚Üí B2:Enriquecer (Neo4j) ‚Üí
B3:DAG ‚Üí B4:Risk Score ‚Üí B5:Ledger ‚Üí B6:Publicar (plans.ready)
```

## üîÑ Integra√ß√£o Completa do Fluxo C (Fase 2)

A **Integra√ß√£o do Fluxo C** conecta todos os componentes da Fase 2 em um fluxo end-to-end que processa Consolidated Decisions desde a inten√ß√£o inicial at√© o deploy final, com telemetria correlacionada completa.

### Componentes Integrados

- ‚úÖ **Biblioteca neural_hive_integration v1.0.0**: 7 clients unificados para todos os servi√ßos da Fase 2
- ‚úÖ **FlowCOrchestrator**: Coordena√ß√£o completa do fluxo C1-C6 (Valida√ß√£o ‚Üí Tickets ‚Üí Workers ‚Üí Deploy ‚Üí Telemetria)
- ‚úÖ **FlowCConsumer**: Consumer Kafka integrado no Orchestrator Dynamic para t√≥pico `plans.consensus`
- ‚úÖ **Telemetry Publisher**: Correla√ß√£o de eventos com OpenTelemetry (trace_id, span_id, correlation_id)
- ‚úÖ **T√≥pico telemetry.flow-c**: Kafka topic dedicado para eventos de integra√ß√£o

### Fluxo Completo C1-C6

```
Consolidated Decision ‚Üí C1:Validar ‚Üí C2:Gerar Tickets ‚Üí C3:Descobrir Workers ‚Üí
C4:Atribuir Tarefas ‚Üí C5:Monitorar Execu√ß√£o ‚Üí C6:Publicar Telemetria
```

### Deploy R√°pido

```bash
# Deploy da integra√ß√£o Fase 2
./scripts/deploy/deploy-phase2-integration.sh

# Validar componentes
./scripts/validation/validate-phase2-integration.sh

# Teste end-to-end completo
./tests/phase2-flow-c-integration-test.sh
```

### M√©tricas de Sucesso

| M√©trica | SLO | Atual |
|---------|-----|-------|
| Lat√™ncia End-to-End (P95) | < 4 horas | - |
| Taxa de Sucesso | > 99% | - |
| Aprova√ß√£o Autom√°tica | > 80% | - |
| Disponibilidade Workers | > 95% | - |

### Documenta√ß√£o Completa

üìñ **[Guia de Integra√ß√£o do Fluxo C](docs/PHASE2_FLOW_C_INTEGRATION.md)**
- Arquitetura detalhada com diagramas Mermaid
- Exemplos de c√≥digo para todos os clients
- Observabilidade (m√©tricas Prometheus, dashboard Grafana, tracing Jaeger)
- Troubleshooting e runbooks
- SLAs e error budgets

üîí **[Guia da Camada de Compliance](docs/COMPLIANCE_LAYER_GUIDE.md)**
- Detec√ß√£o e anonimiza√ß√£o de PII com Microsoft Presidio
- Criptografia de campos sens√≠veis (Fernet AES-128)
- Audit logging e pol√≠ticas de reten√ß√£o
- Conformidade com LGPD e GDPR
- M√©tricas Prometheus e troubleshooting

---

## üß† Motor de Tradu√ß√£o Sem√¢ntica (Fase 1)

O **Motor de Tradu√ß√£o Sem√¢ntica** implementa o **Fluxo B (Gera√ß√£o de Planos)** do Neural Hive-Mind, convertendo Intent Envelopes em Cognitive Plans execut√°veis com DAGs de tarefas, avalia√ß√£o de risco e explicabilidade.

### Componentes Implementados

- ‚úÖ **Semantic Parser**: Parsing sem√¢ntico com enriquecimento via Knowledge Graph (Neo4j)
- ‚úÖ **DAG Generator**: Gera√ß√£o de grafos ac√≠clicos de tarefas com valida√ß√£o topol√≥gica
- ‚úÖ **Risk Scorer**: Avalia√ß√£o de risco baseada em heur√≠sticas (prioridade, seguran√ßa, complexidade)
- ‚úÖ **Explainability Generator**: Gera√ß√£o de tokens e narrativas de explicabilidade
- ‚úÖ **Cognitive Ledger**: Registro imut√°vel de planos no MongoDB com hash SHA-256
- ‚úÖ **Kafka Consumer/Producer**: Consumo de intents e publica√ß√£o de planos com exactly-once semantics

### Fluxo de Processamento (B1-B6)

```
Intent Envelope (Kafka) ‚Üí B1:Receber ‚Üí B2:Enriquecer (Neo4j) ‚Üí
B3:DAG ‚Üí B4:Risk Score ‚Üí B5:Ledger ‚Üí B6:Publicar (plans.ready)
```

1. **B1: Receber**: Consumir Intent Envelope do Kafka com valida√ß√£o de assinatura
2. **B2: Enriquecer**: Consultar Knowledge Graph (Neo4j) para contexto hist√≥rico e ontologias
3. **B3: Decompor**: Gerar DAG de tarefas com valida√ß√£o de aciclicidade
4. **B4: Avaliar**: Calcular risk score (prioridade=0.3 + seguran√ßa=0.4 + complexidade=0.3)
5. **B5: Versionar**: Registrar plano no ledger imut√°vel (MongoDB)
6. **B6: Publicar**: Enviar Cognitive Plan para t√≥pico `plans.ready`

### Deploy

```bash
# Deploy completo
export ENV=dev
export NEO4J_PASSWORD=secret
export MONGODB_PASSWORD=secret
./scripts/deploy/deploy-semantic-translation-engine.sh

# Validar deployment
./scripts/validation/validate-semantic-translation-engine.sh
```

### Acesso e Monitoramento

```bash
# Logs em tempo real
kubectl logs -f -n semantic-translation-engine \
  -l app.kubernetes.io/name=semantic-translation-engine

# M√©tricas Prometheus
kubectl port-forward -n semantic-translation-engine \
  svc/semantic-translation-engine 8080:8080
curl http://localhost:8080/metrics

# Verificar consumer lag
kafka-consumer-groups.sh --bootstrap-server <kafka> \
  --group semantic-translation-engine --describe
```

### Dashboards e Observabilidade

- **Grafana Dashboard**: Lat√™ncia B1‚ÜíB6, DAG complexity, risk distribution
- **Jaeger Traces**: Correla√ß√£o intent_id ‚Üí plan_id ‚Üí trace_id
- **Prometheus Metrics**:
  - `neural_hive_geracao_duration_seconds` - Lat√™ncia de gera√ß√£o (SLO <400ms)
  - `neural_hive_dag_complexity` - Distribui√ß√£o de complexidade
  - `neural_hive_risk_score` - Scores de risco por dom√≠nio
  - `neural_hive_kg_query_duration_seconds` - Lat√™ncia Neo4j (SLO <50ms)

### Documenta√ß√£o

- [Opera√ß√µes do Motor](docs/operations/semantic-translation-engine-operations.md)
- [Documento 06 - Fluxo B](documento-06-fluxos-processos-neural-hive-mind.md)
- [Schema Cognitive Plan](schemas/cognitive-plan/cognitive-plan.avsc)

## üîß Configura√ß√£o por Ambiente

### Development
```bash
# Recursos m√≠nimos para desenvolvimento
cluster_name = "neural-hive-dev"
node_instance_types = ["t3.medium", "t3.large"]
min_nodes_per_zone = 1
enable_vulnerability_scanning = true
block_critical_vulnerabilities = false
```

### Production
```bash
# Configura√ß√£o otimizada para produ√ß√£o
cluster_name = "neural-hive-prod"
node_instance_types = ["m5.large", "m5.xlarge", "c5.large"]
min_nodes_per_zone = 2
enable_vulnerability_scanning = true
block_critical_vulnerabilities = true
```

## üß™ Valida√ß√£o e Testes

### Valida√ß√£o de Infraestrutura
```bash
# Terraform validation
./scripts/validation/validate-terraform.sh

# Cluster health check
./scripts/validation/validate-cluster-health.sh

# mTLS connectivity test
./scripts/validation/test-mtls-connectivity.sh

# Autoscaler test
./scripts/validation/test-autoscaler.sh
```

### E2E Validation Suite

The project includes a comprehensive E2E validation suite for validating the complete flow from Gateway to Specialists:

#### Quick E2E Test (Single Execution)
```bash
# Test basic E2E flow with 5 scenarios
python3 test-fluxo-completo-e2e.py
```

#### Comprehensive E2E Validation (10 Iterations)
```bash
# Run complete validation suite with 10 consecutive iterations
./scripts/validation/run-e2e-validation-suite.sh

# Run with custom number of iterations
./scripts/validation/run-e2e-validation-suite.sh --iterations 20

# Run only tests (without log monitoring)
./scripts/validation/run-e2e-validation-suite.sh --tests-only

# Run only log monitoring (without tests)
./scripts/validation/run-e2e-validation-suite.sh --monitoring-only --duration 300
```

#### Validation Components

The E2E validation suite consists of:

1. **Extended E2E Test** (`test-e2e-validation-complete.py`):
   - 10 consecutive iterations
   - 5 scenarios per iteration (one per specialist)
   - Total: 50 tests executed
   - Specific timestamp validation in each response
   - Detailed metrics collection (latency, success rate)

2. **Real-time Log Monitoring** (`monitor-e2e-logs.sh`):
   - Monitors consensus-engine + 5 specialists
   - Filters: TypeError, evaluated_at, timestamp, EvaluatePlan
   - Automatic alerts for TypeErrors
   - Live statistics display

3. **Integrated Orchestration** (`run-e2e-validation-suite.sh`):
   - Simultaneous execution of tests + monitoring
   - Synchronized start/end
   - Result correlation

4. **Final Report Generation** (`generate-e2e-validation-report.py`):
   - Consolidated analysis of results
   - Aggregated statistics
   - Evidence-based recommendations

#### Validation Criteria

The validation suite checks:
- ‚úì Success rate >= 95%
- ‚úì No TypeErrors detected
- ‚úì All timestamps valid (ISO 8601 format)
- ‚úì Chronological consistency
- ‚úì Performance within expected range (<1s average latency)
- ‚úì 10 consecutive iterations without critical failures

#### Results

Validation results are saved to `/tmp/e2e-validation-suite-{timestamp}/` including:
- **Test Results:** JSON metrics, execution logs
- **Captured Logs:** Kubernetes logs from all components
- **Final Report:** Comprehensive Markdown report with analysis and recommendations

#### Interpreting Results

**‚úÖ VALIDATION PASSED:**
- Success rate >= 95%
- No TypeErrors detected
- All timestamps valid
- System is stable and ready for production

**‚ö†Ô∏è VALIDATION PASSED WITH WARNINGS:**
- Success rate >= 90%
- No TypeErrors detected
- Some non-critical failures
- Review failures before production deployment

**‚ùå VALIDATION FAILED:**
- Success rate < 90% OR TypeErrors detected
- Critical issues detected
- Do NOT deploy to production
- Review detailed logs and fix issues

#### Related Documentation

- [ANALISE_DEBUG_GRPC_TYPEERROR.md](ANALISE_DEBUG_GRPC_TYPEERROR.md) - TypeError analysis and resolution
- [PROTOBUF_VERSION_ANALYSIS.md](PROTOBUF_VERSION_ANALYSIS.md) - Protobuf version compatibility analysis
- [VALIDATION_CHECKLIST_PROTOBUF_FIX.md](VALIDATION_CHECKLIST_PROTOBUF_FIX.md) - Post-deployment validation checklist

### CI/CD Pipelines

- **Validation Pipeline**: Terraform, Helm, OPA policies
- **Deployment Pipeline**: GitOps com aprova√ß√µes autom√°ticas
- **Integration Tests**: Valida√ß√£o em cluster Kind

## üìä Observabilidade

### M√©tricas Coletadas
- **Cluster**: Nodes, pods, resources
- **Service Mesh**: mTLS, lat√™ncia, throughput
- **Policies**: Viola√ß√µes, compliance
- **Applications**: M√©tricas customizadas

### Dashboards
- **Infrastructure**: Utiliza√ß√£o de recursos
- **Security**: Status mTLS, viola√ß√µes
- **Performance**: Lat√™ncia, errors, throughput

## üîÑ Disaster Recovery

Sistema de backup e recupera√ß√£o autom√°tica para garantir continuidade de opera√ß√£o dos especialistas neurais.

### Funcionalidades

- ‚úÖ **Backups Autom√°ticos**: CronJob di√°rio √†s 2h UTC de todos os componentes cr√≠ticos
- ‚úÖ **M√∫ltiplos Storage**: Suporte para S3, Google Cloud Storage e filesystem local
- ‚úÖ **Componentes Backed Up**: Modelos MLflow, Ledger cognitivo, Feature Store, Cache, M√©tricas
- ‚úÖ **Reten√ß√£o Configur√°vel**: 90 dias por padr√£o com cleanup autom√°tico
- ‚úÖ **Testes de Recovery**: Valida√ß√£o semanal autom√°tica de backups
- ‚úÖ **Restore Granular**: Restaura√ß√£o completa ou por componente individual
- ‚úÖ **Multi-Tenancy**: Backups isolados por tenant
- ‚úÖ **Observabilidade**: M√©tricas, alertas e dashboard dedicados

### Quick Start

```bash
# Configurar vari√°veis de ambiente (S3 exemplo)
export ENABLE_DISASTER_RECOVERY=true
export BACKUP_STORAGE_PROVIDER=s3
export BACKUP_S3_BUCKET=neural-hive-backups
export BACKUP_S3_REGION=us-west-2
export BACKUP_RETENTION_DAYS=90

# Backup manual de um especialista
make dr-backup SPECIALIST_TYPE=business

# Listar backups dispon√≠veis
make dr-list-backups SPECIALIST_TYPE=business

# Restaurar √∫ltimo backup
make dr-restore SPECIALIST_TYPE=business

# Testar recovery (n√£o afeta produ√ß√£o)
make dr-test-recovery SPECIALIST_TYPE=business
```

### Targets Make Dispon√≠veis

```bash
make dr-backup              # Backup manual de todos os especialistas
make dr-restore             # Restore interativo
make dr-list-backups        # Lista backups dispon√≠veis
make dr-test-recovery       # Testa restore sem afetar produ√ß√£o
make deploy-dr-cronjobs     # Deploy dos CronJobs de backup e teste
```

### Vari√°veis de Ambiente

**Essenciais:**
- `ENABLE_DISASTER_RECOVERY`: Habilitar DR (default: false)
- `BACKUP_STORAGE_PROVIDER`: s3, gcs ou local
- `BACKUP_S3_BUCKET`: Bucket S3 (se provider=s3)
- `BACKUP_GCS_BUCKET`: Bucket GCS (se provider=gcs)
- `BACKUP_GCS_PROJECT`: Projeto GCP (se provider=gcs)

**Opcionais:**
- `BACKUP_RETENTION_DAYS`: Dias de reten√ß√£o (default: 90)
- `BACKUP_SCHEDULE_CRON`: Schedule de backup (default: "0 2 * * *")
- `RECOVERY_TEST_SCHEDULE_CRON`: Schedule de teste (default: "0 4 * * 0")
- `BACKUP_INCLUDE_CACHE`: Incluir cache Redis (default: false)
- `BACKUP_COMPRESSION_LEVEL`: N√≠vel gzip 1-9 (default: 6)

### Monitoramento

**Dashboard Grafana:**
- Status de √∫ltimo backup e teste de recovery
- Trends de tamanho e dura√ß√£o de backups
- Breakdown por componente (model, ledger, feature store, cache, metrics)
- Erros de storage (upload/download)
- Alertas ativos de DR

**Alertas Configurados:**
- üî¥ `BackupFailed`: Backup falhou
- üü° `BackupNotRunRecently`: >25h sem backup
- üî¥ `RecoveryTestFailed`: Teste de recovery falhou
- üü° `StorageUploadErrors`: Erros persistentes de upload
- üü° `BackupDurationAnomaly`: Dura√ß√£o anormal de backup
- üü° `BackupSizeAnomaly`: Tamanho anormal de backup

### Documenta√ß√£o Operacional

- üìñ [Runbook de Disaster Recovery](docs/operations/DISASTER_RECOVERY_RUNBOOK.md) - Procedimentos operacionais completos
- üö® [Playbook de Incidentes](docs/operations/DISASTER_RECOVERY_PLAYBOOK.md) - Guia step-by-step para emerg√™ncias
- üìä [Dashboard Grafana](monitoring/dashboards/disaster-recovery-dashboard.json) - Dashboard de monitoramento
- üîî [Regras de Alerta](monitoring/alerts/disaster-recovery-alerts.yaml) - Alertas Prometheus

### Arquitetura de Backup

Cada backup cont√©m:
- **model/**: Artifacts e metadata do modelo MLflow
- **ledger/**: Dump BSON do ledger cognitivo (MongoDB)
- **feature_store/**: Features extra√≠das em JSON
- **cache/**: Snapshot do cache Redis (opcional)
- **metrics/**: Resumo de m√©tricas Prometheus
- **config/**: Configura√ß√£o do especialista
- **manifest.json**: Metadados do backup (timestamp, vers√£o, checksums)

### Restore

**Restore Completo:**
```bash
# √öltima vers√£o
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business

# Vers√£o espec√≠fica
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --backup-id specialist-business-backup-20250211-143000 \
  --specialist-type business
```

**Restore Parcial (por componente):**
```bash
# Apenas modelo MLflow
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business --components model

# M√∫ltiplos componentes
python -m neural_hive_specialists.scripts.run_disaster_recovery_restore \
  --latest --specialist-type business --components model,ledger,feature_store
```

### RPO e RTO

- **RPO (Recovery Point Objective)**: 24 horas (backups di√°rios)
- **RTO (Recovery Time Objective)**:
  - Restore completo: 30-60 minutos
  - Restore parcial (modelo): 15-30 minutos
  - Rollback emergencial: 10-15 minutos

## Especialistas Neurais (Fase 1)

Os **5 Especialistas Neurais** implementam avalia√ß√£o multi-dom√≠nio de planos cognitivos com consenso audit√°vel.

### Componentes
- ‚úÖ **Business Specialist**: an√°lise de workflows, KPIs, custos
- ‚úÖ **Technical Specialist**: qualidade de c√≥digo, performance, seguran√ßa
- ‚úÖ **Behavior Specialist**: jornadas de usu√°rio, an√°lise de sentimento
- ‚úÖ **Evolution Specialist**: oportunidades de melhoria, hip√≥teses
- ‚úÖ **Architecture Specialist**: depend√™ncias, escalabilidade, padr√µes

### Caracter√≠sticas
- Contrato gRPC padronizado
- Registro din√¢mico e health checks
- Integra√ß√£o com MLflow para versionamento de modelos
- Explicabilidade estruturada (SHAP/LIME)
- Persist√™ncia no ledger cognitivo (MongoDB)
- Observabilidade completa (OpenTelemetry)

### Deploy
```bash
# Deploy completo dos especialistas
export ENV=dev
export MLFLOW_TRACKING_URI=http://mlflow:5000
export MONGODB_URI=mongodb://mongodb:27017
export NEO4J_PASSWORD=secret
./scripts/deploy/deploy-specialists.sh

# Validar deployment
./scripts/validation/validate-specialists.sh
```

### Acesso
```bash
# Logs de um especialista
kubectl logs -f -n specialist-business -l app.kubernetes.io/name=specialist-business

# M√©tricas
kubectl port-forward -n specialist-business svc/specialist-business 8080:8080
curl http://localhost:8080/metrics

# MLflow UI
kubectl port-forward -n mlflow svc/mlflow 5000:5000
open http://localhost:5000
```

### Dashboards
- Specialists Cognitive Layer: http://grafana/d/specialists-cognitive-layer
- Fluxo B - Gera√ß√£o de Planos: http://grafana/d/fluxo-b-geracao-planos

### Documenta√ß√£o
- [Opera√ß√µes dos Especialistas](docs/operations/specialists-operations.md)
- [Camada Cognitiva](docs/observability/services/agentes/camada-cognitiva.md)
- [Cat√°logo de Agentes](docs/observability/services/agentes.md)
- [Arquitetura gRPC dos Especialistas](docs/GRPC_SPECIALISTS_ARCHITECTURE.md)

## Mecanismo de Consenso Multi-Agente (Fase 1)

O **Mecanismo de Consenso** implementa agrega√ß√£o audit√°vel de pareceres dos 5 especialistas neurais com Bayesian Model Averaging, voting ensemble e ferom√¥nios digitais.

### Componentes
- ‚úÖ **Bayesian Aggregator**: combina distribui√ß√µes de probabilidade dos especialistas
- ‚úÖ **Voting Ensemble**: agrega√ß√£o ponderada com pesos din√¢micos
- ‚úÖ **Ferom√¥nios Digitais**: protocolo de sinaliza√ß√£o para coordena√ß√£o de enxame
- ‚úÖ **Compliance Fallback**: regras determin√≠sticas para guardrails √©ticos
- ‚úÖ **Explainability Consolidator**: gera√ß√£o de explica√ß√µes consolidadas
- ‚úÖ **Ledger de Decis√µes**: registro imut√°vel no MongoDB
- ‚úÖ **gRPC Client**: invoca√ß√£o paralela de especialistas

### Caracter√≠sticas
- Invoca√ß√£o paralela de 5 especialistas via gRPC
- Agrega√ß√£o Bayesiana com prior configur√°vel
- Pesos din√¢micos ajustados por ferom√¥nios
- Fallback determin√≠stico para compliance
- Explicabilidade consolidada com tokens
- Persist√™ncia no ledger com hash SHA-256
- Publica√ß√£o no Kafka (`plans.consensus`)

### Fluxo de Consenso
1. Consumir Cognitive Plan do Kafka (`plans.ready`)
2. Invocar 5 especialistas em paralelo (gRPC)
3. Calcular pesos din√¢micos com ferom√¥nios
4. Agregar com Bayesian Model Averaging
5. Aplicar voting ensemble
6. Verificar compliance e aplicar fallback se necess√°rio
7. Gerar explicabilidade consolidada
8. Persistir decis√£o no ledger
9. Publicar ferom√¥nios
10. Publicar decis√£o no Kafka (`plans.consensus`)

### Deploy
```bash
# Deploy completo
export ENV=dev
export MONGODB_PASSWORD=secret
export REDIS_PASSWORD=secret
./scripts/deploy/deploy-consensus-engine.sh
```

### Acesso
```bash
# Logs
kubectl logs -f -n consensus-engine -l app.kubernetes.io/name=consensus-engine

# M√©tricas
kubectl port-forward -n consensus-engine svc/consensus-engine 8080:8080
curl http://localhost:8080/metrics

# API de decis√µes
kubectl port-forward -n consensus-engine svc/consensus-engine 8000:8000
curl http://localhost:8000/api/v1/decisions/<decision-id>
```

### Dashboards
- Consensus Governance: http://grafana/d/consensus-governance
- Specialists Cognitive Layer: http://grafana/d/specialists-cognitive-layer

### Documenta√ß√£o
- [Mecanismos de Consenso - Documento 03](documento-03-componentes-e-processos-neural-hive-mind.md)
- [Fluxo B - Documento 06](documento-06-fluxos-processos-neural-hive-mind.md)

## Integra√ß√£o Completa da Camada de Mem√≥ria Multicamadas (Fase 1)

A **Integra√ß√£o da Camada de Mem√≥ria** conecta as 4 camadas de armazenamento com API unificada, pipelines de sincroniza√ß√£o, data quality monitoring e lineage tracking.

### Componentes
- ‚úÖ **Memory Layer API**: API unificada com roteamento inteligente (hot ‚Üí Redis, warm ‚Üí MongoDB, cold ‚Üí ClickHouse, semantic ‚Üí Neo4j)
- ‚úÖ **Cliente ClickHouse**: driver async para analytics hist√≥rico com schemas otimizados
- ‚úÖ **Pipelines de Sincroniza√ß√£o**: batch (MongoDB ‚Üí ClickHouse diariamente) e streaming (Kafka ‚Üí ClickHouse)
- ‚úÖ **Data Quality Monitor**: valida√ß√µes, profiling, anomaly detection
- ‚úÖ **Lineage Tracker**: rastreamento de proveni√™ncia (MongoDB + Neo4j)
- ‚úÖ **Retention Policy Manager**: enforcement de TTL e reten√ß√£o por camada
- ‚úÖ **Pol√≠ticas Centralizadas**: ConfigMap com TTL e retention por data_type

### Caracter√≠sticas
- Roteamento autom√°tico baseado em time_range e query_type
- Cache multi-n√≠vel com fallback (Redis ‚Üí MongoDB ‚Üí ClickHouse)
- Sincroniza√ß√£o batch (CronJobs) e streaming (Kafka)
- Data quality monitoring com 5 dimens√µes (completeness, accuracy, timeliness, uniqueness, consistency)
- Lineage tracking com grafo de depend√™ncias (Neo4j) e metadados (MongoDB)
- Pol√≠ticas de TTL e reten√ß√£o centralizadas e enfor√ßadas automaticamente
- Observabilidade completa (m√©tricas, dashboards, alertas)

### Pol√≠ticas de Reten√ß√£o
- **Redis**: 5-15 minutos (TTL autom√°tico)
- **MongoDB**: 30 dias (cleanup di√°rio)
- **ClickHouse**: 18 meses (particionamento mensal)
- **Neo4j**: versionamento de ontologias (max 10 vers√µes)
- **Audit/Compliance**: overrides para 5 anos

### Deploy
```bash
# Deploy completo
export ENV=dev
export MONGODB_PASSWORD=secret
export NEO4J_PASSWORD=secret
export CLICKHOUSE_PASSWORD=secret
./scripts/deploy/deploy-memory-layer-api.sh
./scripts/deploy/deploy-memory-sync-jobs.sh

# Validar deployment
./scripts/validation/validate-memory-layer-integration.sh
```

### Acesso
```bash
# API unificada
kubectl port-forward -n memory-layer-api svc/memory-layer-api 8000:8000
curl -X POST http://localhost:8000/api/v1/memory/query \
  -d '{"query_type": "context", "entity_id": "<id>"}'

# Lineage
curl http://localhost:8000/api/v1/memory/lineage/<entity-id>

# Quality stats
curl http://localhost:8000/api/v1/memory/quality/stats
```

### Dashboards
- Memory Layer Data Quality: http://grafana/d/memory-layer-data-quality
- Memory Layer Lineage: http://grafana/d/memory-layer-lineage
- Memory Layer Overview: http://grafana/d/memory-layer-overview

### Documenta√ß√£o
- [Mem√≥ria Neural Multicamadas - Documento 03](documento-03-componentes-e-processos-neural-hive-mind.md)
- [Camada de Conhecimento & Dados - Documento 08](documento-08-detalhamento-tecnico-camadas-neural-hive-mind.md)

## üõ°Ô∏è Governan√ßa e Comunica√ß√£o (Fase 1 - Finaliza√ß√£o)

As **Camadas de Governan√ßa e Comunica√ß√£o** completam a Fase 1 com protocolos de coordena√ß√£o, risk scoring, explicabilidade e auditoria.

### Componentes
- ‚úÖ **Pheromone Communication Protocol**: coordena√ß√£o de enxame com ferom√¥nios digitais (Redis + Neo4j futuro)
- ‚úÖ **Risk Scoring Engine**: biblioteca multi-dom√≠nio (business, technical, security, operational, compliance)
- ‚úÖ **Explainability Generator**: SHAP/LIME para modelos opacos, API de consulta
- ‚úÖ **Ledger de Auditoria**: MongoDB com hash SHA-256, 100% audit√°vel
- ‚úÖ **Compliance Engine**: OPA Gatekeeper + fallback determin√≠stico
- ‚úÖ **Dashboards de Governan√ßa**: vis√£o executiva consolidada
- ‚úÖ **Eventos de Autocura**: publica√ß√£o no Kafka para rastreamento

### Caracter√≠sticas
- Ferom√¥nios com decay temporal (10% por hora)
- Risk scoring configur√°vel por dom√≠nio e fator
- Explicabilidade 100% com m√∫ltiplos m√©todos (SHAP, LIME, rule_based)
- Auditoria completa com trilhas imut√°veis
- Compliance por design com pol√≠ticas versionadas
- Dashboards executivos para governan√ßa
- Testes end-to-end automatizados

### Pheromone Communication Protocol
- **Tipos**: SUCCESS, FAILURE, WARNING
- **TTL**: 1 hora (configur√°vel)
- **Decay**: Exponencial (10% por hora)
- **Uso**: Ajuste de pesos din√¢micos, coordena√ß√£o de enxame
- **Armazenamento**: Redis (curto prazo), Neo4j (longo prazo - futuro)

### Risk Scoring Multi-Dom√≠nio
- **Dom√≠nios**: Business, Technical, Security, Operational, Compliance
- **Classifica√ß√£o**: LOW, MEDIUM, HIGH, CRITICAL
- **Thresholds**: Configur√°veis por dom√≠nio
- **Pesos**: Ajust√°veis por fator

### Deploy
```bash
# J√° deployado como parte dos servi√ßos da Fase 1
# Consensus Engine inclui PheromoneClient
# Specialists incluem ExplainabilityGenerator
# Risk Scoring integrado em m√∫ltiplos servi√ßos
```

### Acesso
```bash
# Consultar ferom√¥nios
kubectl exec -n redis-cluster <pod> -- redis-cli KEYS 'pheromone:*'

# Consultar explica√ß√µes
kubectl port-forward -n explainability-api svc/explainability-api 8000:8000
curl http://localhost:8000/api/v1/explainability/<token>

# Dashboard de governan√ßa
kubectl port-forward -n neural-hive-observability svc/grafana 3000:80
open http://localhost:3000/d/governance-executive-dashboard
```

### Testes

#### Teste End-to-End da Fase 1
```bash
# Teste end-to-end completo da Fase 1
./tests/phase1-end-to-end-test.sh
```

#### Testes gRPC de Specialists

O projeto inclui ferramentas abrangentes de teste gRPC para validar a comunica√ß√£o entre specialists:

##### Teste R√°pido (Payload √önico)
```bash
# Testar conectividade b√°sica e payload simples
python3 scripts/debug/test-grpc-isolated.py
```

##### Teste Abrangente (M√∫ltiplos Payloads)
```bash
# Testar todos os specialists com m√∫ltiplos cen√°rios de payload
python3 scripts/debug/test-grpc-comprehensive.py

# Testar apenas specialist-business com cen√°rios focados
python3 scripts/debug/test-grpc-comprehensive.py --focus-business

# Testar specialist espec√≠fico
python3 scripts/debug/test-grpc-comprehensive.py --specialist technical
```

##### Suite de Testes Orquestrada
```bash
# Executar todos os cen√°rios de teste com relat√≥rio consolidado
./scripts/debug/run-grpc-comprehensive-tests.sh --all

# Executar com limpeza de resultados antigos
./scripts/debug/run-grpc-comprehensive-tests.sh --all --cleanup
```

##### Cen√°rios de Teste
A suite abrangente valida:
- **Payload Simples**: Plano cognitivo m√≠nimo v√°lido
- **Payload Complexo**: Estrutura completa com tasks aninhadas e metadata
- **Caracteres Especiais**: Unicode, emojis, caracteres de escape
- **Edge Cases**: Campos vazios, valores extremos, payloads grandes
- **Payload M√≠nimo**: Campos m√≠nimos absolutamente necess√°rios

##### Valida√ß√µes Cr√≠ticas
Todos os testes validam o campo timestamp `evaluated_at`:
1. Response n√£o √© None
2. Response √© do tipo `EvaluatePlanResponse`
3. Campo `evaluated_at` existe
4. Campo `evaluated_at` √© do tipo protobuf `Timestamp`
5. Acesso a `evaluated_at.seconds` e `evaluated_at.nanos` bem-sucedido
6. Convers√£o para datetime ISO bem-sucedida

##### Resultados
Os resultados dos testes s√£o salvos em `/tmp/grpc-comprehensive-tests/` incluindo:
- Resultados JSON com detalhes completos
- Relat√≥rio Markdown com tabelas e an√°lise
- Arquivos individuais de stack trace para falhas
- Arquivos de payload que causaram falhas

Para an√°lise detalhada de problemas de compatibilidade de vers√£o protobuf, veja:
- [PROTOBUF_VERSION_ANALYSIS.md](PROTOBUF_VERSION_ANALYSIS.md)
- [ANALISE_DEBUG_GRPC_TYPEERROR.md](ANALISE_DEBUG_GRPC_TYPEERROR.md)

### Dashboards
- Governance Executive Dashboard: http://grafana/d/governance-executive-dashboard
- Consensus Governance: http://grafana/d/consensus-governance
- Data Governance: http://grafana/d/data-governance
- Fluxo E - Autocura: http://grafana/d/fluxo-e-autocura

### Documenta√ß√£o
- [Opera√ß√µes de Governan√ßa](docs/operations/governance-operations.md)
- [Pheromone Communication Protocol](docs/protocols/pheromone-communication-protocol.md)
- [Documento 04 - Seguran√ßa e Governan√ßa](documento-04-seguranca-governanca-neural-hive-mind.md)
- [Documento 06 - Fluxos Operacionais](documento-06-fluxos-processos-neural-hive-mind.md)

## üìà Status do Projeto

- **Fase 0 - Bootstrap**: ‚úÖ CONCLU√çDA (Infraestrutura, Kafka, Gateway de Inten√ß√µes)
- **Fase 1 - Funda√ß√£o**: ‚úÖ **COMPLETE & VALIDATED** *(Completed: 2025-11-12)*
  - ‚úÖ Funda√ß√£o de Dados (MongoDB, Neo4j, ClickHouse, Redis)
  - ‚úÖ Motor de Tradu√ß√£o Sem√¢ntica (Fluxo B)
  - ‚úÖ Especialistas Neurais (5 agentes)
  - ‚úÖ Mecanismo de Consenso Multi-Agente
  - ‚úÖ Integra√ß√£o Completa da Camada de Mem√≥ria
  - ‚úÖ Governan√ßa e Comunica√ß√£o (Ferom√¥nios, Risk Scoring, Explicabilidade, Auditoria)
  - ‚úÖ **Taxa de Sucesso Testes E2E: 100% (23/23 passed)**
  - ‚úÖ **Disponibilidade: 100% (zero crashes, zero restarts)**
  - ‚úÖ **Lat√™ncia M√©dia: 66ms (threshold: <200ms)**

  ### üìä Phase 1 - Executive Summary

  **Completion Date**: November 12, 2025
  **Status**: ‚úÖ **PRODUCTION READY**

  Phase 1 establishes the foundational cognitive capabilities of the Neural Hive-Mind system with complete deployment, validation, and operational readiness.

  **Key Achievements**:
  - **13 components deployed** (9 cognitive services + 4 memory layers)
  - **100% test success rate** (23/23 E2E tests passed)
  - **Zero production failures** (0 crashes, 0 restarts)
  - **Excellent performance** (66ms average latency vs 200ms threshold - 67% better)
  - **100% governance coverage** (auditability, explainability, compliance)

  **Business Value**:
  - Multi-perspective decision making (5 neural specialists)
  - Unified 4-tier memory architecture (hot/warm/semantic/cold)
  - Complete audit trail and explainability for all decisions
  - Scalable event-driven architecture with Kafka backbone

  ### üìö Artifacts

  **Core Documentation**:
  - [üìä Phase 1 Executive Report](docs/PHASE1_EXECUTIVE_REPORT.md) - Comprehensive project summary
  - [üìã Operational Runbook](docs/OPERATIONAL_RUNBOOK.md) - Troubleshooting and maintenance guide
  - [‚ö° Performance Metrics](docs/PHASE1_PERFORMANCE_METRICS.md) - Detailed performance analysis
  - [üéØ Validation Checklist](docs/PHASE1_VALIDATION_CHECKLIST.md) - Complete validation procedures
  - [üéì Presentation](docs/PHASE1_PRESENTATION.md) - Executive slide deck

  **Additional Resources**:
  - [üèóÔ∏è Architecture Diagrams](docs/PHASE1_ARCHITECTURE_DIAGRAM.md) - System architecture visualization
  - [üöÄ Deployment Summary](docs/PHASE1_DEPLOYMENT_SUMMARY.md) - Component versions and resources
  - [üìñ Lessons Learned](docs/PHASE1_LESSONS_LEARNED.md) - Technical and operational insights
  - [üèÜ Completion Certificate](PHASE1_COMPLETION_CERTIFICATE.md) - Official completion record
  - [üìù Changelog](CHANGELOG.md) - Version history and changes

- **Fase 2 - Orquestra√ß√£o**: üîÑ PR√ìXIMA (Orquestrador Din√¢mico, Coordena√ß√£o de Swarm)
- **Fase 3 - Autonomia**: ‚è≥ PLANEJADA (Auto-evolu√ß√£o, Meta-Cogni√ß√£o)

### üéØ Componentes Deployados (13 componentes)

#### Infraestrutura (5 componentes)
| Component | Version | Namespace | Status | Uptime |
|-----------|---------|-----------|--------|--------|
| Kafka Cluster | latest | kafka | ‚úÖ Running | 13d+ |
| MongoDB Cluster | 6.0 | mongodb-cluster | ‚úÖ Running | 13d+ |
| Redis Cluster | 7.0 | redis-cluster | ‚úÖ Running | 2d12h+ |
| Neo4j Cluster | 5.x | neo4j-cluster | ‚úÖ Running | 4d+ |
| ClickHouse Cluster | latest | clickhouse-cluster | ‚úÖ Running (optional) | 3d+ |

#### Servi√ßos Cognitivos (9 componentes)
| Component | Version | Namespace | Status | Uptime |
|-----------|---------|-----------|--------|--------|
| Gateway de Inten√ß√µes | 1.0.0 | gateway-intencoes | ‚úÖ Running | 4d22h+ |
| Semantic Translation Engine | 1.0.0 | semantic-translation-engine | ‚úÖ Running | 2d+ |
| Specialist Business | 1.0.7 | specialist-business | ‚úÖ Running | 3d21h+ |
| Specialist Technical | 1.0.7 | specialist-technical | ‚úÖ Running | 3d21h+ |
| Specialist Behavior | 1.0.7 | specialist-behavior | ‚úÖ Running | 3d21h+ |
| Specialist Evolution | 1.0.7 | specialist-evolution | ‚úÖ Running | 3d21h+ |
| Specialist Architecture | 1.0.7 | specialist-architecture | ‚úÖ Running | 3d21h+ |
| Consensus Engine | 1.0.7 | consensus-engine | ‚úÖ Running | 2d+ |
| Memory Layer API | 1.0.0 | memory-layer-api | ‚úÖ Running | 2d+ |

### ‚úÖ Resultados de Valida√ß√£o

#### Testes E2E Executados
- **Infraestrutura**: 4/4 camadas operacionais ‚úÖ
- **Servi√ßos Cognitivos**: 9/9 running ‚úÖ
- **Health Checks**: 7/7 healthy ‚úÖ
- **Conectividade**: 3/3 validated (DNS resolution, service discovery) ‚úÖ
- **Total**: 23/23 testes passed (100%)

#### M√©tricas de Performance
- **Disponibilidade**: 100% (0 crashes, 0 restarts)
- **Lat√™ncia**:
  - M√≠nima: 39ms
  - M√°xima: 98ms
  - M√©dia: 66ms ‚úÖ (threshold: <200ms)
- **Uptime M√©dio**: 3-4 dias sem interrup√ß√µes
- **Kafka Throughput**: 15 topics ativos
- **Redis Latency**: <5ms

#### Governan√ßa & Compliance
- **Auditabilidade**: 100% dos registros com hash SHA-256
- **Explicabilidade**: 100% das decis√µes com explainability_token
- **Ledger Integrity**: Validado (amostra de 10 registros)
- **Compliance**: OPA Gatekeeper deployado, 0 viola√ß√µes cr√≠ticas

### üìö Documenta√ß√£o & Artefatos

#### Relat√≥rios Consolidados
- [Phase 1 Executive Report](docs/PHASE1_EXECUTIVE_REPORT.md) - Relat√≥rio executivo consolidado
- [Phase 1 Testing Guide](docs/PHASE1_TESTING_GUIDE.md) - Guia de testes completo
- [Operational Runbook](docs/OPERATIONAL_RUNBOOK.md) - Runbook de troubleshooting
- [Phase 1 Presentation](docs/PHASE1_PRESENTATION.md) - Apresenta√ß√£o executiva
- [Phase 1 Performance Metrics](docs/PHASE1_PERFORMANCE_METRICS.md) - M√©tricas detalhadas
- [Phase 1 Completion Certificate](PHASE1_COMPLETION_CERTIFICATE.md) - Certificado de conclus√£o

#### Observabilidade & Monitoramento
- **Dashboards Grafana**: 28 dispon√≠veis (em `monitoring/dashboards/`)
- **Alertas Prometheus**: 19 arquivos configurados (em `monitoring/alerts/`)
- **ServiceMonitors**: 9+ para componentes da Fase 1
- **Stack**: Prometheus + Grafana + Jaeger (deployment status: a confirmar)

### üéØ Crit√©rios de Sucesso da Fase 1 (Validados ‚úÖ)
- ‚úÖ Precis√£o de inten√ß√µes > 90% (via Gateway + NLU)
- ‚úÖ Tempo de resposta cognitiva < 400ms (Semantic Translation + Consensus)
- ‚úÖ Taxa de rejei√ß√£o de pol√≠ticas < 5% (OPA Gatekeeper)
- ‚úÖ Trilhas de auditoria completas habilitadas (100% no ledger)
- ‚úÖ Explicabilidade 100% (tokens gerados para todas as decis√µes)
- ‚úÖ Diverg√™ncia entre especialistas < 5% (Bayesian + Voting)
- ‚úÖ Ferom√¥nios operacionais (coordena√ß√£o de enxame)
- ‚úÖ **Testes E2E: 100% de sucesso (23/23 passed)**
- ‚úÖ **Disponibilidade: 100% (zero crashes)**
- ‚úÖ **Lat√™ncia dentro dos SLOs (<200ms)**
- ‚úÖ **Integridade do ledger validada (100%)**

### üöÄ Phase 2 Roadmap

#### Componentes Planejados
- **Dynamic Orchestrator**: Coordena√ß√£o de execu√ß√£o (Temporal/Cadence)
- **Tool Integration Layer**: Integra√ß√£o com 87 ferramentas MCP (Model Context Protocol)
- **SLA Management System**: Garantias de qualidade e error budgets
- **Execution System**: Execu√ß√£o de planos com rollback autom√°tico
- **Swarm Coordination**: Queen Agent, Scout, Worker, Drone

#### Pr√©-requisitos
- ‚úÖ Fase 1 completa e validada
- ‚úÖ Infraestrutura operacional
- ‚úÖ Observabilidade deployada
- ‚úÖ Governan√ßa ativa

#### Timeline Estimado
- **Dura√ß√£o**: 2-3 meses
- **In√≠cio**: Q1 2026

## üîí Seguran√ßa

### Zero Trust Implementation
- mTLS obrigat√≥rio entre todos os servi√ßos
- Network policies deny-by-default
- Image signature validation
- Resource quotas e limits obrigat√≥rios
- RBAC com least privilege

### Vault e SPIFFE Integration

O Neural Hive-Mind utiliza HashiCorp Vault e SPIFFE/SPIRE para gerenciamento centralizado de secrets e identidade de workloads.

**Modelo de Seguran√ßa em 3 Camadas:**
1. **Camada de Transporte**: Istio mTLS para comunica√ß√£o service-to-service
2. **Camada de Aplica√ß√£o**: Tokens ef√™meros do Vault via identidades SPIFFE
3. **Gerenciamento de Secrets**: Vault como store centralizado com credenciais din√¢micas

**Componentes:**
- **Vault HA Cluster**: 3 r√©plicas com storage Raft e auto-unseal via AWS KMS
- **SPIRE Server**: Provedor de identidade SPIFFE com Vault como CA upstream
- **SPIRE Agents**: DaemonSet em cada node para atesta√ß√£o de workloads
- **Vault Agent Injector**: Sidecar para inje√ß√£o autom√°tica de secrets
- **Security Library**: Biblioteca Python compartilhada (`libraries/security/`) para integra√ß√£o Vault/SPIFFE

**Quick Start:**

```bash
# 1. Deploy Vault
helm install vault helm-charts/vault --namespace vault --create-namespace

# 2. Deploy SPIRE
helm install spire helm-charts/spire --namespace spire --create-namespace

# 3. Inicializar Vault
./scripts/vault-init.sh

# 4. Criar SPIRE registration entries
./scripts/spire-register-entries.sh

# 5. Habilitar para servi√ßos
helm upgrade orchestrator-dynamic helm-charts/orchestrator-dynamic \
  --set config.vault.enabled=true \
  --set config.spiffe.enabled=true
```

**Verificar Integra√ß√£o:**

```bash
# Verificar status do Vault
kubectl exec -n vault vault-0 -- vault status

# Verificar entries SPIRE
kubectl exec -n spire spire-server-0 -- /opt/spire/bin/spire-server entry show

# Verificar logs do servi√ßo
kubectl logs -n neural-hive-orchestration orchestrator-dynamic-xxx | grep vault
```

**Monitoramento:**
- **Dashboard Grafana**: `monitoring/dashboards/vault-spiffe-dashboard.json`
- **Alertas Prometheus**: `monitoring/alerts/vault-spiffe-alerts.yaml`
- **M√©tricas**: Vault e SPIRE exp√µem m√©tricas Prometheus na porta 9090

**Migra√ß√£o Gradual:**
A integra√ß√£o Vault/SPIFFE √© opt-in e compat√≠vel com vers√µes anteriores:
1. **Fase 1**: Deploy de infraestrutura (sem mudan√ßas nos servi√ßos)
2. **Fase 2**: Habilitar Vault em ambiente dev
3. **Fase 3**: Migrar secrets para Vault (paralelo com K8s Secrets)
4. **Fase 4**: Habilitar autentica√ß√£o SPIFFE
5. **Fase 5**: Remover K8s Secrets (somente Vault)
6. **Fase 6**: Rollout em produ√ß√£o

**Refer√™ncias:**
- [Vault Documentation](https://developer.hashicorp.com/vault)
- [SPIRE Documentation](https://spiffe.io/docs/latest/)
- [Vault Agent Injector](https://developer.hashicorp.com/vault/docs/platform/k8s/injector)

### Compliance
- Vulnerability scanning autom√°tico
- Policy-as-code audit√°vel
- Encryption at rest e in transit
- Audit logs completos

## üö® Troubleshooting

### Problemas Comuns

**Cluster n√£o sobe**
```bash
# Verificar quotas AWS
aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A

# Verificar IAM permissions
aws iam simulate-principal-policy --policy-source-arn <role-arn> --action-names eks:*
```

**Pods n√£o iniciam**
```bash
# Verificar policies OPA
kubectl get constraints -A
kubectl describe constraint <constraint-name>

# Verificar network policies
kubectl get networkpolicies -A
```

**mTLS n√£o funciona**
```bash
# Verificar Istio
kubectl get peerauthentication -A
istioctl proxy-status

# Debug certificados
istioctl authn tls-check <pod>.<namespace> <service>.<namespace>
```

## üìö Documenta√ß√£o

### Fase 1 - Funda√ß√£o
- **[Deployment Guide](DEPLOYMENT_GUIDE.md)**: Guia detalhado de implementa√ß√£o
- **[Dependency Optimization Guide](docs/DEPENDENCY_OPTIMIZATION.md)**: Otimiza√ß√µes de depend√™ncias e modelos ML
- **[ADR-0001](docs/adr/ADR-0001-cloud-provider-selection.md)**: Sele√ß√£o de Cloud Provider
- **[ADR-0002](docs/adr/ADR-0002-service-mesh-selection.md)**: Sele√ß√£o de Service Mesh
- **[ADR-0003](docs/adr/ADR-0003-container-registry-solution.md)**: Solu√ß√£o de Container Registry

### Fase 2 - Camada de Execu√ß√£o (100% Implementada) ‚úÖ
- **[PHASE2_IMPLEMENTATION_STATUS.md](PHASE2_IMPLEMENTATION_STATUS.md)**: Status detalhado de todos os componentes da Fase 2
- **[PHASE2_FLOW_C_INTEGRATION.md](docs/PHASE2_FLOW_C_INTEGRATION.md)**: Integra√ß√£o completa do Flow C (Intent ‚Üí Deploy)
- **[neural_hive_integration Library](libraries/neural_hive_integration/README.md)**: Biblioteca Python para integra√ß√£o Flow C
- **[Worker Agents Integration Guide](docs/WORKER_AGENTS_INTEGRATION_GUIDE.md)**: Guia de integra√ß√£o dos 5 executors (90% Production-Ready)

**Componentes Implementados**:
- ‚úÖ Orchestrator Dynamic (Temporal workflows C1-C6)
- ‚úÖ Service Registry (gRPC discovery)
- ‚úÖ Execution Ticket Service (ticket management)
- ‚úÖ Worker Agents (5 executors com integra√ß√µes reais - 90% Production-Ready)
- ‚úÖ Queen/Scout/Analyst/Optimizer/Guard Agents
- ‚úÖ Code Forge (neural code generation)
- ‚úÖ SLA Management
- ‚úÖ Flow C Integration (biblioteca neural_hive_integration v1.0.0)
- ‚úÖ Observabilidade completa (8 alertas Prometheus + 6 pain√©is Grafana)

**Worker Agents - Executores de Tarefas Distribu√≠dos**:

| Executor | Integra√ß√£o Real | Status |
|----------|----------------|--------|
| **BUILD** | Code Forge | ‚úÖ Production-Ready |
| **DEPLOY** | ArgoCD + Flux | ‚úÖ Production-Ready |
| **TEST** | GitHub Actions + GitLab CI + Jenkins | ‚úÖ Production-Ready |
| **VALIDATE** | OPA + Trivy + SonarQube + Snyk + Checkov | ‚úÖ Production-Ready |
| **EXECUTE** | K8s Jobs + Docker + Lambda + Local | ‚úÖ Production-Ready |

**Guia de Integra√ß√£o Completo**: [WORKER_AGENTS_INTEGRATION_GUIDE.md](docs/WORKER_AGENTS_INTEGRATION_GUIDE.md)

## üîí Compliance & Governan√ßa de Dados

O Neural Hive Mind implementa uma **Compliance Layer** abrangente para conformidade com LGPD/GDPR:

### Funcionalidades

- **üîç Detec√ß√£o de PII**: Identifica√ß√£o autom√°tica de dados pessoais usando Microsoft Presidio
- **üé≠ Anonimiza√ß√£o**: M√∫ltiplas estrat√©gias (replace, mask, redact, hash)
- **üîê Criptografia**: Criptografia de campos sens√≠veis em repouso (Fernet/AES-128)
- **üìã Audit Logging**: Rastreamento completo de opera√ß√µes de compliance
- **‚è∞ Pol√≠ticas de Reten√ß√£o**: Mascaramento/dele√ß√£o autom√°tica ap√≥s per√≠odo configur√°vel
- **üóëÔ∏è Direito ao Esquecimento**: Suporte a GDPR right to erasure
- **üì¶ Portabilidade de Dados**: Exporta√ß√£o de dados de usu√°rio

### Configura√ß√£o R√°pida

#### 1. Instalar Depend√™ncias

```bash
# Instalar bibliotecas de compliance
pip install presidio-analyzer presidio-anonymizer

# Baixar modelos de idioma
python -m spacy download pt_core_news_sm  # Portugu√™s
python -m spacy download en_core_web_sm   # Ingl√™s
```

#### 2. Gerar Chave de Criptografia

```bash
# Gerar chave Fernet
python scripts/generate_encryption_key.py --output-path /etc/neural-hive/encryption.key

# Ou para vari√°vel de ambiente
python scripts/generate_encryption_key.py --print-key
```

#### 3. Configurar Vari√°veis de Ambiente

```bash
# Habilitar compliance layer
export ENABLE_COMPLIANCE_LAYER=true
export ENABLE_PII_DETECTION=true
export ENABLE_FIELD_ENCRYPTION=true
export ENCRYPTION_KEY_PATH=/etc/neural-hive/encryption.key
export ENABLE_AUDIT_LOGGING=true

# Configura√ß√µes opcionais
export PII_DETECTION_LANGUAGES=pt,en
export PII_ANONYMIZATION_STRATEGY=replace
export FIELDS_TO_ENCRYPT=correlation_id,trace_id,span_id,intent_id
export AUDIT_LOG_RETENTION_DAYS=730
```

#### 4. Deploy Pol√≠tica de Reten√ß√£o (Kubernetes)

```bash
# Criar secret com chave de criptografia
kubectl create secret generic encryption-key-secret \
  --from-file=encryption.key=/etc/neural-hive/encryption.key \
  --namespace neural-hive

# Deploy CronJob de reten√ß√£o
kubectl apply -f k8s/cronjobs/retention-policy-job.yaml
```

### Arquitetura de Compliance

```mermaid
sequenceDiagram
    participant CP as Cognitive Plan
    participant PII as PIIDetector
    participant FE as FieldEncryptor
    participant AL as AuditLogger
    participant DB as MongoDB

    CP->>PII: Detectar PII em descri√ß√µes
    PII-->>CP: Texto anonimizado
    CP->>DB: Infer√™ncia e avalia√ß√£o
    DB->>FE: Criptografar campos sens√≠veis
    FE-->>DB: Campos criptografados
    DB->>AL: Registrar opera√ß√£o
    AL-->>DB: Audit log persistido
```

### Scripts Utilit√°rios

```bash
# Executar pol√≠ticas de reten√ß√£o manualmente
python scripts/run_retention_policies.py

# Modo dry-run (sem modificar dados)
python scripts/run_retention_policies.py --dry-run

# Executar pol√≠tica espec√≠fica
python scripts/run_retention_policies.py --policy-name high_risk_extended
```

### M√©tricas Prometheus

M√©tricas de compliance dispon√≠veis:

- `compliance_pii_entities_detected_total` - Entidades PII detectadas
- `compliance_fields_encrypted_total` - Campos criptografados
- `compliance_audit_events_total` - Eventos auditados
- `compliance_retention_documents_processed_total` - Documentos processados por reten√ß√£o
- `compliance_pii_detection_duration_seconds` - Lat√™ncia de detec√ß√£o PII
- `compliance_encryption_duration_seconds` - Lat√™ncia de criptografia

### Pol√≠ticas de Reten√ß√£o Padr√£o

| Pol√≠tica | Reten√ß√£o | Recomenda√ß√µes | A√ß√£o |
|----------|----------|---------------|------|
| `high_risk_extended` | 365 dias | reject | Mascarar |
| `standard_retention` | 90 dias | approve, conditional | Mascarar |
| `review_required_extended` | 180 dias | review_required | Mascarar |

### Conformidade LGPD/GDPR

‚úÖ **Minimiza√ß√£o de dados**: PII detectado e anonimizado automaticamente
‚úÖ **Criptografia em repouso**: Campos sens√≠veis criptografados
‚úÖ **Auditabilidade**: Todos os eventos registrados (reten√ß√£o 2 anos)
‚úÖ **Direito ao esquecimento**: API para dele√ß√£o por correlation_id
‚úÖ **Portabilidade**: API para exportar dados de usu√°rio
‚úÖ **Transpar√™ncia**: Audit logs com rastreamento completo

### Documenta√ß√£o Adicional

- [C√≥digo de Compliance](libraries/python/neural_hive_specialists/compliance/)
- [RetentionManager](libraries/python/neural_hive_specialists/ledger/retention_manager.py)
- [Scripts de Compliance](scripts/)
- [CronJob Kubernetes](k8s/cronjobs/retention-policy-job.yaml)

## üè¢ Multi-Tenancy & API Gateway

O Neural Hive Mind suporta **multi-tenancy** com isolamento completo de dados e configura√ß√µes customizadas por tenant:

### Funcionalidades

- **Envoy API Gateway**: Proxy reverso com rate limiting, load balancing e autentica√ß√£o centralizada
- **Isolamento de Dados**: Opini√µes, cache e m√©tricas isolados por tenant
- **Configura√ß√µes Customizadas**: Modelos ML, thresholds e features espec√≠ficos por tenant
- **Rate Limiting por Tenant**: Limites configur√°veis (100-500 req/s)
- **M√©tricas por Tenant**: Monitoramento independente de cada tenant
- **Cardinality Protection**: Limite de 100 tenants para evitar explos√£o de m√©tricas

### Arquitetura

```
Consensus Engine ‚Üí Envoy Gateway (JWT + Rate Limit + LB)
                        ‚Üì
                  MultiTenantSpecialist
                        ‚Üì
          Ledger (tenant_id) + Cache (tenant prefix) + Metrics (tenant label)
```

### Quick Start

1. **Deploy Envoy Gateway:**
   ```bash
   make deploy-envoy-gateway
   ```

2. **Configurar tenants:**
   ```bash
   kubectl apply -f k8s/configmaps/tenant-configs.yaml
   ```

3. **Migrar ledger existente:**
   ```bash
   make migrate-ledger-tenant-id MONGODB_URI=mongodb://localhost:27017
   ```

4. **Habilitar multi-tenancy nos especialistas:**
   ```bash
   export ENABLE_MULTI_TENANCY=true
   export TENANT_CONFIGS_PATH=/etc/neural-hive/tenants/tenant-configs.json
   ```

5. **Visualizar m√©tricas:**
   ```bash
   make view-multi-tenancy-dashboard
   ```

### Adicionar Novo Tenant

```bash
make add-tenant
# Ou editar manualmente:
kubectl edit configmap specialist-tenant-configs
```

### M√©tricas Prometheus

- `neural_hive_tenant_evaluations_total` - Avalia√ß√µes por tenant
- `neural_hive_tenant_confidence_score` - Confidence score por tenant
- `neural_hive_tenant_processing_time_seconds` - Lat√™ncia por tenant
- `neural_hive_active_tenants_count` - N√∫mero de tenants ativos
- `envoy_ratelimit_over_limit` - Rate limit excedido por tenant

### Configura√ß√£o de Tenants

Estrutura do `tenant-configs.json`:

```json
{
  "tenant-enterprise-A": {
    "tenant_id": "tenant-enterprise-A",
    "tenant_name": "Enterprise Customer A",
    "is_active": true,
    "mlflow_model_name": "technical-tenant-a-model",
    "min_confidence_score": 0.85,
    "rate_limit_per_second": 500,
    "metadata": {
      "tier": "premium",
      "sla_level": "gold"
    }
  }
}
```

### Comandos Make

```bash
make deploy-envoy-gateway           # Deploy Envoy API Gateway
make migrate-ledger-tenant-id       # Migrar ledger para multi-tenancy
make test-multi-tenancy             # Executar testes de multi-tenancy
make view-envoy-stats               # Visualizar estat√≠sticas do Envoy
make view-multi-tenancy-dashboard   # Abrir dashboard de multi-tenancy
make add-tenant                     # Adicionar novo tenant (interativo)
```

### Arquitetura de Isolamento

- **Ledger**: Campo `tenant_id` adicionado a todos os documentos + √≠ndices compostos
- **Cache Redis**: Chaves prefixadas com tenant_id (`opinion:tenant-A:technical:1.0.0:hash`)
- **M√©tricas**: Label `tenant_id` em m√©tricas Prometheus (com cardinality limit de 100)
- **Modelos ML**: Modelos customizados por tenant no MLflow

### Seguran√ßa

#### Autentica√ß√£o e Autoriza√ß√£o
- JWT authentication obrigat√≥ria no Envoy Gateway
- Extra√ß√£o de `tenant_id` do claim JWT
- Valida√ß√£o de tenant ativo antes de processar requisi√ß√£o
- Rate limiting por tenant para prevenir abuso
- Isolamento l√≥gico de dados no MongoDB

#### Integra√ß√£o Vault & SPIFFE (Zero-Trust Security)

O Neural Hive-Mind implementa **HashiCorp Vault** para gerenciamento de credenciais e **SPIFFE/SPIRE** para identidade de workloads, estabelecendo arquitetura **zero-trust** para comunica√ß√£o entre servi√ßos.

**Componentes:**

- **Vault**: Gerenciamento centralizado de credenciais
  - Credenciais din√¢micas PostgreSQL (TTL: 1h, renova√ß√£o autom√°tica)
  - Secrets est√°ticos MongoDB/Kafka em KV store
  - PKI Engine para emiss√£o de certificados mTLS
  - Auto-unseal via AWS KMS
  - Audit logs em S3

- **SPIRE**: Identidade criptogr√°fica para workloads
  - JWT-SVID para autentica√ß√£o gRPC (Service Registry)
  - X.509-SVID para canais mTLS
  - Trust domain: `neural-hive.local`
  - PostgreSQL RDS para datastore (provisionado via Terraform)

**Fluxo de Seguran√ßa:**

1. Orchestrator autentica no Vault via Kubernetes Service Account
2. Obt√©m credenciais din√¢micas PostgreSQL (renovadas a cada 48 minutos)
3. SPIRE Agent injeta JWT-SVID para chamadas ao Service Registry
4. Service Registry valida SPIFFE ID antes de retornar agentes dispon√≠veis
5. mTLS opcional com X.509-SVID para comunica√ß√£o entre servi√ßos

**Configura√ß√£o:**

- Scripts de inicializa√ß√£o: `scripts/vault-init-pki.sh`, `scripts/vault-configure-policies.sh`
- Terraform module: `infrastructure/terraform/modules/spire-datastore/`
- Library: `libraries/security/neural_hive_security/` (VaultClient, SPIFFEManager)
- Helm values: `vault.enabled=true`, `spiffe.enabled=true` em produ√ß√£o

**Refer√™ncias:**

- Biblioteca neural-hive-security: `/jimy/Neural-Hive-Mind/libraries/security/`
- Documenta√ß√£o de implementa√ß√£o: `VAULT_SPIFFE_IMPLEMENTATION_STATUS.md`

## üîÑ Continuous Learning com Feedback Humano

O Neural Hive Mind implementa **continuous learning** atrav√©s de feedback humano sobre opini√µes de especialistas, permitindo re-treinamento autom√°tico de modelos quando limiares de qualidade s√£o atingidos.

### Funcionalidades

- ‚úÖ **API de Feedback**: Endpoint REST para revisores humanos submeterem feedback sobre opini√µes
- ‚úÖ **Valida√ß√£o JWT**: Autentica√ß√£o com roles granulares (human_expert, reviewer, etc.)
- ‚úÖ **PII Detection**: Anonimiza√ß√£o autom√°tica de informa√ß√µes pessoais em notas de feedback
- ‚úÖ **Retraining Trigger**: Disparo autom√°tico de re-treinamento ao atingir threshold de feedback
- ‚úÖ **MLflow Integration**: Pipeline de treinamento gerenciado via MLflow Projects
- ‚úÖ **Async Monitoring**: Monitoramento autom√°tico de runs MLflow em background
- ‚úÖ **Circuit Breaker**: Prote√ß√£o contra falhas do MongoDB com pybreaker

### Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CONTINUOUS LEARNING PIPELINE                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìù Human Feedback (POST /api/v1/feedback)                      ‚îÇ
‚îÇ   ‚îú‚îÄ JWT Authentication & Role Validation                       ‚îÇ
‚îÇ   ‚îú‚îÄ PII Detection & Anonymization (Presidio)                   ‚îÇ
‚îÇ   ‚îú‚îÄ Circuit Breaker (MongoDB)                                  ‚îÇ
‚îÇ   ‚îî‚îÄ Persist to feedback collection                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üîÑ Retraining Trigger (CronJob 1h)                             ‚îÇ
‚îÇ   ‚îú‚îÄ Count feedback by specialist_type + window                 ‚îÇ
‚îÇ   ‚îú‚îÄ Check threshold (default: 100 feedbacks)                   ‚îÇ
‚îÇ   ‚îú‚îÄ Trigger MLflow run (async)                                 ‚îÇ
‚îÇ   ‚îî‚îÄ Record trigger in retraining_triggers collection           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üîç MLflow Run Monitor (CronJob 5min)                           ‚îÇ
‚îÇ   ‚îú‚îÄ Find triggers with status='running'                        ‚îÇ
‚îÇ   ‚îú‚îÄ Check MLflow run status (FINISHED/FAILED/RUNNING)          ‚îÇ
‚îÇ   ‚îú‚îÄ Extract metrics (precision, recall, f1)                    ‚îÇ
‚îÇ   ‚îî‚îÄ Update trigger status + duration                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä Prometheus Metrics                                          ‚îÇ
‚îÇ   ‚îú‚îÄ neural_hive_feedback_submissions_total                     ‚îÇ
‚îÇ   ‚îú‚îÄ neural_hive_feedback_rating (histogram)                    ‚îÇ
‚îÇ   ‚îú‚îÄ neural_hive_retraining_triggers_total                      ‚îÇ
‚îÇ   ‚îú‚îÄ neural_hive_retraining_run_duration_seconds                ‚îÇ
‚îÇ   ‚îî‚îÄ neural_hive_pii_entities_detected_total                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Quick Start

1. **Submeter feedback manualmente:**
   ```bash
   make submit-feedback \
     OPINION_ID=opinion-abc123 \
     RATING=0.9 \
     RECOMMENDATION=approve \
     NOTES="An√°lise t√©cnica correta"
   ```

2. **Verificar threshold de re-treinamento:**
   ```bash
   make check-retraining-trigger
   ```

3. **Disparar re-treinamento manual:**
   ```bash
   make trigger-retraining SPECIALIST_TYPE=technical
   ```

4. **Treinar modelo via MLflow:**
   ```bash
   make train-model SPECIALIST_TYPE=technical
   ```

5. **Monitorar runs MLflow:**
   ```bash
   make monitor-retraining-runs
   ```

6. **Visualizar dashboard:**
   ```bash
   make view-continuous-learning
   ```

### API de Feedback

**POST /api/v1/feedback**

```bash
curl -X POST http://specialist-technical:8000/api/v1/feedback \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{
    "opinion_id": "opinion-abc123",
    "human_rating": 0.9,
    "human_recommendation": "approve",
    "feedback_notes": "Opini√£o t√©cnica correta e bem fundamentada"
  }'
```

**GET /api/v1/feedback/opinion/{opinion_id}**

Retorna todos os feedbacks submetidos para uma opini√£o espec√≠fica.

**GET /api/v1/feedback/stats?specialist_type=technical&window_days=30**

Retorna estat√≠sticas agregadas de feedback (rating m√©dio, distribui√ß√£o de recomenda√ß√µes).

### Configura√ß√£o

Vari√°veis de ambiente:

```bash
# Feedback Collection
ENABLE_FEEDBACK_COLLECTION=true
FEEDBACK_REQUIRE_AUTHENTICATION=true
JWT_SECRET_KEY=your-secret-key
FEEDBACK_ALLOWED_ROLES=human_expert,reviewer,admin

# PII Detection
PII_DETECTOR_ENABLED=true
PII_ANONYMIZATION_STRATEGY=redact

# Retraining Trigger
ENABLE_RETRAINING_TRIGGER=true
RETRAINING_THRESHOLD_COUNT=100
RETRAINING_FEEDBACK_WINDOW_DAYS=30
MLFLOW_TRACKING_URI=http://mlflow:5000
RETRAINING_MLFLOW_PROJECT_URI=./mlflow_projects/specialist_retraining
```

### Dashboards e Alertas

- **Dashboard Grafana**: `monitoring/dashboards/continuous-learning-dashboard.json`
- **Alertas Prometheus**: `monitoring/alerts/continuous-learning-alerts.yaml`

Alertas configurados:
- `LowFeedbackSubmissionRate`: Taxa de submiss√µes abaixo de 1/hora por 2h
- `LowAverageFeedbackRating`: Rating m√©dio < 0.5 por 1h
- `RetrainingTriggerFailed`: Falha em trigger de re-treinamento
- `MLflowRunStuckRunning`: Run MLflow rodando h√° mais de 1h
- `FeedbackAPIHighErrorRate`: Taxa de erro da API > 10%
- `HighPIIDetectionErrorRate`: Erros de PII detection > 5%

### Comandos Make

```bash
# Feedback
make submit-feedback              # Submeter feedback via API
make test-feedback                # Executar testes de feedback

# Retraining
make check-retraining-trigger     # Verificar threshold (dry-run)
make trigger-retraining           # Disparar re-treinamento manual
make train-model                  # Treinar modelo via MLflow
make monitor-retraining-runs      # Monitorar runs MLflow

# Deploy
make deploy-retraining-cronjob    # Deploy CronJob de re-treinamento

# Observabilidade
make view-continuous-learning     # Abrir dashboard Grafana
```

### M√©tricas Prometheus

**Feedback:**
- `neural_hive_feedback_submissions_total{specialist_type, submitted_by_role}`
- `neural_hive_feedback_rating{specialist_type}` (histogram)
- `neural_hive_feedback_recommendation_total{recommendation}`
- `neural_hive_feedback_count{specialist_type}` (gauge)
- `neural_hive_feedback_avg_rating{specialist_type}` (gauge)
- `neural_hive_feedback_api_errors_total{error_type}`

**Retraining:**
- `neural_hive_retraining_threshold_checks_total{specialist_type, threshold_met}`
- `neural_hive_retraining_triggers_total{specialist_type, status}`
- `neural_hive_retraining_run_duration_seconds{specialist_type}` (histogram)
- `neural_hive_retraining_last_trigger_timestamp_seconds{specialist_type, status}` (gauge)

**Compliance (PII):**
- `neural_hive_pii_entities_detected_total{entity_type}`
- `neural_hive_pii_anonymization_total{strategy}`
- `neural_hive_pii_detection_errors_total{error_type}`

### Documenta√ß√£o Adicional

Para detalhes completos sobre arquitetura, configura√ß√£o, troubleshooting e monitoramento:

üìñ **[Continuous Learning Guide](docs/CONTINUOUS_LEARNING_GUIDE.md)**

## üî≠ Distributed Tracing & Observability

Neural Hive implementa observabilidade completa com OpenTelemetry, Jaeger, e Prometheus para rastreabilidade end-to-end de inten√ß√µes, planos, e execu√ß√µes.

### Arquitetura de Tracing

```mermaid
graph LR
    A[Services] -->|OTLP| B[OTEL Collector]
    B -->|Tail Sampling| C[Jaeger Collector]
    C -->|Storage| D[Elasticsearch]
    E[Jaeger Query] -->|Read| D
    F[Grafana] -->|Exemplars| E
    B -->|Metrics| G[Prometheus]
```

### Componentes Instrumentados

Todos os servi√ßos utilizam `neural_hive_observability==1.2.0` para instrumenta√ß√£o autom√°tica:

- **Gateway-Intencoes**: ASR, NLU, Kafka producer (propaga√ß√£o de intent_id)
- **Orchestrator-Dynamic**: Kafka consumers, Temporal workflows, gRPC clients (propaga√ß√£o de plan_id)
- **Specialists (5)**: gRPC servicers, ML inference, model evaluation
- **Core Services**: Queen-Agent, Execution-Ticket, Guard-Agents, Service-Registry
- **Support Services**: MCP-Tool-Catalog, Memory-Layer, Consensus-Engine, etc.

### Atributos Neural Hive

Spans incluem atributos customizados para correla√ß√£o:

| Atributo | Descri√ß√£o | Exemplo |
|----------|-----------|---------|
| `neural.hive.intent.id` | ID da inten√ß√£o original | `intent-a1b2c3d4-...` |
| `neural.hive.plan.id` | ID do plano gerado | `plan-e5f6g7h8-...` |
| `neural.hive.user.id` | ID do usu√°rio | `user-12345` |
| `neural.hive.domain` | Dom√≠nio da opera√ß√£o | `experiencia`, `cognicao` |
| `neural.hive.component` | Componente do servi√ßo | `gateway`, `orchestrator` |
| `neural.hive.layer` | Camada arquitetural | `experiencia`, `cognicao`, `execucao` |

### Valida√ß√£o E2E de Tracing

Execute os scripts de valida√ß√£o:

```bash
# Validar infraestrutura OTEL + Jaeger
./scripts/observability/validate-otel-jaeger-complete.sh

# Testar correla√ß√£o de contexto
./scripts/observability/test-correlation.sh --verbose

# Smoke test r√°pido (<2 min)
./scripts/observability/smoke-test-tracing.sh

# Validar fluxo E2E completo (gateway ‚Üí orchestrator ‚Üí specialists)
python scripts/observability/test-e2e-tracing-complete.py \
  --gateway-url http://gateway-intencoes:8000 \
  --jaeger-url http://jaeger-query:16686 \
  --verbose \
  --output-json reports/e2e-tracing-$(date +%Y%m%d).json
```

### Queries Jaeger Comuns

**Buscar por Intent ID:**
```
Service: *
Tags: neural.hive.intent.id=<intent-id>
Lookback: 1h
```

**Buscar por Plan ID:**
```
Service: *
Tags: neural.hive.plan.id=<plan-id>
Lookback: 1h
```

**Buscar traces com erro:**
```
Service: *
Tags: error=true
Lookback: 1h
```

**Via API:**
```bash
curl "http://jaeger-query:16686/api/traces?tag=neural.hive.intent.id:<intent-id>" | jq
```

### Documenta√ß√£o de Observabilidade

- üìñ **[Guia de Instrumenta√ß√£o](docs/observability/instrumentation-guide.md)** - Como instrumentar servi√ßos
- üîß **[Troubleshooting Jaeger](docs/observability/jaeger-troubleshooting.md)** - Diagn√≥stico e resolu√ß√£o de problemas
- üîç **[Queries Customizadas](docs/observability/jaeger-queries-neural-hive.md)** - Queries avan√ßadas para Neural Hive
- üèóÔ∏è **[Arquitetura de Observabilidade](docs/observability/architecture.md)** - Vis√£o geral da stack

### Sampling Strategies

Configurado em `helm-charts/jaeger/values.yaml`:

| Contexto | Taxa de Sampling | Descri√ß√£o |
|----------|------------------|-----------|
| Default | 5% | Todos os traces |
| Gateway-Intencoes | 25% | Entrada cr√≠tica |
| Intents com intent_id | 70% | Via OTEL tail sampling |
| Plans com plan_id | 70% | Via OTEL tail sampling |
| Erros | 100% | Sempre capturados |
| Health checks | 1% | Reduzir ru√≠do |

### M√©tricas de Observabilidade

Prometheus exp√µe m√©tricas de tracing:

```
otelcol_receiver_accepted_spans      # Spans recebidos pelo OTEL Collector
otelcol_exporter_sent_spans          # Spans exportados para Jaeger
jaeger_collector_spans_received_total # Spans recebidos pelo Jaeger
jaeger_query_requests_total          # Queries no Jaeger UI
```

### Troubleshooting R√°pido

**Traces n√£o aparecem no Jaeger:**
```bash
# 1. Verificar OTEL Collector est√° exportando
kubectl logs -n observability deployment/neural-hive-otel-collector | grep "exporter.*jaeger"

# 2. Verificar sampling n√£o est√° descartando
kubectl exec -n observability deployment/neural-hive-otel-collector -- \
  curl -s http://localhost:8888/metrics | grep tail_sampling

# 3. Verificar Jaeger est√° indexando
kubectl exec -n observability deployment/jaeger-collector -- \
  curl -s http://elasticsearch:9200/neural-hive-jaeger-*/_count
```

**Atributos Neural Hive n√£o aparecem:**
```bash
# 1. Verificar baggage est√° sendo propagado
kubectl logs -n neural-hive deployment/gateway-intencoes | grep "set_baggage"

# 2. Verificar OTEL processor est√° ativo
kubectl get configmap -n observability neural-hive-otel-collector -o yaml | grep "attributes/neural_hive"
```

Consulte [docs/observability/jaeger-troubleshooting.md](docs/observability/jaeger-troubleshooting.md) para cen√°rios detalhados.

## ü§ñ ML Pipeline - Specialist Model Training & Management

O Neural Hive Mind utiliza um pipeline de Machine Learning para treinar e gerenciar modelos de avalia√ß√£o dos 5 especialistas (technical, business, behavior, evolution, architecture).

### Overview

Cada especialista utiliza modelos de ML (Random Forest, Gradient Boosting ou Neural Networks) para avaliar planos cognitivos e emitir opini√µes estruturadas. Os modelos s√£o:
- **Treinados** com datasets sint√©ticos gerados por LLMs (GPT-4, Claude, Ollama)
- **Versionados** e **rastreados** no MLflow Model Registry
- **Promovidos** automaticamente quando atingem thresholds de qualidade
- **Carregados** em runtime pelos pods de especialistas via `mlflow_client.py`

### Quick Start

```bash
# Gerar datasets com IA
cd ml_pipelines/training
./generate_all_datasets.sh

# Treinar todos os modelos
./train_all_specialists.sh

# Validar modelos carregados
./validate_models_loaded.sh

# Verificar status dos modelos
../scripts/check_model_status.sh --all
```

### Components

| Componente | Descri√ß√£o |
|------------|-----------|
| **Dataset Generation** | Gera√ß√£o sint√©tica com LLMs (OpenAI/Anthropic/Ollama) |
| **Model Training** | Random Forest, Gradient Boosting, Neural Networks |
| **MLflow Integration** | Tracking, Model Registry, Auto-promotion |
| **Validation** | Health checks e model loading verification |
| **Maintenance Scripts** | Status check, retrain, rollback |

### Model Naming Convention

- **Modelos**: `{specialist_type}-evaluator` (ex: `technical-evaluator`)
- **Experimentos MLflow**: `{specialist_type}-specialist` (ex: `technical-specialist`)
- **Stages**: Production, Staging, Archived

### Promotion Thresholds

Para promo√ß√£o autom√°tica para Production:

| M√©trica | Threshold |
|---------|-----------|
| Precision | ‚â• 0.75 |
| Recall | ‚â• 0.70 |
| F1 Score | ‚â• 0.72 |
| Improvement | ‚â• 5% vs baseline |

### Maintenance Operations

```bash
# Verificar status de modelos
ml_pipelines/scripts/check_model_status.sh --all

# Re-treinar especialista espec√≠fico
ml_pipelines/scripts/retrain_specialist.sh --specialist technical

# Fazer rollback de modelo
ml_pipelines/scripts/rollback_model.sh --specialist technical \
  --reason "High latency in production"

# An√°lise explorat√≥ria (Jupyter)
cd ml_pipelines/notebooks
jupyter notebook model_analysis.ipynb
```

### MLflow Access

- **URL**: `http://mlflow.mlflow:5000`
- **Port-forward**: `kubectl port-forward -n mlflow svc/mlflow 5000:5000`
- **UI**: `http://localhost:5000`

### Integration with Specialists

Os especialistas carregam modelos em runtime via `mlflow_client.py`:
- Circuit breaker e fallback para cache expirado
- Health checks: `/status` endpoint mostra `model_loaded: true`
- Namespace: `semantic-translation`
- Restart para for√ßar reload: `kubectl rollout restart deployment/specialist-{type} -n semantic-translation`

### Troubleshooting

| Problema | Diagn√≥stico | Solu√ß√£o |
|----------|-------------|---------|
| MLflow n√£o conectado | `curl -f http://mlflow.mlflow:5000/health` | `kubectl rollout restart deployment/mlflow -n mlflow` |
| Modelo n√£o carregado | `/status` retorna `model_loaded: false` | `kubectl rollout restart deployment/specialist-{type}` |
| Specialist NOT READY | Ver `/tmp/ANALISE_SPECIALIST_TECHNICAL.md` | Verificar liveness probes, MongoDB, model loading |
| Datasets ausentes | `FileNotFoundError` no treinamento | `cd ml_pipelines/training && ./generate_all_datasets.sh` |

### Documentation

Para documenta√ß√£o completa do pipeline ML:

üìñ **[ML Pipeline README](ml_pipelines/README.md)**
üìñ **[Dataset Generation Guide](ml_pipelines/training/README_DATASET_GENERATION.md)**
üìñ **[Continuous Learning Guide](CONTINUOUS_LEARNING_GUIDE.md)**

## üìä Business Metrics & Anomaly Detection

O Neural Hive Mind rastreia **m√©tricas de impacto de neg√≥cio** que correlacionam opini√µes de especialistas com decis√µes finais do consenso:

### M√©tricas Dispon√≠veis

- **Concord√¢ncia com Consenso**: Taxa de vezes que especialista concordou com decis√£o final
- **False Positive Rate**: Taxa de aprova√ß√µes incorretas (especialista aprovou mas consenso rejeitou)
- **False Negative Rate**: Taxa de rejei√ß√µes incorretas (especialista rejeitou mas consenso aprovou)
- **Precision/Recall/F1**: M√©tricas de qualidade p√≥s-consenso
- **Valor de Neg√≥cio**: Planos aprovados que foram executados com sucesso

### Anomaly Detection

Detec√ß√£o autom√°tica de comportamentos an√¥malos usando **Isolation Forest**:
- Treinado em m√©tricas hist√≥ricas (30 dias)
- Detecta desvios significativos em tempo real
- Gera alertas inteligentes no Alertmanager

### Quick Start

1. **Configurar vari√°veis de ambiente:**
   ```bash
   export ENABLE_BUSINESS_METRICS=true
   export CONSENSUS_MONGODB_URI=mongodb://consensus-engine:27017
   ```

2. **Deploy CronJob:**
   ```bash
   make deploy-business-metrics-cronjob
   ```

3. **Treinar modelo de anomaly detection:**
   ```bash
   make anomaly-detector-train
   ```

4. **Visualizar m√©tricas:**
   ```bash
   make view-business-metrics
   ```

### Dashboards

- **Grafana**: `monitoring/dashboards/business-metrics-dashboard.json`
- **M√©tricas Prometheus**: `neural_hive_business_*`

### Scripts Utilit√°rios

```bash
# Executar coleta de business metrics manualmente
make business-metrics-collect

# Modo dry-run (sem atualizar m√©tricas)
make business-metrics-collect-dry-run

# Treinar modelo de anomaly detection
make anomaly-detector-train

# Executar testes de business metrics
make test-business-metrics
```

### M√©tricas Prometheus

M√©tricas de business dispon√≠veis:

- `neural_hive_business_consensus_agreement_rate` - Taxa de concord√¢ncia com consenso
- `neural_hive_business_false_positive_rate` - Taxa de falsos positivos
- `neural_hive_business_false_negative_rate` - Taxa de falsos negativos
- `neural_hive_business_precision_score` - Precision p√≥s-consenso
- `neural_hive_business_recall_score` - Recall p√≥s-consenso
- `neural_hive_business_f1_score` - F1-score p√≥s-consenso
- `neural_hive_business_value_generated_total` - Valor de neg√≥cio gerado
- `neural_hive_anomaly_detected_total` - Anomalias detectadas em m√©tricas

### Alertas Configurados

- `LowConsensusAgreementRate` - Agreement < 70%
- `HighFalsePositiveRate` - FP > 20%
- `LowPrecisionScore` - Precision < 0.7
- `MetricsAnomalyDetected` - Anomalia detectada pelo Isolation Forest

### Arquitetura

```mermaid
sequenceDiagram
    participant S as Specialists
    participant L as Ledger (MongoDB)
    participant CE as Consensus Engine
    participant BMC as BusinessMetricsCollector
    participant AD as AnomalyDetector
    participant P as Prometheus
    participant AM as Alertmanager

    S->>L: save_opinion(opinion)
    S->>CE: Enviar opini√µes
    CE->>CE: process_consensus()
    CE->>L: save_decision(decision)

    BMC->>L: fetch_opinions(24h)
    BMC->>CE: fetch_consensus_decisions(24h)
    BMC->>BMC: correlate_via_opinion_id()
    BMC->>BMC: calculate_metrics()

    BMC->>AD: detect_anomalies(metrics)
    AD-->>BMC: is_anomaly, severity

    BMC->>P: update_business_metrics()
    P->>AM: Avaliar regras de alerta
    AM->>AM: Disparar alertas
```

### Documenta√ß√£o Adicional

- [BusinessMetricsCollector](libraries/python/neural_hive_specialists/observability/business_metrics_collector.py)
- [AnomalyDetector](libraries/python/neural_hive_specialists/observability/anomaly_detector.py)
- [Scripts](libraries/python/neural_hive_specialists/scripts/)
- [CronJob Kubernetes](k8s/cronjobs/business-metrics-collector-job.yaml)
- [Alertas](monitoring/alerts/business-metrics-alerts.yaml)

## ü§ù Contribui√ß√£o

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

### Padr√µes de Commit
```
feat: nova funcionalidade
fix: corre√ß√£o de bug
docs: atualiza√ß√£o de documenta√ß√£o
style: formata√ß√£o de c√≥digo
refactor: refatora√ß√£o sem mudan√ßa de funcionalidade
test: adi√ß√£o/corre√ß√£o de testes
chore: mudan√ßas de build/CI
```

## üìÑ Licen√ßa

Este projeto √© licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üîó Links √öteis

- **AWS EKS Documentation**: https://docs.aws.amazon.com/eks/
- **Istio Documentation**: https://istio.io/latest/docs/
- **OPA Gatekeeper**: https://open-policy-agent.github.io/gatekeeper/
- **Terraform AWS Provider**: https://registry.terraform.io/providers/hashicorp/aws/

---

ü§ñ **Neural Hive-Mind Phase 1 - Foundation Layer**
*Construindo a base para intelig√™ncia artificial distribu√≠da*

## Makefile v2.0 Quick Start
- List categories: `make help`
- Build: `make build-local` | Deploy: `make deploy-local` or `make deploy-eks`
- Tests: `make test` (or component-specific like `make test-phase2`)
- Validation: `make validate` | Security: `make security-validate`
- Observability: `make observability-dashboards` | ML: `make ml-train SPECIALIST_TYPE=<type>`

### Unified CLIs
- `./scripts/observability.sh` ‚Äî dashboards, validation, SLO/correlation tests
- `./scripts/setup.sh` ‚Äî minikube, eks (`--auto`), backend setup
- `./scripts/maintenance.sh` ‚Äî backup/restore, cluster tasks, cost optimization, DR status

See `docs/MAKEFILE_MIGRATION.md` for migration details and deprecated commands.

## ‚ö†Ô∏è Scripts Deprecated
Os seguintes scripts foram consolidados nos CLIs unificados e ser√£o removidos na vers√£o 2.0.0:
- Scripts de build na raiz ‚Üí `./scripts/build.sh`
- Scripts de deploy individuais ‚Üí `./scripts/deploy.sh`
- Scripts de teste na raiz ‚Üí `./tests/run-tests.sh`
- Scripts de valida√ß√£o dispersos ‚Üí `./scripts/validate.sh`
- Scripts de seguran√ßa dispersos ‚Üí `./scripts/security.sh`
- Scripts de ML dispersos ‚Üí `./ml_pipelines/ml.sh`

Per√≠odo de transi√ß√£o: 3 meses (at√© vers√£o 2.0.0). Consulte [docs/scripts/MIGRATION_GUIDE.md](docs/scripts/MIGRATION_GUIDE.md) para migra√ß√£o.
