# Fluxo Completo do Neural Hive-Mind - Detalhamento Passo a Passo

> **Vers√£o**: 1.0.0
> **√öltima Atualiza√ß√£o**: Janeiro 2026
> **P√∫blico-Alvo**: Desenvolvedores, Arquitetos, DevOps

---

## Sum√°rio

1. [Sum√°rio Executivo](#sum√°rio-executivo)
2. [Vis√£o Geral da Arquitetura](#-vis√£o-geral-da-arquitetura)
3. [FLUXO A: Captura e Normaliza√ß√£o de Inten√ß√µes](#-fluxo-a-captura-e-normaliza√ß√£o-de-inten√ß√µes)
4. [FLUXO B: Gera√ß√£o de Planos Cognitivos](#-fluxo-b-gera√ß√£o-de-planos-cognitivos)
5. [FLUXO DE CONSENSO: Avalia√ß√£o Multi-Especialista](#-fluxo-de-consenso-avalia√ß√£o-multi-especialista)
6. [FLUXO C: Orquestra√ß√£o Din√¢mica de Execu√ß√£o](#-fluxo-c-orquestra√ß√£o-din√¢mica-de-execu√ß√£o)
7. [FLUXO D: Observabilidade Hol√≠stica](#-fluxo-d-observabilidade-hol√≠stica)
8. [FLUXO E: Autocura e Resolu√ß√£o Proativa](#-fluxo-e-autocura-e-resolu√ß√£o-proativa)
9. [FLUXO F: Gest√£o de Experimentos](#-fluxo-f-gest√£o-de-experimentos)
10. [Seguran√ßa e Governan√ßa](#-seguran√ßa-e-governan√ßa)
11. [M√©tricas Globais do Sistema](#-m√©tricas-globais-do-sistema)
12. [Fluxo Completo Resumido](#-fluxo-completo-resumido)
13. [Pr√≥ximos Passos e Evolu√ß√£o](#-pr√≥ximos-passos-e-evolu√ß√£o)
14. [Refer√™ncias de Documenta√ß√£o](#-refer√™ncias-de-documenta√ß√£o)
15. [Conceitos-Chave](#-conceitos-chave)
16. [Diferenciais da Arquitetura](#-diferenciais-da-arquitetura)

---

## Sum√°rio Executivo

O **Neural Hive-Mind** √© um sistema de intelig√™ncia coletiva que transforma inten√ß√µes humanas em a√ß√µes execut√°veis atrav√©s de um processo multi-etapas envolvendo captura sem√¢ntica, planejamento cognitivo, consenso entre especialistas neurais, orquestra√ß√£o din√¢mica e observabilidade completa.

**Caracter√≠sticas Principais:**
- **6 Fluxos Operacionais** integrados (A-F)
- **5 Especialistas Neurais** colaborando via consenso bayesiano
- **Lat√™ncia E2E P95** < 2 segundos
- **Disponibilidade** > 99.9%
- **Autocura** com MTTR < 90 segundos

---

## üìã Vis√£o Geral da Arquitetura

### Diagrama de Intera√ß√£o entre Componentes

```mermaid
sequenceDiagram
    autonumber
    participant U as üë§ Usu√°rio
    participant GW as üö™ Gateway de Inten√ß√µes
    participant SE as üß† Semantic Engine
    participant SP as üë• 5 Especialistas
    participant CE as ‚öñÔ∏è Consensus Engine
    participant OD as üéØ Orchestrator Dynamic
    participant ML as üíæ Memory Layer
    participant K as üì® Kafka

    U->>GW: Intent (texto/voz)
    GW->>GW: Valida√ß√£o + NLU
    GW->>K: Intent Envelope
    K->>SE: Consume Intent
    SE->>ML: Enriquecer Contexto
    ML-->>SE: Hist√≥rico + Prefer√™ncias
    SE->>SE: Gerar DAG de Tarefas
    SE->>K: Cognitive Plan
    K->>CE: Consume Plan
    CE->>SP: Consulta Paralela (gRPC)
    SP-->>CE: 5 Opini√µes Estruturadas
    CE->>CE: Agrega√ß√£o Bayesiana
    CE->>K: Consolidated Decision
    K->>OD: Consume Decision
    OD->>OD: Workflow Temporal
    OD->>ML: Persistir Resultados
    OD->>U: Resultado Final
```

### Tabela de Componentes Principais

| Componente | Porta | Tecnologia | Responsabilidade |
|------------|-------|------------|------------------|
| Gateway de Inten√ß√µes | 8080 | FastAPI, Redis, Kafka | Captura e normaliza√ß√£o de inten√ß√µes |
| Semantic Translation Engine | 8081 | FastAPI, Neo4j, MongoDB | Gera√ß√£o de planos cognitivos |
| Consensus Engine | 8082 | FastAPI, gRPC, Redis | Agrega√ß√£o de opini√µes e consenso |
| Orchestrator Dynamic | 8083 | FastAPI, Temporal | Execu√ß√£o orquestrada de tarefas |
| Memory Layer API | 8084 | FastAPI, Multi-DB | Persist√™ncia e consulta unificada |
| Specialist Architecture | 50051 | gRPC, Python | Avalia√ß√£o arquitetural |
| Specialist Technical | 50052 | gRPC, Python | Viabilidade t√©cnica |
| Specialist Business | 50053 | gRPC, Python | Valor de neg√≥cio |
| Specialist Behavior | 50054 | gRPC, Python | UX e usabilidade |
| Specialist Evolution | 50055 | gRPC, Python | Manutenibilidade |

### Refer√™ncias de C√≥digo

- `services/gateway-intencoes/` - Gateway de Inten√ß√µes
- `services/semantic-translation-engine/` - Semantic Engine
- `services/consensus-engine/` - Consensus Engine
- `services/orchestrator-dynamic/` - Orchestrator Dynamic
- `services/memory-layer-api/` - Memory Layer
- `services/specialist-architecture/` - Especialista de Arquitetura
- `services/specialist-technical/` - Especialista T√©cnico
- `services/specialist-business/` - Especialista de Neg√≥cios
- `services/specialist-behavior/` - Especialista de Comportamento
- `services/specialist-evolution/` - Especialista de Evolu√ß√£o

---

## üîÑ FLUXO A: Captura e Normaliza√ß√£o de Inten√ß√µes

### A1: Vis√£o Geral

O Fluxo A √© respons√°vel por receber inten√ß√µes humanas de m√∫ltiplos canais, process√°-las linguisticamente e public√°-las no barramento de eventos de forma normalizada.

**Servi√ßo Principal**: `services/gateway-intencoes/src/main.py`
**Porta**: 8080 (HTTP/REST)
**Tecnologias**: FastAPI, Redis, Kafka Producer

### A2: Diagrama do Fluxo

```mermaid
flowchart LR
    subgraph Entrada
        A1[üì± API REST] --> V
        A2[üé§ Voz/ASR] --> V
        A3[üí¨ Chat] --> V
    end

    subgraph Processamento
        V[Valida√ß√£o OAuth2 + mTLS] --> R[Rate Limiting]
        R --> NLU[Pipeline NLU]
        NLU --> PII[Detec√ß√£o PII]
        PII --> ENV[Constru√ß√£o Envelope]
    end

    subgraph Roteamento
        ENV --> D{Confidence?}
        D -->|‚â•0.85| H[intentions.high-confidence]
        D -->|0.70-0.84| M[intentions.medium-confidence]
        D -->|0.50-0.69| L[intentions.low-confidence]
        D -->|<0.50| VR[intentions.validation-required]
    end

    subgraph Persist√™ncia
        H --> K[Kafka]
        M --> K
        L --> K
        VR --> K
        ENV --> C[(Redis Cache)]
        ENV --> AU[üìã Audit Log]
    end
```

### A3: Etapas Detalhadas

#### A3.1: Recep√ß√£o Multicanal

**Endpoints:**
- `POST /intentions` - Recebe inten√ß√µes em texto
- `POST /intentions/voice` - Recebe √°udio para processamento ASR

**Middleware de Seguran√ßa:**
- `services/gateway-intencoes/src/middleware/auth_middleware.py` - Autentica√ß√£o OAuth2 + mTLS
- `services/gateway-intencoes/src/middleware/rate_limiter.py` - Limita√ß√£o de taxa por tenant

**Exemplo de Request:**
```json
{
  "content": "Quero criar um novo microservi√ßo de pagamentos com integra√ß√£o Stripe",
  "channel": "api",
  "user_id": "usr_12345",
  "session_id": "sess_abc123",
  "locale": "pt-BR",
  "metadata": {
    "client_version": "2.1.0",
    "platform": "web"
  }
}
```

#### A3.2: Pr√©-processamento Lingu√≠stico

**Pipelines:**
- `services/gateway-intencoes/src/pipelines/nlu_pipeline.py` - Processamento de Linguagem Natural
- `services/gateway-intencoes/src/pipelines/asr_pipeline.py` - Reconhecimento Autom√°tico de Fala

**Etapas do NLU Pipeline:**
1. Detec√ß√£o de idioma (langdetect)
2. Tokeniza√ß√£o e normaliza√ß√£o
3. Extra√ß√£o de entidades (NER)
4. Classifica√ß√£o de inten√ß√£o
5. An√°lise de sentimento
6. Detec√ß√£o e mascaramento de PII

#### A3.3: Constru√ß√£o do Intent Envelope

**Modelo**: `services/gateway-intencoes/src/models/intent_envelope.py`

**Exemplo de Intent Envelope Completo:**
```json
{
  "intent_id": "int_7f8a9b2c-4d5e-6f7a-8b9c-0d1e2f3a4b5c",
  "correlation_id": "corr_1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d",
  "timestamp": "2026-01-15T14:30:00.000Z",
  "version": "1.0.0",
  "intent": {
    "raw_content": "Quero criar um novo microservi√ßo de pagamentos com integra√ß√£o Stripe",
    "normalized_content": "criar microservi√ßo pagamentos integra√ß√£o stripe",
    "detected_language": "pt-BR",
    "intent_type": "CREATE_SERVICE",
    "entities": [
      {"type": "SERVICE_TYPE", "value": "microservi√ßo", "confidence": 0.95},
      {"type": "DOMAIN", "value": "pagamentos", "confidence": 0.92},
      {"type": "INTEGRATION", "value": "Stripe", "confidence": 0.98}
    ],
    "sentiment": "neutral",
    "urgency": "normal"
  },
  "confidence": {
    "overall": 0.89,
    "intent_classification": 0.92,
    "entity_extraction": 0.87,
    "language_detection": 0.99
  },
  "user": {
    "user_id": "usr_12345",
    "tenant_id": "tenant_acme",
    "session_id": "sess_abc123",
    "roles": ["developer", "team_lead"],
    "preferences": {
      "notification_channel": "slack",
      "language": "pt-BR"
    }
  },
  "constraints": {
    "max_execution_time_ms": 300000,
    "priority": "normal",
    "requires_approval": false,
    "budget_limit_usd": 1000
  },
  "trace_context": {
    "trace_id": "trace_abc123def456",
    "span_id": "span_001",
    "parent_span_id": null,
    "baggage": {
      "environment": "production",
      "region": "us-east-1"
    }
  },
  "security": {
    "pii_detected": false,
    "pii_masked": false,
    "classification": "internal",
    "audit_hash": "sha512:abc123..."
  }
}
```

#### A3.4: Publica√ß√£o no Kafka

**Producer**: `services/gateway-intencoes/src/kafka/producer.py`

**T√≥picos por Confian√ßa:**
| T√≥pico | Crit√©rio | A√ß√£o Subsequente |
|--------|----------|------------------|
| `intentions.high-confidence` | confidence ‚â• 0.85 | Processamento direto |
| `intentions.medium-confidence` | 0.70 ‚â§ confidence < 0.85 | Enriquecimento adicional |
| `intentions.low-confidence` | 0.50 ‚â§ confidence < 0.70 | Clarifica√ß√£o opcional |
| `intentions.validation-required` | confidence < 0.50 | Interven√ß√£o humana |

**Garantias de Entrega:**
- Exactly-once semantics via transa√ß√µes Kafka
- Ordena√ß√£o garantida por partition key (user_id)
- Schema validation via Apicurio Schema Registry

#### A3.5: Cache e Auditoria

**Redis Client**: `services/gateway-intencoes/src/cache/redis_client.py`

**Estrat√©gia de Cache:**
- Chave: `intent:{intent_id}`
- TTL: 3600 segundos (1 hora)
- Prop√≥sito: Idempot√™ncia e consulta r√°pida

**Auditoria:**
- Log estruturado com hash SHA-512 do envelope
- Campos auditados: timestamp, user_id, intent_type, confidence, source_ip

### A4: M√©tricas do Fluxo A

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `gateway_latency_p95` | < 200ms | Lat√™ncia de processamento |
| `gateway_rejection_rate` | < 2% | Taxa de rejei√ß√£o por valida√ß√£o |
| `gateway_audit_coverage` | 100% | Cobertura de auditoria |
| `gateway_pii_detection_rate` | > 99% | Detec√ß√£o de dados sens√≠veis |

---

## üß© FLUXO B: Gera√ß√£o de Planos Cognitivos

### B1: Vis√£o Geral

O Fluxo B transforma Intent Envelopes em Planos Cognitivos estruturados (DAGs de tarefas) com avalia√ß√£o de risco e explicabilidade.

**Servi√ßo Principal**: `services/semantic-translation-engine/src/main.py`
**Orquestrador**: `services/semantic-translation-engine/src/services/orchestrator.py`
**Tecnologias**: FastAPI, Neo4j, MongoDB, Redis, Kafka

### B2: Diagrama do Fluxo

```mermaid
sequenceDiagram
    autonumber
    participant K as üì® Kafka
    participant SE as üß† Semantic Engine
    participant Neo as üîó Neo4j
    participant Mongo as üìÑ MongoDB
    participant Redis as ‚ö° Redis

    K->>SE: Intent Envelope
    SE->>SE: Validar Assinatura
    SE->>Redis: Verificar Idempot√™ncia
    Redis-->>SE: N√£o Processado

    SE->>Neo: Buscar Inten√ß√µes Similares
    Neo-->>SE: Hist√≥rico de Planos
    SE->>Mongo: Buscar Contexto de Sess√£o
    Mongo-->>SE: Prefer√™ncias do Usu√°rio
    SE->>Redis: Buscar Cache de Entidades
    Redis-->>SE: Entidades Enriquecidas

    SE->>SE: Decompor em DAG
    SE->>SE: Avaliar Risco
    SE->>SE: Gerar Explicabilidade
    SE->>SE: Versionar Plano

    SE->>Mongo: Persistir Plano (Ledger)
    SE->>Neo: Persistir Grafo de Tarefas
    SE->>K: Publicar Cognitive Plan
```

### B3: Etapas Detalhadas

#### B3.1: Receber e Validar Intent Envelope

**Consumer**: `services/semantic-translation-engine/src/consumers/intent_consumer.py`

**Valida√ß√µes:**
1. Verifica√ß√£o de assinatura do envelope
2. Verifica√ß√£o de idempot√™ncia via Redis
3. Extra√ß√£o de trace context (OpenTelemetry)
4. Valida√ß√£o de schema Avro

#### B3.2: Enriquecer Contexto

**Componentes de Enriquecimento:**
- `services/semantic-translation-engine/src/services/semantic_parser.py` - Parser sem√¢ntico
- `services/semantic-translation-engine/src/clients/neo4j_client.py` - Cliente Neo4j
- `services/semantic-translation-engine/src/clients/mongodb_client.py` - Cliente MongoDB
- `services/semantic-translation-engine/src/clients/redis_client.py` - Cliente Redis

**Fontes de Contexto:**
| Fonte | Dados | Lat√™ncia |
|-------|-------|----------|
| Neo4j | Inten√ß√µes similares, grafo de relacionamentos | < 50ms |
| MongoDB | Hist√≥rico de sess√£o, prefer√™ncias | < 30ms |
| Redis | Cache de entidades, contexto recente | < 5ms |

#### B3.3: Decompor em DAG de Tarefas

**DAG Generator**: `services/semantic-translation-engine/src/services/dag_generator.py`

**Processo de Decomposi√ß√£o:**
1. An√°lise sint√°tica da inten√ß√£o
2. Identifica√ß√£o de sub-objetivos
3. Gera√ß√£o de n√≥s de tarefa
4. Estabelecimento de depend√™ncias
5. Ordena√ß√£o topol√≥gica
6. Valida√ß√£o de ciclos

**Estrutura TaskNode:**
```json
{
  "task_id": "task_001",
  "task_type": "CREATE_SERVICE",
  "description": "Criar estrutura base do microservi√ßo de pagamentos",
  "dependencies": [],
  "estimated_duration_ms": 30000,
  "required_capabilities": ["code_generation", "docker"],
  "parameters": {
    "service_name": "payment-service",
    "framework": "fastapi",
    "database": "postgresql"
  },
  "retry_policy": {
    "max_attempts": 3,
    "backoff_multiplier": 2.0
  }
}
```

#### B3.4: Avaliar Risco

**Risk Scorer**: `services/semantic-translation-engine/src/services/risk_scorer.py`

**Fatores de Risco:**
| Fator | Peso | Descri√ß√£o |
|-------|------|-----------|
| `complexity` | 0.25 | N√∫mero de tarefas e depend√™ncias |
| `security_impact` | 0.30 | Acesso a dados sens√≠veis |
| `blast_radius` | 0.20 | Servi√ßos afetados |
| `novelty` | 0.15 | Similaridade com execu√ß√µes anteriores |
| `user_experience` | 0.10 | Impacto na experi√™ncia do usu√°rio |

**Classifica√ß√£o de Risco:**
| Band | Score Range | A√ß√£o |
|------|-------------|------|
| `low` | 0.0 - 0.3 | Execu√ß√£o autom√°tica |
| `medium` | 0.3 - 0.6 | Consenso padr√£o |
| `high` | 0.6 - 0.8 | Consenso refor√ßado |
| `critical` | 0.8 - 1.0 | Aprova√ß√£o humana obrigat√≥ria |

#### B3.5: Gerar Explicabilidade

**Explainability Generator**: `services/semantic-translation-engine/src/services/explainability_generator.py`

**Sa√≠da:**
```json
{
  "explainability_token": "exp_abc123",
  "reasoning_summary": "Plano gerado com 5 tarefas sequenciais para criar microservi√ßo de pagamentos. Risco m√©dio devido √† integra√ß√£o externa com Stripe.",
  "key_decisions": [
    "Framework FastAPI selecionado por compatibilidade com stack existente",
    "PostgreSQL escolhido para persist√™ncia transacional",
    "Integra√ß√£o Stripe via SDK oficial"
  ],
  "confidence_factors": [
    {"factor": "intent_clarity", "score": 0.92},
    {"factor": "historical_success", "score": 0.85},
    {"factor": "resource_availability", "score": 0.90}
  ]
}
```

#### B3.6: Versionar e Publicar Plano

**Modelo**: `services/semantic-translation-engine/src/models/cognitive_plan.py`
**Schema Avro**: `schemas/cognitive-plan/cognitive-plan.avsc`

**Exemplo de Cognitive Plan Completo:**
```json
{
  "plan_id": "plan_9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d",
  "intent_id": "int_7f8a9b2c-4d5e-6f7a-8b9c-0d1e2f3a4b5c",
  "correlation_id": "corr_1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d",
  "version": "1.0.0",
  "created_at": "2026-01-15T14:30:05.000Z",
  "status": "PENDING_CONSENSUS",
  "intent_summary": {
    "original": "Criar microservi√ßo de pagamentos com integra√ß√£o Stripe",
    "interpreted": "Provisionar novo microservi√ßo para processamento de pagamentos utilizando gateway Stripe"
  },
  "task_dag": {
    "nodes": [
      {
        "task_id": "task_001",
        "task_type": "SCAFFOLD_SERVICE",
        "description": "Gerar estrutura base do servi√ßo",
        "dependencies": [],
        "estimated_duration_ms": 15000
      },
      {
        "task_id": "task_002",
        "task_type": "CONFIGURE_DATABASE",
        "description": "Configurar PostgreSQL e migrations",
        "dependencies": ["task_001"],
        "estimated_duration_ms": 20000
      },
      {
        "task_id": "task_003",
        "task_type": "INTEGRATE_STRIPE",
        "description": "Implementar integra√ß√£o com Stripe SDK",
        "dependencies": ["task_001"],
        "estimated_duration_ms": 45000
      },
      {
        "task_id": "task_004",
        "task_type": "CREATE_API_ENDPOINTS",
        "description": "Criar endpoints REST para pagamentos",
        "dependencies": ["task_002", "task_003"],
        "estimated_duration_ms": 30000
      },
      {
        "task_id": "task_005",
        "task_type": "DEPLOY_SERVICE",
        "description": "Deploy em ambiente de staging",
        "dependencies": ["task_004"],
        "estimated_duration_ms": 60000
      }
    ],
    "edges": [
      {"from": "task_001", "to": "task_002"},
      {"from": "task_001", "to": "task_003"},
      {"from": "task_002", "to": "task_004"},
      {"from": "task_003", "to": "task_004"},
      {"from": "task_004", "to": "task_005"}
    ],
    "critical_path": ["task_001", "task_003", "task_004", "task_005"],
    "total_estimated_duration_ms": 150000
  },
  "risk_assessment": {
    "risk_score": 0.45,
    "risk_band": "medium",
    "factors": {
      "complexity": 0.40,
      "security_impact": 0.60,
      "blast_radius": 0.30,
      "novelty": 0.50,
      "user_experience": 0.20
    },
    "mitigations": [
      "Utilizar sandbox Stripe para testes",
      "Implementar circuit breaker para chamadas externas",
      "Habilitar feature flag para rollback r√°pido"
    ]
  },
  "explainability": {
    "token": "exp_abc123",
    "reasoning_summary": "Plano estruturado em 5 tarefas com caminho cr√≠tico de 150s",
    "confidence": 0.87
  },
  "context": {
    "similar_plans_count": 12,
    "avg_historical_success_rate": 0.94,
    "user_preference_alignment": 0.91
  },
  "trace_context": {
    "trace_id": "trace_abc123def456",
    "span_id": "span_002"
  }
}
```

**Persist√™ncia:**
- MongoDB: Ledger imut√°vel com versionamento
- Neo4j: Grafo de relacionamentos entre tarefas

**Producer**: `services/semantic-translation-engine/src/producers/plan_producer.py`
**T√≥pico Kafka**: `cognitive-plans.ready`

### B4: M√©tricas do Fluxo B

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `semantic_latency_p95` | < 120ms | Lat√™ncia de gera√ß√£o de plano |
| `semantic_fallback_rate` | < 3% | Taxa de fallback heur√≠stico |
| `semantic_explainability_coverage` | 100% | Cobertura de explicabilidade |
| `semantic_dag_validation_success` | > 99% | Valida√ß√£o de DAGs gerados |

---

## ü§ù FLUXO DE CONSENSO: Avalia√ß√£o Multi-Especialista

### C1: Vis√£o Geral

O Fluxo de Consenso orquestra a avalia√ß√£o colaborativa de Planos Cognitivos por 5 especialistas neurais, agregando opini√µes via m√©todo bayesiano e sistema de ferom√¥nios.

**Servi√ßo Principal**: `services/consensus-engine/src/main.py`
**Orquestrador**: `services/consensus-engine/src/services/consensus_orchestrator.py`
**Tecnologias**: FastAPI, gRPC, Redis, Kafka

### C2: Os 5 Especialistas Neurais

```mermaid
graph TB
    subgraph Especialistas
        A[üèõÔ∏è Architecture<br/>Padr√µes e Escalabilidade]
        T[‚öôÔ∏è Technical<br/>Viabilidade T√©cnica]
        B[üíº Business<br/>Valor de Neg√≥cio]
        H[üë§ Behavior<br/>UX e Usabilidade]
        E[üîÑ Evolution<br/>Manutenibilidade]
    end

    P[üìã Cognitive Plan] --> A
    P --> T
    P --> B
    P --> H
    P --> E

    A --> C[‚öñÔ∏è Consensus Engine]
    T --> C
    B --> C
    H --> C
    E --> C

    C --> D[‚úÖ Consolidated Decision]
```

**Tabela de Especialistas:**

| Especialista | Servi√ßo | Porta gRPC | Foco Principal | Crit√©rios de Avalia√ß√£o |
|--------------|---------|------------|----------------|------------------------|
| Architecture | `services/specialist-architecture/` | 50051 | Padr√µes arquiteturais | Estrutura, acoplamento, coes√£o, escalabilidade |
| Technical | `services/specialist-technical/` | 50052 | Viabilidade t√©cnica | Stack, APIs, integra√ß√µes, performance |
| Business | `services/specialist-business/` | 50053 | Valor de neg√≥cio | ROI, impacto, custos, benef√≠cios |
| Behavior | `services/specialist-behavior/` | 50054 | Experi√™ncia do usu√°rio | Fluxos, acessibilidade, usabilidade |
| Evolution | `services/specialist-evolution/` | 50055 | Evolu√ß√£o do sistema | Testabilidade, documenta√ß√£o, manuten√ß√£o |

### C3: Diagrama do Fluxo de Consenso

```mermaid
sequenceDiagram
    autonumber
    participant K as üì® Kafka
    participant CE as ‚öñÔ∏è Consensus Engine
    participant SA as üèõÔ∏è Arch Specialist
    participant ST as ‚öôÔ∏è Tech Specialist
    participant SB as üíº Biz Specialist
    participant SH as üë§ Behavior Specialist
    participant SE as üîÑ Evolution Specialist
    participant R as ‚ö° Redis (Ferom√¥nios)

    K->>CE: Cognitive Plan
    CE->>R: Buscar Pesos de Ferom√¥nios
    R-->>CE: Pesos por Especialista

    par Consulta Paralela
        CE->>SA: EvaluatePlan(plan)
        CE->>ST: EvaluatePlan(plan)
        CE->>SB: EvaluatePlan(plan)
        CE->>SH: EvaluatePlan(plan)
        CE->>SE: EvaluatePlan(plan)
    end

    SA-->>CE: SpecialistOpinion
    ST-->>CE: SpecialistOpinion
    SB-->>CE: SpecialistOpinion
    SH-->>CE: SpecialistOpinion
    SE-->>CE: SpecialistOpinion

    CE->>CE: Agrega√ß√£o Bayesiana
    CE->>CE: Voting Ensemble
    CE->>CE: Compliance Check
    CE->>R: Atualizar Ferom√¥nios
    CE->>K: Consolidated Decision
```

### C4: Etapas Detalhadas

#### C4.1: Consumir Cognitive Plan

**Consumer**: `services/consensus-engine/src/consumers/plan_consumer.py`

**Processo:**
1. Deserializa√ß√£o Avro do plano
2. Extra√ß√£o de trace context
3. Valida√ß√£o de integridade
4. In√≠cio de span de consenso

#### C4.2: Consultar Especialistas via gRPC

**Cliente gRPC**: `services/consensus-engine/src/clients/specialists_grpc_client.py`
**Protocolo**: `schemas/specialist-opinion/specialist.proto`

**Defini√ß√£o Protobuf:**
```protobuf
syntax = "proto3";

package specialist;

service SpecialistService {
  rpc EvaluatePlan(EvaluatePlanRequest) returns (EvaluatePlanResponse);
  rpc GetHealth(HealthRequest) returns (HealthResponse);
}

message EvaluatePlanRequest {
  string plan_id = 1;
  string plan_json = 2;
  map<string, string> context = 3;
  string trace_id = 4;
}

message EvaluatePlanResponse {
  string opinion_id = 1;
  string specialist_type = 2;
  double confidence_score = 3;
  double risk_score = 4;
  Recommendation recommendation = 5;
  string reasoning_summary = 6;
  repeated ReasoningFactor reasoning_factors = 7;
  string explainability_token = 8;
  repeated Mitigation mitigations = 9;
  int64 evaluation_duration_ms = 10;
}

enum Recommendation {
  APPROVE = 0;
  REJECT = 1;
  CONDITIONAL = 2;
  REVIEW_REQUIRED = 3;
}

message ReasoningFactor {
  string factor_name = 1;
  double weight = 2;
  double score = 3;
  string explanation = 4;
}

message Mitigation {
  string risk_type = 1;
  string mitigation_action = 2;
  string priority = 3;
}
```

**Chamada Paralela:**
```python
async def consult_specialists(self, plan: CognitivePlan) -> List[SpecialistOpinion]:
    tasks = [
        self._call_specialist(SpecialistType.ARCHITECTURE, plan),
        self._call_specialist(SpecialistType.TECHNICAL, plan),
        self._call_specialist(SpecialistType.BUSINESS, plan),
        self._call_specialist(SpecialistType.BEHAVIOR, plan),
        self._call_specialist(SpecialistType.EVOLUTION, plan),
    ]
    return await asyncio.gather(*tasks, return_exceptions=True)
```

#### C4.3: Exemplo de Specialist Opinion

```json
{
  "opinion_id": "op_arch_123",
  "specialist_type": "ARCHITECTURE",
  "confidence_score": 0.85,
  "risk_score": 0.35,
  "recommendation": "APPROVE",
  "reasoning_summary": "Arquitetura proposta segue padr√µes de microservi√ßos estabelecidos com baixo acoplamento",
  "reasoning_factors": [
    {
      "factor_name": "service_isolation",
      "weight": 0.30,
      "score": 0.90,
      "explanation": "Servi√ßo bem isolado com responsabilidade √∫nica"
    },
    {
      "factor_name": "scalability",
      "weight": 0.25,
      "score": 0.85,
      "explanation": "Design permite escala horizontal"
    },
    {
      "factor_name": "coupling",
      "weight": 0.25,
      "score": 0.80,
      "explanation": "Acoplamento baixo via APIs REST"
    },
    {
      "factor_name": "cohesion",
      "weight": 0.20,
      "score": 0.88,
      "explanation": "Alta coes√£o funcional no dom√≠nio de pagamentos"
    }
  ],
  "explainability_token": "exp_arch_456",
  "mitigations": [
    {
      "risk_type": "external_dependency",
      "mitigation_action": "Implementar circuit breaker para Stripe API",
      "priority": "HIGH"
    }
  ],
  "evaluation_duration_ms": 45
}
```

#### C4.4: Sistema de Ferom√¥nios

**Cliente de Ferom√¥nios**: `services/consensus-engine/src/clients/pheromone_client.py`

**Conceito:**
Inspirado em col√¥nias de formigas, especialistas que historicamente acertam mais recebem maior peso nas decis√µes futuras.

**Estrutura Redis:**
- Chave: `pheromone:{specialist_type}:{domain}`
- Valor: Score acumulado (0.0 - 1.0)
- TTL: 7 dias (decay natural)

**Tipos de Sinal:**
| Tipo | Efeito | Trigger |
|------|--------|---------|
| `SUCCESS` | +0.05 ao peso | Execu√ß√£o bem-sucedida |
| `FAILURE` | -0.10 ao peso | Execu√ß√£o falhou |
| `WARNING` | -0.02 ao peso | Execu√ß√£o com alertas |

**C√°lculo de Peso Din√¢mico:**
```python
def calculate_weight(self, specialist_type: str, domain: str) -> float:
    base_weight = 0.20  # Peso base igual para todos
    pheromone_score = self.redis.get(f"pheromone:{specialist_type}:{domain}") or 0.5

    # Normaliza√ß√£o para manter soma = 1.0
    adjusted_weight = base_weight * (0.5 + pheromone_score)
    return min(max(adjusted_weight, 0.10), 0.40)  # Limites de seguran√ßa
```

#### C4.5: Agrega√ß√£o Bayesiana

**Agregador**: `services/consensus-engine/src/services/bayesian_aggregator.py`

**Processo:**
1. Coletar opini√µes dos 5 especialistas
2. Aplicar pesos de ferom√¥nios
3. Calcular confian√ßa agregada (m√©dia ponderada)
4. Calcular risco agregado (m√°ximo ponderado)
5. Calcular diverg√™ncia (desvio padr√£o das opini√µes)

**F√≥rmulas:**
```
Confian√ßa Agregada = Œ£(peso_i √ó confian√ßa_i) / Œ£(peso_i)
Risco Agregado = max(peso_i √ó risco_i)
Diverg√™ncia = sqrt(Œ£(peso_i √ó (confian√ßa_i - m√©dia)¬≤) / Œ£(peso_i))
```

#### C4.6: Voting Ensemble

**Voting Ensemble**: `services/consensus-engine/src/services/voting_ensemble.py`

**Processo de Vota√ß√£o:**
```python
def calculate_ensemble_decision(self, opinions: List[SpecialistOpinion], weights: Dict[str, float]) -> VoteResult:
    votes = {
        "APPROVE": 0.0,
        "REJECT": 0.0,
        "CONDITIONAL": 0.0,
        "REVIEW_REQUIRED": 0.0
    }

    for opinion in opinions:
        weight = weights[opinion.specialist_type]
        votes[opinion.recommendation] += weight

    # Verificar unanimidade
    unanimous = len(set(o.recommendation for o in opinions)) == 1

    # Decis√£o por maioria ponderada
    final_decision = max(votes, key=votes.get)

    return VoteResult(
        decision=final_decision,
        unanimous=unanimous,
        vote_distribution=votes
    )
```

#### C4.7: Verifica√ß√£o de Compliance

**Compliance Fallback**: `services/consensus-engine/src/services/compliance_fallback.py`

**Thresholds Adaptativos:**
| Par√¢metro | Valor Padr√£o | Descri√ß√£o |
|-----------|--------------|-----------|
| `min_confidence` | 0.70 | Confian√ßa m√≠nima para aprovar |
| `max_divergence` | 0.25 | Diverg√™ncia m√°xima aceit√°vel |
| `max_risk` | 0.80 | Risco m√°ximo sem revis√£o humana |

**Guardrails:**
| Guardrail | Condi√ß√£o | A√ß√£o |
|-----------|----------|------|
| `confidence_too_low` | confidence < 0.70 | Fallback determin√≠stico |
| `divergence_too_high` | divergence > 0.25 | Solicitar revis√£o humana |
| `risk_critical` | risk > 0.80 | Bloquear execu√ß√£o autom√°tica |
| `unanimous_reject` | 5/5 rejeitam | Rejei√ß√£o imediata |

#### C4.8: Consolidated Decision

**Producer**: `services/consensus-engine/src/producers/decision_producer.py`
**Modelo**: `services/consensus-engine/src/models/consolidated_decision.py`
**T√≥pico Kafka**: `consolidated-decisions.ready`

**Exemplo de Consolidated Decision:**
```json
{
  "decision_id": "dec_1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d",
  "plan_id": "plan_9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d",
  "intent_id": "int_7f8a9b2c-4d5e-6f7a-8b9c-0d1e2f3a4b5c",
  "correlation_id": "corr_1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d",
  "created_at": "2026-01-15T14:30:10.000Z",
  "final_decision": "APPROVE",
  "consensus_method": "BAYESIAN_WEIGHTED",
  "aggregated_confidence": 0.847,
  "aggregated_risk": 0.42,
  "divergence": 0.12,
  "specialist_votes": [
    {
      "specialist_type": "ARCHITECTURE",
      "recommendation": "APPROVE",
      "confidence": 0.85,
      "risk": 0.35,
      "weight": 0.22
    },
    {
      "specialist_type": "TECHNICAL",
      "recommendation": "APPROVE",
      "confidence": 0.88,
      "risk": 0.40,
      "weight": 0.21
    },
    {
      "specialist_type": "BUSINESS",
      "recommendation": "APPROVE",
      "confidence": 0.82,
      "risk": 0.45,
      "weight": 0.20
    },
    {
      "specialist_type": "BEHAVIOR",
      "recommendation": "APPROVE",
      "confidence": 0.80,
      "risk": 0.38,
      "weight": 0.18
    },
    {
      "specialist_type": "EVOLUTION",
      "recommendation": "CONDITIONAL",
      "confidence": 0.78,
      "risk": 0.50,
      "weight": 0.19
    }
  ],
  "consensus_metrics": {
    "unanimous": false,
    "majority_threshold": 0.60,
    "achieved_majority": 0.81,
    "convergence_time_ms": 450
  },
  "compliance_checks": {
    "confidence_check": "PASSED",
    "divergence_check": "PASSED",
    "risk_check": "PASSED",
    "guardrails_triggered": []
  },
  "requires_human_review": false,
  "conditions": [
    "Implementar testes de integra√ß√£o antes do deploy em produ√ß√£o"
  ],
  "cognitive_plan": {
    "plan_id": "plan_9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d",
    "task_count": 5,
    "critical_path_duration_ms": 150000
  },
  "trace_context": {
    "trace_id": "trace_abc123def456",
    "span_id": "span_003"
  }
}
```

### C5: M√©tricas do Consenso

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `consensus_convergence_p95` | < 1000ms | Tempo de converg√™ncia |
| `consensus_unanimity_rate` | ~30% | Taxa de unanimidade |
| `consensus_fallback_rate` | < 5% | Taxa de fallback |
| `consensus_human_review_rate` | < 10% | Taxa de revis√£o humana |

---

## üéØ FLUXO C: Orquestra√ß√£o Din√¢mica de Execu√ß√£o

### C1: Vis√£o Geral

O Fluxo C executa Planos Cognitivos aprovados atrav√©s de workflows Temporal, gerenciando recursos, SLAs e consolida√ß√£o de resultados.

**Servi√ßo Principal**: `services/orchestrator-dynamic/src/main.py`
**Workflow Engine**: Temporal.io
**Tecnologias**: FastAPI, Temporal, gRPC, Redis, MongoDB

### C2: Diagrama do Fluxo

```mermaid
flowchart TD
    subgraph Entrada
        K[üì® Kafka] -->|Decision APPROVE| C[FlowC Consumer]
    end

    subgraph Workflow Temporal
        C --> W[üîÑ Orchestration Workflow]
        W --> T[üìã Generate Tickets]
        T --> A[üé∞ Allocate Resources]
        A --> E[‚ö° Execute Tasks]
        E --> M[üìä Monitor SLAs]
        M --> R[üì¶ Consolidate Results]
    end

    subgraph Execu√ß√£o
        E --> WA[üë∑ Worker Agents]
        E --> SS[üîß Specialized Services]
        WA --> SR[Service Registry]
        SS --> SR
    end

    subgraph Sa√≠da
        R --> KO[üì® Kafka: execution-results]
        R --> N[üîî Notifica√ß√µes]
        R --> ML[üíæ Memory Layer]
    end
```

### C3: Etapas Detalhadas

#### C3.1: Consumir Consolidated Decision

**Consumer**: `services/orchestrator-dynamic/src/integration/flow_c_consumer.py`

**Filtro:** Apenas decisions com `final_decision = "APPROVE"` ou `final_decision = "CONDITIONAL"`

#### C3.2: Iniciar Workflow Temporal

**Workflow**: `services/orchestrator-dynamic/src/workflows/orchestration_workflow.py`

**Defini√ß√£o do Workflow:**
```python
@workflow.defn
class OrchestrationWorkflow:
    @workflow.run
    async def run(self, decision: ConsolidatedDecision) -> ExecutionResult:
        # Activity 1: Gerar tickets de execu√ß√£o
        tickets = await workflow.execute_activity(
            generate_execution_tickets,
            decision.cognitive_plan,
            start_to_close_timeout=timedelta(seconds=30)
        )

        # Activity 2: Alocar recursos
        allocations = await workflow.execute_activity(
            allocate_resources,
            tickets,
            start_to_close_timeout=timedelta(seconds=60)
        )

        # Activity 3: Executar tarefas (paralelo onde poss√≠vel)
        results = []
        for level in self._get_execution_levels(tickets):
            level_results = await asyncio.gather(*[
                workflow.execute_activity(
                    execute_task,
                    ticket,
                    allocation,
                    start_to_close_timeout=timedelta(seconds=300)
                )
                for ticket, allocation in zip(level, allocations)
            ])
            results.extend(level_results)

        # Activity 4: Consolidar resultados
        return await workflow.execute_activity(
            consolidate_results,
            results,
            start_to_close_timeout=timedelta(seconds=30)
        )
```

#### C3.3: Gerar Execution Tickets

**Activity**: `services/orchestrator-dynamic/src/activities/ticket_generation.py`
**Modelo**: `services/orchestrator-dynamic/src/models/execution_ticket.py`

**Exemplo de Execution Ticket:**
```json
{
  "ticket_id": "tkt_001_abc123",
  "plan_id": "plan_9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d",
  "task_id": "task_001",
  "task_type": "SCAFFOLD_SERVICE",
  "priority": 85,
  "estimated_duration_ms": 15000,
  "deadline_ms": 300000,
  "dependencies_satisfied": true,
  "parameters": {
    "service_name": "payment-service",
    "framework": "fastapi"
  },
  "required_capabilities": ["code_generation"],
  "retry_policy": {
    "max_attempts": 3,
    "backoff_ms": 1000,
    "backoff_multiplier": 2.0
  },
  "qos_tier": "standard",
  "trace_context": {
    "trace_id": "trace_abc123def456",
    "span_id": "span_004"
  }
}
```

#### C3.4: Alocar Recursos

**Componentes de Scheduling:**
- `services/orchestrator-dynamic/src/scheduler/intelligent_scheduler.py` - Scheduler principal
- `services/orchestrator-dynamic/src/scheduler/priority_calculator.py` - C√°lculo de prioridade
- `services/orchestrator-dynamic/src/scheduler/resource_allocator.py` - Aloca√ß√£o de recursos

**Estrat√©gias de Aloca√ß√£o:**
1. **C√°lculo de Prioridade**: Baseado em urg√™ncia, depend√™ncias, SLA
2. **Verifica√ß√£o de Capacidade**: Pool de workers dispon√≠veis
3. **Pol√≠ticas de QoS**: Tiers (premium, standard, best-effort)
4. **ML Scheduling Optimizer**: Predi√ß√£o de dura√ß√£o e recursos

#### C3.5: Executar Tarefas

**Worker Temporal**: `services/orchestrator-dynamic/src/workers/temporal_worker.py`

**Estrat√©gias de Execu√ß√£o:**
| Tipo de Tarefa | Executor | Timeout |
|----------------|----------|---------|
| Tarefas simples | Worker Agents | 60s |
| Tarefas complexas | Specialized Services | 300s |
| Integra√ß√µes externas | Service Registry | 120s |

**Service Registry Client**: `services/orchestrator-dynamic/src/clients/service_registry_client.py`

#### C3.6: Monitorar SLAs

**Componentes:**
- `services/orchestrator-dynamic/src/sla/sla_monitor.py` - Monitor de SLAs
- `services/orchestrator-dynamic/src/sla/alert_manager.py` - Gerenciador de alertas

**M√©tricas Monitoradas:**
| M√©trica | Threshold | A√ß√£o |
|---------|-----------|------|
| Lat√™ncia por tarefa | > 80% do estimado | Alerta WARNING |
| Taxa de sucesso | < 95% | Alerta HIGH |
| Tempo de fila | > 30s | Escalar workers |
| Utiliza√ß√£o de recursos | > 85% | Provisionar mais |

**Alertas:**
- `SLA_AT_RISK`: Execu√ß√£o pode exceder deadline
- `SLA_VIOLATED`: Deadline excedido

#### C3.7: Consolidar Resultados

**Activity**: `services/orchestrator-dynamic/src/activities/result_consolidation.py`

**Processo:**
1. Agregar outputs de todas as tarefas
2. Validar integridade dos resultados
3. Calcular m√©tricas de execu√ß√£o
4. Publicar telemetria

#### C3.8: Publicar Resultado Final

**Producer**: `services/orchestrator-dynamic/src/clients/kafka_producer.py`
**T√≥pico**: `execution-results.completed`

**Exemplo de Execution Result:**
```json
{
  "result_id": "res_xyz789",
  "decision_id": "dec_1a2b3c4d-5e6f-7a8b-9c0d-1e2f3a4b5c6d",
  "plan_id": "plan_9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d",
  "intent_id": "int_7f8a9b2c-4d5e-6f7a-8b9c-0d1e2f3a4b5c",
  "status": "SUCCESS",
  "completed_at": "2026-01-15T14:32:30.000Z",
  "execution_summary": {
    "total_tasks": 5,
    "completed_tasks": 5,
    "failed_tasks": 0,
    "retried_tasks": 1,
    "total_duration_ms": 142000,
    "estimated_duration_ms": 150000,
    "efficiency_ratio": 1.056
  },
  "task_results": [
    {
      "task_id": "task_001",
      "status": "SUCCESS",
      "duration_ms": 12000,
      "output": {"service_path": "/services/payment-service"}
    },
    {
      "task_id": "task_002",
      "status": "SUCCESS",
      "duration_ms": 18000,
      "output": {"migration_count": 3}
    },
    {
      "task_id": "task_003",
      "status": "SUCCESS",
      "duration_ms": 42000,
      "output": {"stripe_integration": "configured"}
    },
    {
      "task_id": "task_004",
      "status": "SUCCESS",
      "duration_ms": 28000,
      "retries": 1,
      "output": {"endpoints_created": 4}
    },
    {
      "task_id": "task_005",
      "status": "SUCCESS",
      "duration_ms": 55000,
      "output": {"deployment_url": "https://staging.example.com/payment-service"}
    }
  ],
  "sla_compliance": {
    "deadline_met": true,
    "margin_ms": 8000,
    "violations": []
  },
  "trace_context": {
    "trace_id": "trace_abc123def456",
    "span_id": "span_final"
  }
}
```

### C4: M√©tricas do Fluxo C

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `orchestrator_sla_compliance_p99` | > 99% | Cumprimento de SLA |
| `orchestrator_retry_rate` | < 1.5% | Taxa de retry |
| `orchestrator_burst_usage` | < 5% | Uso de capacidade burst |
| `orchestrator_task_success_rate` | > 99% | Taxa de sucesso de tarefas |

---

## üíæ FLUXO D: Observabilidade Hol√≠stica

### D1: Vis√£o Geral

O Fluxo D fornece observabilidade completa atrav√©s de m√©tricas, traces distribu√≠dos, logs estruturados e mem√≥ria multicamadas.

**Servi√ßo Principal**: `services/memory-layer-api/src/main.py`
**Stack**: OpenTelemetry, Prometheus, Jaeger, Grafana, Loki

### D2: Diagrama de Observabilidade

```mermaid
flowchart LR
    subgraph Coleta
        S1[Gateway] --> OT[OpenTelemetry Collector]
        S2[Semantic] --> OT
        S3[Consensus] --> OT
        S4[Orchestrator] --> OT
        S5[Specialists] --> OT
    end

    subgraph Processamento
        OT --> P[Prometheus<br/>M√©tricas]
        OT --> J[Jaeger<br/>Traces]
        OT --> L[Loki<br/>Logs]
    end

    subgraph Armazenamento
        P --> G[Grafana]
        J --> G
        L --> G
    end

    subgraph Mem√≥ria
        ML[Memory Layer API]
        R[(Redis L1)]
        M[(MongoDB L2)]
        N[(Neo4j L3)]
        C[(ClickHouse L4)]
        ML --> R
        ML --> M
        ML --> N
        ML --> C
    end

    subgraph A√ß√µes
        G --> A[üîî Alertas]
        G --> D[üìä Dashboards]
        A --> SH[Self-Healing]
    end
```

### D3: Camadas de Observabilidade

#### D3.1: M√©tricas (Prometheus)

**M√©tricas por Servi√ßo:**
| Servi√ßo | M√©trica | Tipo | Descri√ß√£o |
|---------|---------|------|-----------|
| Gateway | `gateway_requests_total` | Counter | Total de requisi√ß√µes |
| Gateway | `gateway_latency_seconds` | Histogram | Lat√™ncia de processamento |
| Semantic | `semantic_plans_generated_total` | Counter | Planos gerados |
| Semantic | `semantic_dag_nodes_count` | Histogram | Tarefas por plano |
| Consensus | `consensus_decisions_total` | Counter | Decis√µes tomadas |
| Consensus | `consensus_convergence_seconds` | Histogram | Tempo de converg√™ncia |
| Orchestrator | `orchestrator_tickets_executed_total` | Counter | Tickets executados |
| Orchestrator | `orchestrator_sla_violations_total` | Counter | Viola√ß√µes de SLA |

**Dashboards Grafana:**
- `observability/grafana/dashboards/overview.json` - Vis√£o geral do sistema
- `observability/grafana/dashboards/gateway.json` - M√©tricas do Gateway
- `observability/grafana/dashboards/consensus.json` - M√©tricas de Consenso
- `observability/grafana/dashboards/orchestrator.json` - M√©tricas de Orquestra√ß√£o

#### D3.2: Traces Distribu√≠dos (Jaeger)

**Propaga√ß√£o de Contexto:**
- `trace_id`: Identificador √∫nico do trace E2E
- `span_id`: Identificador do span atual
- `correlation_id`: ID de correla√ß√£o de neg√≥cio

**Exemplo de Trace Completo:**
```
Trace: trace_abc123def456
‚îú‚îÄ‚îÄ span_001: Gateway.receiveIntent (15ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_002: Gateway.validateAuth (5ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_003: Gateway.processNLU (8ms)
‚îú‚îÄ‚îÄ span_004: Semantic.generatePlan (45ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_005: Semantic.enrichContext (12ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_006: Semantic.buildDAG (18ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_007: Semantic.assessRisk (10ms)
‚îú‚îÄ‚îÄ span_008: Consensus.evaluatePlan (450ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_009: Specialist.Architecture (42ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_010: Specialist.Technical (38ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_011: Specialist.Business (45ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_012: Specialist.Behavior (40ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_013: Specialist.Evolution (44ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_014: Consensus.aggregate (35ms)
‚îú‚îÄ‚îÄ span_015: Orchestrator.execute (142000ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_016: Task.scaffold (12000ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_017: Task.database (18000ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_018: Task.stripe (42000ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_019: Task.endpoints (28000ms)
‚îÇ   ‚îî‚îÄ‚îÄ span_020: Task.deploy (55000ms)
‚îî‚îÄ‚îÄ span_021: Memory.persist (25ms)

Total Duration: 142535ms
```

#### D3.3: Logs Estruturados (Loki)

**Formato Structlog:**
```json
{
  "timestamp": "2026-01-15T14:30:00.000Z",
  "level": "INFO",
  "service": "gateway-intencoes",
  "component": "nlu_pipeline",
  "layer": "processing",
  "event": "intent_processed",
  "intent_id": "int_7f8a9b2c",
  "correlation_id": "corr_1a2b3c4d",
  "trace_id": "trace_abc123def456",
  "span_id": "span_003",
  "duration_ms": 8,
  "confidence": 0.89,
  "entities_count": 3
}
```

#### D3.4: Mem√≥ria Multicamadas

**Cliente Unificado**: `services/memory-layer-api/src/clients/unified_memory_client.py`

| Camada | Storage | Lat√™ncia | Uso |
|--------|---------|----------|-----|
| L1 | Redis | < 5ms | Cache hot, sess√µes ativas |
| L2 | MongoDB | < 50ms | Dados operacionais, hist√≥rico recente |
| L3 | Neo4j | < 100ms | Grafos de relacionamento, conhecimento |
| L4 | ClickHouse | < 200ms | Analytics, s√©ries temporais |

**Query Routing:**
```python
def route_query(self, query_type: str, params: dict) -> Any:
    if query_type == "session_context":
        return self.redis.get(f"session:{params['session_id']}")
    elif query_type == "intent_history":
        return self.mongodb.find({"user_id": params["user_id"]})
    elif query_type == "similar_plans":
        return self.neo4j.query_similar(params["intent_embedding"])
    elif query_type == "analytics":
        return self.clickhouse.query(params["sql"])
```

### D4: M√©tricas de Observabilidade

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `observability_coverage` | > 99.7% | Cobertura de telemetria |
| `observability_ingestion_lag` | < 2s | Tempo de ingest√£o |
| `observability_alert_precision_p90` | > 95% | Precis√£o de alertas |
| `observability_query_latency_p95` | < 500ms | Lat√™ncia de consultas |

---

## üîß FLUXO E: Autocura e Resolu√ß√£o Proativa

### E1: Vis√£o Geral

O Fluxo E detecta anomalias e executa a√ß√µes de recupera√ß√£o autom√°tica para manter a sa√∫de do sistema.

**Cliente Principal**: `services/orchestrator-dynamic/src/clients/self_healing_client.py`

### E2: Diagrama do Fluxo

```mermaid
flowchart TD
    subgraph Detec√ß√£o
        P[Prometheus Alerts] --> D[Detector de Anomalias]
        J[Jaeger Errors] --> D
        L[Loki Exceptions] --> D
        M[SLA Metrics] --> D
    end

    subgraph Classifica√ß√£o
        D --> C{Severidade?}
        C -->|CRITICAL| PB1[Playbook Cr√≠tico]
        C -->|HIGH| PB2[Playbook Alta]
        C -->|MEDIUM| PB3[Playbook M√©dia]
        C -->|LOW| PB4[Playbook Baixa]
    end

    subgraph Execu√ß√£o
        PB1 --> A[A√ß√µes Automatizadas]
        PB2 --> A
        PB3 --> A
        PB4 --> A
        A --> CB[Circuit Breaker]
        A --> SC[Scaling]
        A --> RS[Restart]
        A --> FO[Failover]
        A --> RL[Rate Limit]
    end

    subgraph Valida√ß√£o
        CB --> V[Validar Recupera√ß√£o]
        SC --> V
        RS --> V
        FO --> V
        RL --> V
        V -->|OK| DOC[Documentar]
        V -->|FALHA| ESC[Escalar Humano]
    end
```

### E3: Processo Detalhado

#### E3.1: Detec√ß√£o de Anomalias

**Fontes de Detec√ß√£o:**
| Fonte | Tipo de Anomalia | Lat√™ncia de Detec√ß√£o |
|-------|------------------|---------------------|
| Prometheus | M√©tricas fora do baseline | < 15s |
| Jaeger | Traces com erro | < 10s |
| Loki | Exce√ß√µes em logs | < 5s |
| SLA Monitor | Viola√ß√µes de SLA | < 30s |

**Classifica√ß√£o de Severidade:**
| Severidade | Crit√©rio | A√ß√£o |
|------------|----------|------|
| CRITICAL | Sistema indispon√≠vel, perda de dados | A√ß√£o imediata automatizada |
| HIGH | Degrada√ß√£o severa, SLA violado | A√ß√£o em < 1 minuto |
| MEDIUM | Degrada√ß√£o parcial, risco de SLA | A√ß√£o em < 5 minutos |
| LOW | Anomalia detectada, sem impacto | A√ß√£o em < 15 minutos |

#### E3.2: Recovery Playbooks

**Exemplos de Playbooks:**

**kafka_consumer_lag_high.yaml:**
```yaml
name: kafka_consumer_lag_high
description: Consumer lag excedendo threshold
trigger:
  metric: kafka_consumer_lag_seconds
  threshold: 300
  duration: 60s
severity: HIGH
actions:
  - type: scaling
    target: consumer-group
    scale_factor: 2
    max_replicas: 10
  - type: alert
    channel: slack
    message: "Consumer lag alto - scaling autom√°tico iniciado"
validation:
  metric: kafka_consumer_lag_seconds
  expected: < 60
  timeout: 120s
```

**specialist_timeout.yaml:**
```yaml
name: specialist_timeout
description: Especialista n√£o respondendo
trigger:
  metric: specialist_response_time_p99
  threshold: 5000
  duration: 30s
severity: HIGH
actions:
  - type: circuit_breaker
    target: specialist-{type}
    state: HALF_OPEN
  - type: restart
    target: specialist-{type}
    strategy: rolling
  - type: failover
    target: specialist-{type}
    fallback: deterministic_evaluator
validation:
  metric: specialist_response_time_p99
  expected: < 1000
  timeout: 60s
```

#### E3.3: A√ß√µes Dispon√≠veis

| A√ß√£o | Descri√ß√£o | Tempo de Execu√ß√£o |
|------|-----------|-------------------|
| `circuit_breaker` | Isolar componente com falha | < 1s |
| `scaling` | Aumentar/diminuir r√©plicas | < 30s |
| `restart` | Reiniciar pods com falha | < 60s |
| `failover` | Ativar componente backup | < 5s |
| `rate_limit` | Limitar tr√°fego de entrada | < 1s |

#### E3.4: Valida√ß√£o de Recupera√ß√£o

**Processo:**
1. Aguardar per√≠odo de estabiliza√ß√£o (30s padr√£o)
2. Verificar m√©tricas de sa√∫de
3. Comparar com thresholds esperados
4. Se OK: documentar e fechar incidente
5. Se FALHA: escalar para humano

### E4: M√©tricas de Autocura

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `selfhealing_mttd` | < 15s | Mean Time To Detect |
| `selfhealing_mttr` | < 90s | Mean Time To Recover |
| `selfhealing_automation_rate` | > 85% | Taxa de automa√ß√£o |
| `selfhealing_success_rate` | > 95% | Taxa de sucesso de recupera√ß√£o |

---

## üß™ FLUXO F: Gest√£o de Experimentos

### F1: Vis√£o Geral

O Fluxo F gerencia experimentos A/B e feature flags para evolu√ß√£o controlada do sistema.

### F2: Diagrama do Fluxo

```mermaid
flowchart LR
    subgraph Proposta
        H[üìù Hip√≥tese] --> V[‚úÖ Valida√ß√£o √âtica]
        V --> G[üõ°Ô∏è Guardrails]
    end

    subgraph Execu√ß√£o
        G --> AB[üîÄ A/B Split]
        AB --> C[Control Group]
        AB --> T[Treatment Group]
        C --> M[üìä M√©tricas]
        T --> M
    end

    subgraph An√°lise
        M --> S[üìà Signific√¢ncia<br/>Estat√≠stica]
        S -->|p < 0.05| A[‚úÖ Aprovar]
        S -->|p >= 0.05| R[‚ùå Rejeitar]
    end

    subgraph Aprendizado
        A --> U[üîÑ Atualizar Config]
        R --> L[üìö Registrar Ledger]
        U --> L
    end
```

### F3: Processo Detalhado

#### F3.1: Propor Experimento

**Estrutura da Proposta:**
```json
{
  "experiment_id": "exp_001",
  "name": "new_consensus_algorithm",
  "hypothesis": "Algoritmo de consenso baseado em attention melhora converg√™ncia em 15%",
  "objective": "Reduzir tempo de converg√™ncia de consenso",
  "duration_days": 7,
  "traffic_percentage": 10,
  "success_criteria": {
    "primary": "consensus_convergence_time_p95 < 850ms",
    "secondary": "consensus_accuracy > 0.95"
  }
}
```

#### F3.2: Aprova√ß√£o √âtica

**Checklist de √âtica:**
| Crit√©rio | Verifica√ß√£o |
|----------|-------------|
| N√£o exp√µe dados sens√≠veis | ‚úÖ Obrigat√≥rio |
| N√£o degrada UX significativamente | ‚úÖ Obrigat√≥rio |
| Possui mecanismo de rollback | ‚úÖ Obrigat√≥rio |
| Tem m√©tricas de abandono | ‚úÖ Obrigat√≥rio |
| N√£o discrimina usu√°rios | ‚úÖ Obrigat√≥rio |

#### F3.3: Configurar Guardrails

**Exemplo de Guardrails:**
```json
{
  "guardrails": {
    "max_error_rate": 0.05,
    "max_latency_p95_ms": 2000,
    "min_success_rate": 0.95,
    "max_user_complaints": 10,
    "auto_rollback": true
  }
}
```

#### F3.4: Executar Experimento

**Randomiza√ß√£o:**
```python
def assign_group(user_id: str, experiment_id: str, traffic_pct: float) -> str:
    hash_value = hashlib.md5(f"{user_id}:{experiment_id}".encode()).hexdigest()
    bucket = int(hash_value[:8], 16) % 100
    return "treatment" if bucket < traffic_pct else "control"
```

#### F3.5: Analisar Resultados

**M√©tricas Coletadas:**
| M√©trica | Control | Treatment | Diferen√ßa |
|---------|---------|-----------|-----------|
| `rejection_rate` | 2.3% | 1.8% | -21.7% |
| `avg_confidence` | 0.82 | 0.87 | +6.1% |
| `avg_latency_ms` | 920 | 850 | -7.6% |

**Signific√¢ncia Estat√≠stica:**
- p-value < 0.05 para aprovar
- Intervalo de confian√ßa de 95%

#### F3.6: Incorporar Aprendizado

**Se Sucesso:**
1. Atualizar configura√ß√£o global
2. Registrar decis√£o no experiment ledger
3. Documentar aprendizados

**Se Falha:**
1. Registrar no experiment ledger
2. Documentar raz√µes da falha
3. Propor hip√≥tese refinada

### F4: M√©tricas de Experimentos

| M√©trica | SLO | Descri√ß√£o |
|---------|-----|-----------|
| `experiment_lead_time` | < 2 dias | Tempo at√© execu√ß√£o |
| `experiment_ethics_approval_rate` | > 99% | Taxa de aprova√ß√£o √©tica |
| `experiment_analysis_time` | < 10 min | Tempo de an√°lise |
| `experiment_success_rate` | > 30% | Taxa de experimentos bem-sucedidos |

---

## üîê Seguran√ßa e Governan√ßa

### Controles Implementados

#### Autentica√ß√£o
- **OAuth2 + mTLS**: Autentica√ß√£o de servi√ßo a servi√ßo
- **Rota√ß√£o de Tokens**: Autom√°tica a cada 24 horas
- **SPIFFE/SPIRE**: Identidade de workload

#### Autoriza√ß√£o
- **RBAC**: Controle de acesso baseado em roles
- **OPA (Open Policy Agent)**: Pol√≠ticas din√¢micas
- **Pol√≠ticas por Tenant**: Isolamento multi-tenant

**Refer√™ncia**: `services/orchestrator-dynamic/src/policies/opa_client.py`

#### Criptografia
- **TLS 1.3**: Em tr√¢nsito
- **Vault**: Gerenciamento de secrets
- **Encryption at Rest**: Dados em repouso

**Refer√™ncia**: `services/orchestrator-dynamic/src/clients/vault_integration.py`

#### Auditoria
- **Logs Imut√°veis**: Assinados com hash SHA-512
- **Ledger Append-Only**: MongoDB com write-once
- **Reten√ß√£o**: 5 anos para compliance

#### Compliance
- **PII Detection**: Detec√ß√£o autom√°tica de dados sens√≠veis
- **GDPR Compliance**: Direito ao esquecimento
- **Retention Policies**: Pol√≠ticas de reten√ß√£o configur√°veis

**Refer√™ncia**: `documento-04-seguranca-governanca-neural-hive-mind.md`

---

## üìà M√©tricas Globais do Sistema

### SLIs/SLOs do Sistema

| M√©trica | SLO | Atual | Status |
|---------|-----|-------|--------|
| Lat√™ncia E2E P95 | < 2s | 1.8s | ‚úÖ |
| Taxa de Sucesso | > 99% | 99.3% | ‚úÖ |
| Disponibilidade | > 99.9% | 99.95% | ‚úÖ |
| Taxa de Autocorre√ß√£o | > 85% | 87% | ‚úÖ |
| Cobertura de Testes | > 80% | 85% | ‚úÖ |

### Capacidade do Sistema

| Recurso | Capacidade | Uso M√©dio |
|---------|------------|-----------|
| Throughput | 1000 intents/s | 350 intents/s |
| Especialistas | 5 tipos √ó 3 r√©plicas | 15 pods |
| Lat√™ncia M√©dia | - | 850ms |
| Armazenamento | 1TB | 500GB |

---

## üéØ Fluxo Completo Resumido

```mermaid
graph TD
    subgraph "FLUXO A: Captura"
        U[üë§ Usu√°rio] -->|Intent| GW[üö™ Gateway]
        GW -->|Envelope| K1[üì® Kafka]
    end

    subgraph "FLUXO B: Planejamento"
        K1 --> SE[üß† Semantic Engine]
        SE -->|Cognitive Plan| K2[üì® Kafka]
    end

    subgraph "FLUXO CONSENSO"
        K2 --> CE[‚öñÔ∏è Consensus Engine]
        CE <-->|gRPC| SP[üë• 5 Especialistas]
        CE -->|Decision| K3[üì® Kafka]
    end

    subgraph "FLUXO C: Execu√ß√£o"
        K3 --> OD[üéØ Orchestrator]
        OD -->|Workflow| TW[‚ö° Temporal Workers]
        TW -->|Resultado| K4[üì® Kafka]
    end

    subgraph "FLUXO D: Observabilidade"
        GW & SE & CE & OD --> OT[üìä OpenTelemetry]
        OT --> ML[üíæ Memory Layer]
    end

    subgraph "FLUXO E: Autocura"
        OT --> SH[üîß Self-Healing]
        SH -.->|Recovery| GW & SE & CE & OD
    end

    subgraph "FLUXO F: Experimentos"
        EX[üß™ Experiments] -.->|A/B| CE
    end

    K4 --> U
```

---

## üöÄ Pr√≥ximos Passos e Evolu√ß√£o

### Fase 2 (Em Progresso)
- **Scout Agents**: Explora√ß√£o aut√¥noma de dom√≠nios
- **Worker Agents**: Execu√ß√£o distribu√≠da de tarefas
- **Queen Agent**: Coordena√ß√£o central de col√¥nia
- **Guard Agents**: Seguran√ßa e compliance
- **Analyst Agents**: An√°lise de dados e insights
- **Optimizer Agents**: Otimiza√ß√£o cont√≠nua

### Fase 3 (Planejada)
- **Continuous Learning**: Aprendizado cont√≠nuo com feedback
- **Multi-tenancy**: Isolamento completo por tenant
- **Compliance Layer Avan√ßado**: SOC2, HIPAA, PCI-DSS
- **ML Pipelines**: Pipelines de machine learning integrados

### Fase 4 (Futuro)
- **Self-evolving Architecture**: Arquitetura auto-evolutiva
- **Predictive Governance**: Governan√ßa preditiva
- **Autonomous Experimentation**: Experimenta√ß√£o aut√¥noma

**Refer√™ncias:**
- `ROADMAP_COMPLETO.md`
- `PHASE2_IMPLEMENTATION_STATUS.md`

---

## üìö Refer√™ncias de Documenta√ß√£o

### Documentos Conceituais
| Documento | Conte√∫do |
|-----------|----------|
| `documento-01-visao-geral-neural-hive-mind.md` | Vis√£o geral e conceitos |
| `documento-02-arquitetura-e-topologias-neural-hive-mind.md` | Arquitetura e topologias |
| `documento-03-componentes-e-processos-neural-hive-mind.md` | Componentes e processos |
| `documento-04-seguranca-governanca-neural-hive-mind.md` | Seguran√ßa e governan√ßa |
| `documento-05-implementacao-e-operacao-neural-hive-mind.md` | Implementa√ß√£o e opera√ß√£o |
| `documento-06-fluxos-processos-neural-hive-mind.md` | Fluxos operacionais |
| `documento-07-arquitetura-referencia-especifica-neural-hive-mind.md` | Arquitetura de refer√™ncia |
| `documento-08-detalhamento-tecnico-camadas-neural-hive-mind.md` | Detalhamento t√©cnico |

### Guias Operacionais
- `README.md` - Vis√£o geral do projeto
- `DEPLOYMENT_GUIDE.md` - Guia de deployment
- `OPERATIONAL_GUIDE.md` - Guia operacional

### Schemas
- `schemas/cognitive-plan/cognitive-plan.avsc` - Schema Avro de Cognitive Plan
- `schemas/specialist-opinion/specialist.proto` - Protocolo gRPC de Especialistas

---

## üéì Conceitos-Chave

| Conceito | Descri√ß√£o |
|----------|-----------|
| **Intent Envelope** | Envelope can√¥nico que encapsula uma inten√ß√£o humana com contexto, metadados e rastreabilidade |
| **Cognitive Plan** | Plano hier√°rquico de tarefas (DAG) gerado a partir de uma inten√ß√£o, com avalia√ß√£o de risco e explicabilidade |
| **Specialist Opinion** | Parecer estruturado de um especialista neural sobre um plano, incluindo confian√ßa, risco e recomenda√ß√£o |
| **Consolidated Decision** | Decis√£o consensual agregada de m√∫ltiplos especialistas, com m√©tricas de converg√™ncia e compliance |
| **Execution Ticket** | Ordem de trabalho granular para execu√ß√£o distribu√≠da de uma tarefa espec√≠fica |
| **Pheromone Signal** | Sinal de feedback que ajusta dinamicamente o peso de especialistas baseado em hist√≥rico de acertos |
| **Explainability Token** | Identificador que permite recuperar explica√ß√£o detalhada de uma decis√£o ou plano |

---

## üèÜ Diferenciais da Arquitetura

1. **Intelig√™ncia Coletiva**: 5 especialistas colaboram para decis√µes mais robustas que qualquer avalia√ß√£o individual

2. **Aprendizado Cont√≠nuo**: Sistema de ferom√¥nios ajusta pesos dinamicamente baseado em resultados reais

3. **Observabilidade Total**: Rastreabilidade E2E com OpenTelemetry permite debugging em qualquer ponto

4. **Autocura Proativa**: MTTR < 90s com playbooks automatizados reduz tempo de indisponibilidade

5. **Governan√ßa Consciente**: Compliance checks em cada etapa garantem conformidade cont√≠nua

6. **Explicabilidade**: Todas as decis√µes s√£o audit√°veis e explic√°veis, crucial para confian√ßa

7. **Resili√™ncia Biol√≥gica**: Arquitetura inspirada em sistemas naturais (formigas, neur√¥nios) para robustez

---

*Documento gerado para onboarding de desenvolvedores do Neural Hive-Mind.*
*Vers√£o: 1.0.0 | Janeiro 2026*
