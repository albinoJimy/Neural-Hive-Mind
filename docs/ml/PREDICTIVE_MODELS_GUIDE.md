# Guia de Modelos Preditivos - Neural Hive-Mind

## ðŸ“‹ VisÃ£o Geral

O Neural Hive-Mind utiliza 3 modelos preditivos centralizados para otimizar scheduling e detecÃ§Ã£o de anomalias:

1. **SchedulingPredictor** - Prediz duraÃ§Ã£o e recursos de tickets
2. **LoadPredictor** - PrevÃª carga futura do sistema (60min, 6h, 24h)
3. **AnomalyDetector** - Detecta tickets anÃ´malos

## ðŸ—ï¸ Arquitetura

```mermaid
graph TD
    A[Cognitive Plan] --> B[Orchestrator Dynamic]
    B --> C[IntelligentScheduler]
    C --> D[SchedulingPredictor]
    C --> E[AnomalyDetector]
    C --> F[LoadPredictor]
    D --> G[MLflow Registry]
    E --> G
    F --> G
    G --> H[MongoDB Historical Data]
    G --> I[ClickHouse Analytics]
```

## ðŸ“Š Modelos Registrados

### SchedulingPredictor

- **Algoritmo:** XGBoost Regressor
- **Features:** 20 features (risk_weight, capabilities_count, qos_priority, etc.)
- **MÃ©tricas:**
  - MAE < 1000ms
  - MAPE < 15%
  - RÂ² > 0.75
- **Uso:** Prediz `predicted_duration_ms` e `cpu_cores`/`memory_mb`

### LoadPredictor

- **Algoritmo:** Prophet (time-series forecasting)
- **Horizontes:** 60min, 360min, 1440min
- **MÃ©tricas:**
  - MAPE < 20%
  - MAE < 10 tickets
- **Uso:** PrevÃª carga futura para capacity planning
- **Dados:** Usa registros reais do ClickHouse/MongoDB quando disponÃ­veis (fallback sintÃ©tico se <1000 amostras)

### AnomalyDetector

- **Algoritmo:** Isolation Forest
- **Contamination:** 5% (taxa esperada de anomalias)
- **MÃ©tricas:**
  - F1-score > 0.65
  - Precision > 0.70
  - Recall > 0.60
- **Uso:** Detecta tickets com padrÃµes anÃ´malos

## ðŸ”„ Pipeline de Treinamento

### Treinamento AutomÃ¡tico (CronJob)

- **FrequÃªncia:** Semanal (domingos 2 AM UTC)
- **DuraÃ§Ã£o:** ~10-20 minutos
- **Dados:** Ãšltimos 18 meses (540 dias)
- **Auto-promoÃ§Ã£o:** Modelos promovidos se mÃ©tricas melhorarem >5%

### Treinamento Manual

```bash
kubectl create job --from=cronjob/predictive-models-training \
  manual-training-$(date +%Y%m%d-%H%M%S) \
  -n neural-hive-ml
```

## ðŸ“ˆ Monitoramento

### MÃ©tricas Prometheus

- `orchestration_ml_prediction_duration_seconds` - LatÃªncia de prediÃ§Ãµes (histograma por modelo)
- `orchestration_ml_predictions_total` - Contagem de prediÃ§Ãµes por modelo/status
- `orchestration_ml_anomalies_detected_total` - Total de anomalias detectadas
- `orchestration_ml_prediction_cache_hits_total` - Hits de cache de prediÃ§Ãµes/forecasts
- `orchestration_ml_model_accuracy` - MÃ©tricas de acurÃ¡cia (gauges por modelo/metric_type)

### Alertas

- **MLTrainingJobFailed** - Job de treinamento falhou
- **MLTrainingJobTookTooLong** - Job rodando >2h
- **PredictionLatencyHigh** - P95 latency >100ms
- **AnomalyRateHigh** - Taxa de anomalias >10%

## ðŸ”§ Troubleshooting

### Modelos nÃ£o carregam no Orchestrator

1. Verificar se modelos estÃ£o em Production:
   ```bash
   ./ml_pipelines/training/validate_model_promotion.sh
   ```

2. Verificar logs do Orchestrator:
   ```bash
   kubectl logs -n semantic-translation -l app=orchestrator-dynamic | grep -i "predictor"
   ```

3. Verificar MLflow acessÃ­vel:
   ```bash
   kubectl port-forward -n mlflow svc/mlflow 5000:5000
   curl http://localhost:5000/health
   ```

### PrediÃ§Ãµes com baixa confianÃ§a

- **Causa:** Dados histÃ³ricos insuficientes
- **SoluÃ§Ã£o:** Aguardar acÃºmulo de dados (mÃ­nimo 1000 tickets)

### Taxa de anomalias muito alta (>10%)

- **Causa:** Threshold muito sensÃ­vel
- **SoluÃ§Ã£o:** Ajustar `contamination` em `anomaly_detector.py` (linha 44)

## ðŸ“Š Requisitos de Dados de Treinamento

### ConfiguraÃ§Ãµes de Treinamento

Os requisitos de dados sÃ£o configurÃ¡veis via variÃ¡veis de ambiente ou ConfigMap:

| ConfiguraÃ§Ã£o | Default | DescriÃ§Ã£o |
|-------------|---------|-----------|
| `ml_min_training_samples` | 100 | MÃ­nimo de amostras para treinar modelo |
| `ml_training_window_days` | 540 | Janela de dados (18 meses para sazonalidade) |
| `ml_duration_error_threshold` | 0.15 | MAE mÃ¡ximo (15%) para promoÃ§Ã£o |

### Campos ObrigatÃ³rios nos Dados

Para treinamento do **DurationPredictor**:
- `actual_duration_ms` - DuraÃ§Ã£o real de execuÃ§Ã£o (obrigatÃ³rio, >0)
- `completed_at` - Timestamp de conclusÃ£o (usado para filtrar janela)
- `task_type` - Tipo da tarefa (para features)
- `risk_band` - Banda de risco (low/medium/high/critical)
- `estimated_duration_ms` - Estimativa inicial
- `required_capabilities` - Lista de capabilities necessÃ¡rias

Para treinamento do **AnomalyDetector**:
- `completed_at` - Timestamp de conclusÃ£o
- `task_type`, `risk_band`, `required_capabilities` - Features de detecÃ§Ã£o

### CritÃ©rios de PromoÃ§Ã£o de Modelos

Os modelos sÃ£o promovidos para Production quando atingem os seguintes critÃ©rios:

**DurationPredictor:**
- MAE percentual < `ml_duration_error_threshold` (default 15%)
- RÂ² > 0.7 (recomendado)

**AnomalyDetector:**
- Precision >= `ml_validation_precision_threshold` (default 0.75)
- F1-score > 0.65 (recomendado)

### Comportamento de Fallback HeurÃ­stico

Quando o modelo nÃ£o estÃ¡ treinado (sem `estimators_`), o sistema usa heurÃ­sticas:

**DurationPredictor fallback:**
- Usa `avg_duration_by_task` ajustado por `risk_weight` e `capabilities_count`
- Retorna `confidence=0.3` para indicar prediÃ§Ã£o heurÃ­stica

**AnomalyDetector fallback:**
- Aplica regras heurÃ­sticas: resource_mismatch, duration_outlier, capability_anomaly
- `anomaly_score=-0.5` para anomalias, `0.5` para normais

## ðŸš€ Auto-Treinamento no Startup

### Job de InicializaÃ§Ã£o

Durante o startup do Orchestrator, o mÃ©todo `MLPredictor.ensure_models_trained()` Ã© chamado para:

1. Verificar se modelos existentes tÃªm `estimators_` (estÃ£o treinados)
2. Se nÃ£o treinados, verificar disponibilidade de dados via `count_documents`
3. Se `count >= ml_min_training_samples`, executar treinamento automÃ¡tico
4. Promover modelo se mÃ©tricas atingirem critÃ©rios

```python
# Chamado durante inicializaÃ§Ã£o
status = await ml_predictor.ensure_models_trained()
# Retorna: {'duration': bool, 'anomaly': bool}
```

### Fluxo de DecisÃ£o

```
_ensure_model_trained()
    â”‚
    â”œâ”€â–º Modelo tem estimators_? â”€â–º SIM â”€â–º return True
    â”‚
    â””â”€â–º NÃƒO
         â”‚
         â”œâ”€â–º count_documents >= ml_min_training_samples? â”€â–º NÃƒO â”€â–º return False
         â”‚
         â””â”€â–º SIM â”€â–º train_model()
                     â”‚
                     â”œâ”€â–º MÃ©tricas OK? â”€â–º Promover modelo â”€â–º return True
                     â”‚
                     â””â”€â–º MÃ©tricas insuficientes â”€â–º return False
```

## ðŸ“ˆ MÃ©tricas de Monitoramento

### Status de Treinamento

- `ml_model_training_status{model_name, is_trained, has_estimators}` - Status atual do modelo
- `ml_model_quality_metrics{model_name, metric_type}` - MÃ©tricas de qualidade (MAE, RMSE, RÂ², precision, recall, f1)

### Como Monitorar

```promql
# Verificar se modelos estÃ£o treinados
ml_model_training_status{is_trained="true"}

# Verificar qualidade dos modelos
ml_model_quality_metrics{model_name="ticket-duration-predictor", metric_type="mae_percentage"}

# Alertar se modelo nÃ£o treinado
ml_model_training_status{model_name="ticket-duration-predictor", is_trained="false"} == 1
```

### Logs Estruturados

Eventos relevantes logados:
- `predictor_initialized_without_trained_model` - Modelo nÃ£o disponÃ­vel no startup
- `auto_training_triggered` - Treinamento automÃ¡tico iniciado
- `auto_training_succeeded` / `auto_training_not_promoted` - Resultado do treinamento
- `model_not_trained_using_heuristic` - Fallback para heurÃ­stica em prediÃ§Ã£o

## ðŸ“š ReferÃªncias

- Pipeline de treinamento: `file:ml_pipelines/training/train_predictive_models.py`
- Modelos: `file:libraries/python/neural_hive_ml/predictive_models/`
- Scheduler: `file:services/orchestrator-dynamic/src/scheduler/intelligent_scheduler.py`
- Testes E2E: `file:tests/e2e/test_predictive_models_e2e.py`
