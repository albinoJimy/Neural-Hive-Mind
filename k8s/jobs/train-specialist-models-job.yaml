apiVersion: batch/v1
kind: Job
metadata:
  name: train-specialist-models
  namespace: mlflow
  labels:
    app: model-training
    component: specialist-models
spec:
  ttlSecondsAfterFinished: 3600
  backoffLimit: 2
  template:
    metadata:
      labels:
        app: model-training
    spec:
      restartPolicy: Never
      containers:
      - name: trainer
        image: python:3.11-slim
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "============================================="
          echo "ü§ñ Neural Hive - Model Training Pipeline"
          echo "============================================="

          # Instalar depend√™ncias
          # scikit-learn 1.5.x √© a vers√£o de refer√™ncia para modelos em Production
          echo "üì¶ Instalando depend√™ncias..."
          pip install --quiet mlflow==2.9.0 "scikit-learn>=1.5.0,<1.6.0" pandas numpy pymongo structlog pyarrow

          # Criar script de treinamento inline
          cat > /tmp/train_model.py << 'PYTHON_SCRIPT'
          #!/usr/bin/env python3
          """Pipeline de treinamento de modelos para especialistas."""
          import os
          import sys
          import pickle
          import tempfile
          import numpy as np
          import pandas as pd
          from sklearn.ensemble import RandomForestClassifier
          from sklearn.model_selection import train_test_split
          from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
          import mlflow
          import mlflow.sklearn

          def create_synthetic_dataset(n_samples=1000):
              """Cria dataset sint√©tico para treinamento."""
              np.random.seed(42)

              data = {
                  'cognitive_complexity': np.random.uniform(0, 1, n_samples),
                  'abstraction_level': np.random.uniform(0, 1, n_samples),
                  'reasoning_depth': np.random.randint(1, 6, n_samples),
                  'confidence_score': np.random.beta(5, 2, n_samples),
                  'risk_score': np.random.beta(2, 5, n_samples),
                  'priority_numeric': np.random.choice([0, 1, 2, 3], n_samples),
                  'consensus_agreement': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
                  'specialist_agreement_rate': np.random.uniform(0.5, 1, n_samples),
              }

              # Features adicionais
              for i in range(18):
                  data[f'feature_{i}'] = np.random.randn(n_samples)

              df = pd.DataFrame(data)
              df['label'] = df['consensus_agreement']

              return df

          def train_specialist_model(specialist_type):
              """Treina modelo para um especialista."""
              print(f"\n{'='*50}")
              print(f"üîß Treinando modelo para: {specialist_type}")
              print(f"{'='*50}")

              # Configurar MLflow
              mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://mlflow:5000'))
              experiment_name = f"{specialist_type}-specialist"

              try:
                  mlflow.create_experiment(experiment_name)
              except:
                  pass

              mlflow.set_experiment(experiment_name)

              with mlflow.start_run(run_name=f"{specialist_type}-training"):
                  # Par√¢metros
                  mlflow.log_param('specialist_type', specialist_type)
                  mlflow.log_param('model_type', 'random_forest')
                  mlflow.log_param('n_estimators', 100)

                  # Dataset sint√©tico (Comment 3: logar data_source para rastreabilidade)
                  df = create_synthetic_dataset(n_samples=1000)
                  mlflow.log_metric('dataset_size', len(df))
                  mlflow.log_param('data_source', 'synthetic')
                  mlflow.set_tag('data_source_type', 'synthetic')
                  print(f"   ‚ö†Ô∏è  Using SYNTHETIC dataset for training")

                  # Split
                  X = df.drop('label', axis=1)
                  y = df['label']
                  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                  print(f"   Dataset: {len(df)} samples")
                  print(f"   Train: {len(X_train)}, Test: {len(X_test)}")

                  # Treinar
                  model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
                  model.fit(X_train, y_train)

                  # Avaliar
                  y_pred = model.predict(X_test)
                  metrics = {
                      'precision': precision_score(y_test, y_pred, zero_division=0),
                      'recall': recall_score(y_test, y_pred, zero_division=0),
                      'f1': f1_score(y_test, y_pred, zero_division=0),
                      'accuracy': accuracy_score(y_test, y_pred)
                  }

                  for name, value in metrics.items():
                      mlflow.log_metric(name, value)

                  print(f"   Precision: {metrics['precision']:.3f}")
                  print(f"   Recall: {metrics['recall']:.3f}")
                  print(f"   F1: {metrics['f1']:.3f}")
                  print(f"   Accuracy: {metrics['accuracy']:.3f}")

                  # Registrar modelo
                  model_name = f"{specialist_type}-evaluator"

                  # Log modelo como sklearn
                  mlflow.sklearn.log_model(
                      model,
                      artifact_path="model",
                      registered_model_name=model_name
                  )

                  print(f"   ‚úÖ Modelo registrado: {model_name}")

                  # Validar m√©tricas antes de promover
                  min_precision = 0.75
                  min_recall = 0.70
                  min_f1 = 0.72

                  metrics_ok = (
                      metrics['precision'] >= min_precision and
                      metrics['recall'] >= min_recall and
                      metrics['f1'] >= min_f1
                  )

                  client = mlflow.tracking.MlflowClient()
                  versions = client.search_model_versions(f"name='{model_name}'")
                  if versions:
                      latest_version = max([int(v.version) for v in versions])

                      if metrics_ok:
                          # Arquivar vers√µes anteriores em Production manualmente (Comment 5)
                          # Similar a scripts/mlflow/promote_model.py
                          archived_versions = []
                          for v in versions:
                              if v.current_stage == "Production":
                                  client.transition_model_version_stage(
                                      name=model_name,
                                      version=v.version,
                                      stage="Archived",
                                      archive_existing_versions=False
                                  )
                                  archived_versions.append(v.version)
                                  print(f"   üì¶ Arquivada vers√£o anterior v{v.version}")

                          # Promover nova vers√£o para Production
                          # N√£o usar archive_existing_versions=True porque j√° arquivamos manualmente
                          client.transition_model_version_stage(
                              name=model_name,
                              version=latest_version,
                              stage="Production",
                              archive_existing_versions=False
                          )
                          print(f"   ‚úÖ Modelo v{latest_version} promovido para PRODUCTION")
                          if archived_versions:
                              print(f"   üìã Vers√µes arquivadas: {archived_versions}")
                      else:
                          # M√©tricas n√£o atingiram threshold, manter em Staging
                          client.transition_model_version_stage(
                              name=model_name,
                              version=latest_version,
                              stage="Staging"
                          )
                          print(f"   ‚ö†Ô∏è M√©tricas abaixo do threshold, v{latest_version} em Staging")
                          print(f"      Requerido: P>={min_precision}, R>={min_recall}, F1>={min_f1}")

                  return metrics_ok

          def main():
              specialists = ['business', 'technical', 'behavior', 'evolution', 'architecture']

              print("\nüöÄ Iniciando treinamento de modelos para todos os especialistas\n")

              success_count = 0
              for specialist in specialists:
                  try:
                      if train_specialist_model(specialist):
                          success_count += 1
                  except Exception as e:
                      print(f"   ‚ùå Erro treinando {specialist}: {e}")

              print(f"\n{'='*50}")
              print(f"‚úÖ Treinamento conclu√≠do: {success_count}/{len(specialists)} modelos")
              print(f"{'='*50}\n")

              # Listar modelos registrados
              print("üìä Modelos registrados no MLflow:")
              client = mlflow.tracking.MlflowClient()
              for rm in client.search_registered_models():
                  print(f"   - {rm.name}")
                  for v in rm.latest_versions:
                      print(f"     v{v.version}: {v.current_stage}")

              return success_count == len(specialists)

          if __name__ == '__main__':
              success = main()
              sys.exit(0 if success else 1)
          PYTHON_SCRIPT

          # Executar treinamento
          python /tmp/train_model.py

          echo ""
          echo "============================================="
          echo "‚úÖ Pipeline de treinamento conclu√≠do!"
          echo "============================================="
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.mlflow.svc.cluster.local:5000"
        - name: PYTHONUNBUFFERED
          value: "1"
        # Controle de fallback para dataset sint√©tico
        # Em production, defina ALLOW_SYNTHETIC_FALLBACK=false para exigir dataset real
        - name: ALLOW_SYNTHETIC_FALLBACK
          value: "true"
        - name: ENVIRONMENT
          value: "development"
        # Threshold de melhoria para promo√ß√£o autom√°tica (Comment 4)
        # Novo modelo precisa ser improvement_threshold melhor que baseline
        - name: MODEL_IMPROVEMENT_THRESHOLD
          value: "0.05"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
