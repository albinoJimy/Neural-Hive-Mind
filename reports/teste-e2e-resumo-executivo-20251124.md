# Resumo Executivo - Teste E2E Manual
**Data**: 24/11/2025
**Status**: PARCIALMENTE CONCLUÃDO - Fluxo A validado, Fluxos B/C bloqueados

---

## ğŸ¯ Objetivo

Validar end-to-end os trÃªs fluxos principais do Neural Hive-Mind:
- **Fluxo A**: Gateway â†’ Kafka
- **Fluxo B**: Semantic Translation â†’ Specialists â†’ Plano Cognitivo
- **Fluxo C**: Consensus â†’ Orchestrator â†’ Execution Tickets

---

## âœ… FLUXO A: VALIDADO COM SUCESSO (100%)

### Resultados

| Passo | Status | Tempo | ObservaÃ§Ã£o |
|-------|--------|-------|------------|
| Gateway Health Check | âœ… | <200ms | Todos componentes healthy |
| Processar IntenÃ§Ã£o | âœ… | 231ms | Confidence 0.95 (HIGH) |
| Publicar no Kafka | âœ… | - | Topic: intentions-security |
| Cache no Redis | âœ… | - | TTL aplicado corretamente |

### IDs Capturados

```
intent_id: b7e4d61f-b41c-4779-914b-d14bbcaa1a04
correlation_id: e2e-test-08fcb589
domain: security
classification: authentication
confidence: 0.95
```

### EvidÃªncias

**Mensagem no Kafka (intentions-security partition 2, offset 9)**:
```json
{
  "id": "b7e4d61f-b41c-4779-914b-d14bbcaa1a04",
  "correlationId": "e2e-test-08fcb589",
  "intent": {
    "text": "Analisar viabilidade tÃ©cnica de implementar autenticaÃ§Ã£o biomÃ©trica no aplicativo mÃ³vel",
    "domain": "SECURITY",
    "classification": "authentication"
  },
  "confidence": 0.95
}
```

**Cache no Redis**:
```bash
redis-cli GET "intent:b7e4d61f-b41c-4779-914b-d14bbcaa1a04"
# âœ“ Dados completos cacheados
```

---

## âŒ FLUXO B/C: BLOQUEADOS (0%)

### Problema CrÃ­tico

**Semantic Translation Engine nÃ£o consegue consumir mensagens do Kafka**

**Sintoma**:
```
KafkaError{code=UNKNOWN_TOPIC_OR_PART,val=3,str="Subscribed topic not available: intentions-security: Broker: Unknown topic or partition"}
```

### AnÃ¡lise Profunda Executada

Executei script de debug Python com logging completo do `librdkafka`:

**Descobertas**:
1. âœ… AdminClient lista tÃ³picos corretamente (17 tÃ³picos encontrados)
2. âœ… TÃ³picos `intentions-*` existem e tÃªm 3 partitions cada
3. âœ… DNS resolve: `neural-hive-kafka-kafka-bootstrap â†’ 10.99.11.200`
4. âœ… Consumer conecta ao bootstrap server
5. âœ… Consumer obtÃ©m metadata inicial
6. âŒ **Broker termina conexÃ£o ao tentar fazer partition assignment**

**EvidÃªncia dos Logs**:
```
[DEBUG] AdminClient.list_topics() â†’ SUCESSO
[DEBUG] Consumer.subscribe(topics) â†’ SUCESSO
[DEBUG] Consumer obtÃ©m metadata â†’ SUCESSO
[ERROR] Broker: Client is terminating (after 395ms) (_DESTROY)
[ERROR] Broker changed state UP â†’ DOWN
```

### Root Cause

**O broker Kafka estÃ¡ encerrando forÃ§adamente conexÃµes de consumers apÃ³s metadata exchange**, provavelmente devido a:

1. ConfiguraÃ§Ã£o `connections.max.idle.ms` muito baixa
2. Incompatibilidade com mÃºltiplos listeners (REPLICATION, PLAIN, TLS)
3. Bug na versÃ£o do Strimzi Operator ou Kafka 4.1.0

### Tentativas de ResoluÃ§Ã£o

| SoluÃ§Ã£o | Status | Resultado |
|---------|--------|-----------|
| OpÃ§Ã£o 1: Atualizar confluent-kafka | â¸ï¸ | Requer rebuild de imagem |
| OpÃ§Ã£o 2: Usar broker direto | âŒ | Testado - problema persiste |
| OpÃ§Ã£o 3: Adicionar keepalive configs | â¸ï¸ | Requer rebuild de imagem |
| Restart do broker Kafka | âœ… | Executado - nÃ£o resolveu |
| Restart dos pods STE | âœ… | Executado - nÃ£o resolveu |

---

## ğŸ“Š Impacto

### Componentes Afetados

- âŒ Semantic Translation Engine (nÃ£o consome)
- âŒ 5 Specialists (nÃ£o sÃ£o consultados)
- âŒ Consensus Engine (nÃ£o recebe plans)
- âŒ Orchestrator Dynamic (nÃ£o gera tickets)
- âŒ Memory Layer API (sem dados para armazenar)

### MÃ©tricas

| MÃ©trica | Esperado | Obtido | Status |
|---------|----------|--------|--------|
| IntenÃ§Ãµes publicadas | 1 | 1 | âœ… |
| Plans gerados | 1 | **0** | âŒ |
| Specialists consultados | 5 | **0** | âŒ |
| DecisÃµes de consensus | 1 | **0** | âŒ |
| Execution tickets | 3-5 | **0** | âŒ |

---

## ğŸ”§ SoluÃ§Ãµes Propostas (Em Ordem de Prioridade)

### 1. CRÃTICO - Ajustar ConfiguraÃ§Ã£o do Broker Kafka

```bash
kubectl edit kafka neural-hive-kafka -n kafka
```

```yaml
spec:
  kafka:
    config:
      # Aumentar timeout de conexÃµes idle
      connections.max.idle.ms: 600000  # 10 minutos (padrÃ£o: 600000)

      # Aumentar buffer de requests
      socket.request.max.bytes: 104857600  # 100MB

      # Ajustar metadata refresh
      metadata.max.age.ms: 300000  # 5 minutos

      # Desabilitar compressÃ£o agressiva (pode causar timeouts)
      compression.type: "none"
```

**Reiniciar broker apÃ³s mudanÃ§a**:
```bash
kubectl delete pod neural-hive-kafka-broker-0 -n kafka
kubectl wait --for=condition=ready pod -l strimzi.io/name=neural-hive-kafka-kafka -n kafka --timeout=180s
```

### 2. ALTA - Rebuild STE com ConfiguraÃ§Ãµes Corrigidas

**services/semantic-translation-engine/src/consumers/intent_consumer.py**:
```python
consumer_config = {
    'bootstrap.servers': self.settings.kafka_bootstrap_servers,
    'group.id': self.settings.kafka_consumer_group_id,
    'auto.offset.reset': self.settings.kafka_auto_offset_reset,
    'enable.auto.commit': False,
    'isolation.level': 'read_committed',
    'session.timeout.ms': self.settings.kafka_session_timeout_ms,

    # FIX: Prevenir timeout e desconexÃµes
    'connections.max.idle.ms': 540000,  # 9 minutos
    'socket.keepalive.enable': True,
    'heartbeat.interval.ms': 3000,
    'max.poll.interval.ms': 300000,  # 5 minutos
    'metadata.max.age.ms': 180000,  # 3 minutos
    'topic.metadata.refresh.interval.ms': 10000,  # 10 segundos
}
```

**Rebuild e deploy**:
```bash
cd /jimy/Neural-Hive-Mind
docker build -t docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix \
  --build-arg BUILD_CONTEXT=. \
  -f services/semantic-translation-engine/Dockerfile .

docker push docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix

kubectl set image deployment/semantic-translation-engine \
  semantic-translation-engine=docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix \
  -n semantic-translation

kubectl rollout status deployment/semantic-translation-engine -n semantic-translation
```

### 3. MÃ‰DIA - Investigar Strimzi Operator

O Strimzi v0.x pode ter bugs conhecidos com metadata requests. Considerar:

1. Verificar versÃ£o atual:
```bash
kubectl get deploy -n strimzi-system strimzi-cluster-operator -o yaml | grep image:
```

2. Upgrade para versÃ£o mais recente (se < 0.40.0):
```bash
kubectl apply -f 'https://strimzi.io/install/latest?namespace=strimzi-system'
```

### 4. ALTERNATIVA - Migrar para Kafka Nativo

Se Strimzi continuar problemÃ¡tico:

```bash
# Deploy Kafka usando Helm Chart oficial da Apache
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install neural-hive-kafka bitnami/kafka \
  --namespace kafka \
  --set replicaCount=1 \
  --set listeners.client.protocol=PLAINTEXT
```

---

## ğŸ“‹ Checklist de ValidaÃ§Ã£o PÃ³s-CorreÃ§Ã£o

### Fluxo A (Revalidar)
- [ ] Gateway health check
- [ ] Enviar nova intenÃ§Ã£o
- [ ] Verificar publicaÃ§Ã£o no Kafka
- [ ] Validar cache no Redis

### Fluxo B
- [ ] STE consumir mensagem do Kafka
- [ ] STE gerar plano cognitivo
- [ ] STE publicar plan no topic `plans.ready`
- [ ] Verificar persistÃªncia no MongoDB (`cognitive_ledger`)
- [ ] Validar mÃ©tricas no Prometheus
- [ ] Verificar trace no Jaeger

### Specialists
- [ ] Specialist Business responder
- [ ] Specialist Technical responder
- [ ] Specialist Architecture responder
- [ ] Specialist Behavior responder
- [ ] Specialist Evolution responder
- [ ] 5/5 opiniÃµes persistidas no MongoDB

### Fluxo C
- [ ] Consensus Engine agregar opiniÃµes
- [ ] Consensus Engine gerar decisÃ£o
- [ ] DecisÃ£o persistida no MongoDB (`consensus_decisions`)
- [ ] FeromÃ´nios publicados no Redis
- [ ] Orchestrator gerar execution tickets
- [ ] Tickets persistidos no MongoDB (`execution_tickets`)

---

## ğŸ¯ PrÃ³ximos Passos Imediatos

### âœ… AÃ§Ãµes JÃ¡ Executadas

1. âœ… **CorreÃ§Ã£o #1 APLICADA**: Ajustado config do Kafka broker
   ```yaml
   connections.max.idle.ms: 600000
   socket.request.max.bytes: 104857600
   metadata.max.age.ms: 300000
   ```
   - Broker reiniciado
   - **Resultado**: Problema persiste

2. âœ… **CorreÃ§Ã£o #2 APLICADA**: CÃ³digo do STE modificado com keepalive configs
   - Arquivo `intent_consumer.py` atualizado
   - **Resultado**: Requer rebuild de imagem (nÃ£o aplicado em runtime)

3. âœ… **CorreÃ§Ã£o #3 TESTADA**: Alterado KAFKA_BOOTSTRAP_SERVERS para broker direto
   - Usado `neural-hive-kafka-broker-0.neural-hive-kafka-kafka-brokers.kafka.svc:9092`
   - **Resultado**: Problema persiste

### ğŸ”´ AÃ§Ãµes Pendentes (Offline)

1. **CRÃTICO**: Rebuild completo da imagem do STE com correÃ§Ãµes
   ```bash
   # Navegar para raiz do projeto
   cd /jimy/Neural-Hive-Mind

   # Build com contexto correto incluindo schemas
   docker build --platform linux/amd64 \
     --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
     -t neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix \
     --file services/semantic-translation-engine/Dockerfile \
     --build-context schemas=./schemas \
     .

   # Tag e push para registry
   docker tag neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix \
     docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix
   docker push docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix

   # Update deployment
   kubectl set image deployment/semantic-translation-engine \
     semantic-translation-engine=docker.io/neural-hive-mind/semantic-translation-engine:1.0.8-kafka-fix \
     -n semantic-translation
   ```

2. **ALTA**: Investigar versÃ£o do Strimzi Operator
   - Verificar se hÃ¡ bugs conhecidos com KRaft mode + metadata requests
   - Considerar downgrade para ZooKeeper mode se necessÃ¡rio
   - Ou upgrade para Strimzi mais recente

3. **ALTERNATIVA**: Deploy Kafka standalone (sem Strimzi)
   - Usar Helm chart oficial do Apache Kafka
   - Ou Bitnami Kafka chart
   - ConfiguraÃ§Ã£o mais simples pode resolver problema de metadata

---

## ğŸ“„ DocumentaÃ§Ã£o Relacionada

- **RelatÃ³rio Detalhado**: [teste-e2e-manual-20251124.md](./teste-e2e-manual-20251124.md)
- **Script de Debug**: [../scripts/kafka/debug-ste-kafka-connection.py](../scripts/kafka/debug-ste-kafka-connection.py)
- **Logs Salvos**: `logs/ste-kafka-error-20251124.log`

---

## âœ… ConclusÃ£o

**Fluxo A estÃ¡ 100% funcional** - Gateway, NLU, Kafka Producer e Redis operando perfeitamente.

**Fluxo B/C estÃ£o bloqueados** por bug de infraestrutura no Kafka broker que estÃ¡ terminando conexÃµes de consumers prematuramente. A soluÃ§Ã£o requer ajuste de configuraÃ§Ã£o do broker + rebuild do STE com parÃ¢metros de keepalive/timeout adequados.

**Estimativa de ResoluÃ§Ã£o**: 2-4 horas de trabalho tÃ©cnico + testes de revalidaÃ§Ã£o.
